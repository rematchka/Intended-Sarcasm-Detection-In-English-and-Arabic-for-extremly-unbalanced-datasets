{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basline_ML.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"72beb5ac3f6a4eb2a7b75e4d00922a76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_369a4a585490425d8f6dd43fd11e0981","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a0ae20d03d6749deb5b79557e1e162f2","IPY_MODEL_a82251be93cd4ebcb7a9ca05d30df03e","IPY_MODEL_ffdd3972063f4be083ff46d442ed6537"]}},"369a4a585490425d8f6dd43fd11e0981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0ae20d03d6749deb5b79557e1e162f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd5a982c44004f63adda21a8dfa071d4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d57d9b5d71da4961b997234919488e92"}},"a82251be93cd4ebcb7a9ca05d30df03e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0326432c939b41a9a2956c59ae8f9c55","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_459cdeec89f44b63821f6d6c0e23ec26"}},"ffdd3972063f4be083ff46d442ed6537":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4e34e3e70e6e4bdd966a9f11b7dbee5c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:10&lt;00:00, 37.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa2e4d8f21dd4a128748c743a0c39672"}},"cd5a982c44004f63adda21a8dfa071d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d57d9b5d71da4961b997234919488e92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0326432c939b41a9a2956c59ae8f9c55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"459cdeec89f44b63821f6d6c0e23ec26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e34e3e70e6e4bdd966a9f11b7dbee5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa2e4d8f21dd4a128748c743a0c39672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"421d86ef54464e57a82f7d2d8966e6be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_61ac26f1b5464bf9bc36e835e22c2936","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_538159e0c1f94623b9765a39d0ca77ae","IPY_MODEL_7688d0391df84abfb5fecf214ae6345b","IPY_MODEL_efdee16a08794d60b823181c572fa1b8"]}},"61ac26f1b5464bf9bc36e835e22c2936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"538159e0c1f94623b9765a39d0ca77ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ccc8b4c833df415fb330163728b4b1cc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f924ea693c4648d28b186d1a3babeec2"}},"7688d0391df84abfb5fecf214ae6345b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8c3a7549522840fead1b78519727e620","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1175,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1175,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dbc6af5ffbf45caae5135fb1924ff46"}},"efdee16a08794d60b823181c572fa1b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7f51cbe0444d45e3954266abc88b2eae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.18k/1.18k [00:00&lt;00:00, 27.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de61c8ba8ad4419dbfb9620c7813e8e2"}},"ccc8b4c833df415fb330163728b4b1cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f924ea693c4648d28b186d1a3babeec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c3a7549522840fead1b78519727e620":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4dbc6af5ffbf45caae5135fb1924ff46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f51cbe0444d45e3954266abc88b2eae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"de61c8ba8ad4419dbfb9620c7813e8e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75f2ddc72bbf46f2a9cb7a2d667153f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ad97ac6775f74f13ab118af51d3b1952","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_76f21dd075da4625bfbac8c90de59091","IPY_MODEL_fd44050aeb3c4a9ab2dd6a2ca6bd645b","IPY_MODEL_130f2df38c0a45bcb6c0b565aab4f017"]}},"ad97ac6775f74f13ab118af51d3b1952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76f21dd075da4625bfbac8c90de59091":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e236c445eb8648b4994c13937eb02b62","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9dffd63ab8734ffd8ffba1d1a7902ca4"}},"fd44050aeb3c4a9ab2dd6a2ca6bd645b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a291e1e133714e99b4108262ac6c0cbc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":10177,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10177,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24b3690fffd3458ca115f32d5fb2cf61"}},"130f2df38c0a45bcb6c0b565aab4f017":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b4aac39b13c8422a9dae80c815578364","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10.2k/10.2k [00:00&lt;00:00, 164kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfd3ae45282641579d56870e2f607c07"}},"e236c445eb8648b4994c13937eb02b62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9dffd63ab8734ffd8ffba1d1a7902ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a291e1e133714e99b4108262ac6c0cbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"24b3690fffd3458ca115f32d5fb2cf61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4aac39b13c8422a9dae80c815578364":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cfd3ae45282641579d56870e2f607c07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f6721e2d96a432c838fdc550e2cb802":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fdeebb7cccc3472e988bee5ad8463117","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_722c610192dc4316be15da59b6c47b26","IPY_MODEL_d39f987a0f1e4891828795c74e49cd29","IPY_MODEL_4eadf00d92c04ec691662b5fedd5deb3"]}},"fdeebb7cccc3472e988bee5ad8463117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"722c610192dc4316be15da59b6c47b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aec8ec5d7034470abde5a201f37b60cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c55574f4141140a48469b0c31c9c69a1"}},"d39f987a0f1e4891828795c74e49cd29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b67bc6fd5ad4ff2a18ec94b00753812","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":612,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":612,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c3beba3594d4fe28bd7a14c682b65af"}},"4eadf00d92c04ec691662b5fedd5deb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_84c6e85374d4447c8adc272594a6b179","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 612/612 [00:00&lt;00:00, 11.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa1f76fdca7b45c1919ea7143e6d0200"}},"aec8ec5d7034470abde5a201f37b60cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c55574f4141140a48469b0c31c9c69a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b67bc6fd5ad4ff2a18ec94b00753812":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c3beba3594d4fe28bd7a14c682b65af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84c6e85374d4447c8adc272594a6b179":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa1f76fdca7b45c1919ea7143e6d0200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54e497109d99459581c2d1c4a284e6b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b66b27280f6a4ab387d8a719834d6b0f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1d00f608a739481a962258a49ebb350b","IPY_MODEL_bbe96c0a95a14430ae610e06c125dd15","IPY_MODEL_b149efbc9d654f7f844671c3549245c1"]}},"b66b27280f6a4ab387d8a719834d6b0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1d00f608a739481a962258a49ebb350b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b2ba097a5f4456da4866bc33da6ba0c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d3d9e6179b8495b9deb1a463bbd3eb5"}},"bbe96c0a95a14430ae610e06c125dd15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b93be0da838d49bd97d1677b3485be57","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":116,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":116,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f622680fa854f6b91f0027fbc079442"}},"b149efbc9d654f7f844671c3549245c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_137ef2463f484949b80773f872aeff91","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 116/116 [00:00&lt;00:00, 2.35kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f19397b33eef4f3b8cf3629ae7148e02"}},"2b2ba097a5f4456da4866bc33da6ba0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2d3d9e6179b8495b9deb1a463bbd3eb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b93be0da838d49bd97d1677b3485be57":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3f622680fa854f6b91f0027fbc079442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"137ef2463f484949b80773f872aeff91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f19397b33eef4f3b8cf3629ae7148e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09b528a1794a49ba9af40e00db856969":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_317de30212154693987b20e3b5a61dc1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_59c044f99d7b46188b82a01f2f7225e7","IPY_MODEL_439f2ae4fa0b45f38f5a67b09caee1b0","IPY_MODEL_d8edbce4c8b049e29226912a3c8df4bd"]}},"317de30212154693987b20e3b5a61dc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59c044f99d7b46188b82a01f2f7225e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ff6b032bb3c4cadb14ecf5b33dbff26","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c41a8b200d7648608187217b0603743c"}},"439f2ae4fa0b45f38f5a67b09caee1b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89d2a8419012483187688e79e619b21a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":39265,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":39265,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81e65d7f05834b1aadeb28681d147db8"}},"d8edbce4c8b049e29226912a3c8df4bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6931d7cd9d2a4c7598154db25ca711b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 39.3k/39.3k [00:00&lt;00:00, 752kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35ed4d5e44264a8ca5cc50d19fdd90aa"}},"7ff6b032bb3c4cadb14ecf5b33dbff26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c41a8b200d7648608187217b0603743c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89d2a8419012483187688e79e619b21a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81e65d7f05834b1aadeb28681d147db8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6931d7cd9d2a4c7598154db25ca711b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"35ed4d5e44264a8ca5cc50d19fdd90aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"910fa093cf4f4b2fa2ec6a0fd095243b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d6e72ac3e0af4bcda409e58e5a44d433","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_36cb522c9e534621a7782d15e75e9260","IPY_MODEL_c7ee615e5a7849b08e16b7486d5054fc","IPY_MODEL_9ac8bd223b99421594e30abc314ea819"]}},"d6e72ac3e0af4bcda409e58e5a44d433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36cb522c9e534621a7782d15e75e9260":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_daae8c1281484d5e8e4c20f3e5d7f653","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4e69c30c36445b48cfc0ca28ff2eee9"}},"c7ee615e5a7849b08e16b7486d5054fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e29be9dc1404f71afc92057275f54fb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":349,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":349,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28ad5c38ff60416aa2bbf99f84470b2b"}},"9ac8bd223b99421594e30abc314ea819":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfd76643d79f4c92b402a58606292393","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 349/349 [00:00&lt;00:00, 9.18kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34ec17e9c84e42a6a5cbc5cf71d170c5"}},"daae8c1281484d5e8e4c20f3e5d7f653":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4e69c30c36445b48cfc0ca28ff2eee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e29be9dc1404f71afc92057275f54fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"28ad5c38ff60416aa2bbf99f84470b2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfd76643d79f4c92b402a58606292393":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"34ec17e9c84e42a6a5cbc5cf71d170c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"503d5d2f93ad4720aeb9a2681547b80b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_29b0955ce1144d0cbbc05aff1f99daeb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9dd590294704dee89cbce72544f604a","IPY_MODEL_0de7021fad1e41e1a45918cc9df4ed51","IPY_MODEL_1d902f95af9d4148bdb0df43a6b0ed6c"]}},"29b0955ce1144d0cbbc05aff1f99daeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9dd590294704dee89cbce72544f604a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cbe87065fd54394be9f5568cb4b366c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c87b2365dae4d12b2a0ed18de65f051"}},"0de7021fad1e41e1a45918cc9df4ed51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ca5f2d88f84d495ea19e048b5620e4ae","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":90888945,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":90888945,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11578e21181f4212a5bf2a855c38e9aa"}},"1d902f95af9d4148bdb0df43a6b0ed6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d53de598c5564950a574df83d3bf9670","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 90.9M/90.9M [00:02&lt;00:00, 44.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb817d98975a488698e5286edc718e0f"}},"6cbe87065fd54394be9f5568cb4b366c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4c87b2365dae4d12b2a0ed18de65f051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca5f2d88f84d495ea19e048b5620e4ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"11578e21181f4212a5bf2a855c38e9aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d53de598c5564950a574df83d3bf9670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb817d98975a488698e5286edc718e0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0298e4e44844048b3f768c4e02d6fa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_126345447ac44cdd808f4d690a07409c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d4c47b71c1d64bee90d30304811092d1","IPY_MODEL_25b37fc82d094c6d875b561bcc5f70ca","IPY_MODEL_08dcc25afdff4303a588ab14d0f2730a"]}},"126345447ac44cdd808f4d690a07409c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4c47b71c1d64bee90d30304811092d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a41424a3683425aa3595c6568ffb5a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e9cb8220645408eaf29f7510579440d"}},"25b37fc82d094c6d875b561bcc5f70ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7586ec0ade1d4998a8a4c7a580fedf7f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":53,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":53,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c63776394cb04a73a915d2197657c16d"}},"08dcc25afdff4303a588ab14d0f2730a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f40f0a4a95c347f08b19ca27bcb134cc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 53.0/53.0 [00:00&lt;00:00, 1.25kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f12a56d0b37e4ab78115453bfbd87679"}},"2a41424a3683425aa3595c6568ffb5a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9e9cb8220645408eaf29f7510579440d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7586ec0ade1d4998a8a4c7a580fedf7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c63776394cb04a73a915d2197657c16d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f40f0a4a95c347f08b19ca27bcb134cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f12a56d0b37e4ab78115453bfbd87679":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd1b583487d74c8cb3b1013e0604e60e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cebf38ce7b26424ea03445aa8c1e2202","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_632b9610dc834bceaa88241996566f86","IPY_MODEL_5401b4e5f3ff40ba96f5c781d4d7d35b","IPY_MODEL_c9e1b5181bf248a8acbea44515ba8ec6"]}},"cebf38ce7b26424ea03445aa8c1e2202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"632b9610dc834bceaa88241996566f86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8e47211d69a4c83b5677afc5347cdae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f4f323a0bdd4a40b232d8bdff728603"}},"5401b4e5f3ff40ba96f5c781d4d7d35b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ab3caee0734438db56db2d2386e3c29","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38239817b1e64a37babd3c665c1c19b1"}},"c9e1b5181bf248a8acbea44515ba8ec6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87bb3bce417947a5b487276ff69740a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 2.78kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0dc6619782334bedbf6e59037e3f43ab"}},"b8e47211d69a4c83b5677afc5347cdae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f4f323a0bdd4a40b232d8bdff728603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ab3caee0734438db56db2d2386e3c29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"38239817b1e64a37babd3c665c1c19b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87bb3bce417947a5b487276ff69740a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0dc6619782334bedbf6e59037e3f43ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ac2b5e90f2b4ab8b20bcff23624c40d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_177bd2aeeba14652aa6c02dfbcfc2c17","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1e3e60faa56c4e8d8c7ec9cced2ccd22","IPY_MODEL_23d85af386cc4050b02a9fcd25333eeb","IPY_MODEL_918d742e16994bfb8fd0966506b53b8f"]}},"177bd2aeeba14652aa6c02dfbcfc2c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e3e60faa56c4e8d8c7ec9cced2ccd22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05a4f0a3973742e2a81acf990b4f93d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8859e8b6b3cd47e4931418672cda7c26"}},"23d85af386cc4050b02a9fcd25333eeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_10285752e08f43c1b11f5e26be22e418","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466247,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466247,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91cd2b182e734470b957b83863768f97"}},"918d742e16994bfb8fd0966506b53b8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2cef2ae31d6f4c0a916f0217684e62d5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 633kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd69925905f3432081b2d350a0928bef"}},"05a4f0a3973742e2a81acf990b4f93d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8859e8b6b3cd47e4931418672cda7c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10285752e08f43c1b11f5e26be22e418":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"91cd2b182e734470b957b83863768f97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2cef2ae31d6f4c0a916f0217684e62d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd69925905f3432081b2d350a0928bef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7462495951e648dd96846771b67c7450":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a84ddb9478f435498303fb7e70c3b28","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72c98a9b436149028097d170a61a2984","IPY_MODEL_f316a115bc4b40849bfeef2910622f15","IPY_MODEL_3186dc18d27447fa81909a9954d5b0ec"]}},"1a84ddb9478f435498303fb7e70c3b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72c98a9b436149028097d170a61a2984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c9f871f9d112403b9f690259a31b40e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3448daf2362a48bebf4fc4caed7b4b33"}},"f316a115bc4b40849bfeef2910622f15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1906fee778f249269411afc2530fa65d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":350,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":350,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_072861dccce549028e0693b9b2bab5b4"}},"3186dc18d27447fa81909a9954d5b0ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a6998243c024a0a8f55b1941ffb265e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 350/350 [00:00&lt;00:00, 7.35kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2365e2289d154433a8eaefc309d388b5"}},"c9f871f9d112403b9f690259a31b40e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3448daf2362a48bebf4fc4caed7b4b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1906fee778f249269411afc2530fa65d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"072861dccce549028e0693b9b2bab5b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a6998243c024a0a8f55b1941ffb265e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2365e2289d154433a8eaefc309d388b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd1fcfaa0965448b9019df9f99c84428":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d4d9e061dc3c4f91a4d5acea41aa4983","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_52eaad8de0954d93ba2b0a6f064c1d7b","IPY_MODEL_f88d01a6a0c641cc855875dda2f33563","IPY_MODEL_a7de38bdd5274113bfadea3e33b15985"]}},"d4d9e061dc3c4f91a4d5acea41aa4983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52eaad8de0954d93ba2b0a6f064c1d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e0348263ba9141ba9afcc6a3a1116351","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f632b8f909414a5894e145494895cc87"}},"f88d01a6a0c641cc855875dda2f33563":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_63db7c99f68549b59b0f173f84a0875e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":13156,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":13156,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8056c0118f7947efaa0500add508f1a0"}},"a7de38bdd5274113bfadea3e33b15985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ff068175eb3545abbe1556fceedee668","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 13.2k/13.2k [00:00&lt;00:00, 298kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a29df5c30d104f2d8961ca04b4c2f203"}},"e0348263ba9141ba9afcc6a3a1116351":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f632b8f909414a5894e145494895cc87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63db7c99f68549b59b0f173f84a0875e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8056c0118f7947efaa0500add508f1a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff068175eb3545abbe1556fceedee668":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a29df5c30d104f2d8961ca04b4c2f203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d05a14a3ec464c95a28a3bda0cf66ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cd08fbd7459742d3a73429535c3edf06","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_987e6c0ade3e465c9c11ee1f9048eed4","IPY_MODEL_30398c37e17d42f9a213a4de6e91663a","IPY_MODEL_d7ac66829b8e448985bcb8e3e4d58464"]}},"cd08fbd7459742d3a73429535c3edf06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"987e6c0ade3e465c9c11ee1f9048eed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ca0db0ff0e4d475c9e631417549f1f9c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8e7aec33dc546318aff8ed85c3d66dc"}},"30398c37e17d42f9a213a4de6e91663a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dbb0b5337b264dc3ab7912d6422e6532","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1abc50f08a9b4e91a7b77a1f47948920"}},"d7ac66829b8e448985bcb8e3e4d58464":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87c6bf72da7e420d926d2cf318ab3e81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 257kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4532cf7ccec447079f60cb7ef754d3fe"}},"ca0db0ff0e4d475c9e631417549f1f9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8e7aec33dc546318aff8ed85c3d66dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbb0b5337b264dc3ab7912d6422e6532":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1abc50f08a9b4e91a7b77a1f47948920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87c6bf72da7e420d926d2cf318ab3e81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4532cf7ccec447079f60cb7ef754d3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60ffa8a42b5a47e5a6cf6a586de31d4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ec837f5ec138400c888095609362819e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_891fe06b5ca84acda4a0f83a0bf826bb","IPY_MODEL_0d66c774e5304bb48b8fafee89580a9e","IPY_MODEL_bb8821bea4114b7d8817557151f55db6"]}},"ec837f5ec138400c888095609362819e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"891fe06b5ca84acda4a0f83a0bf826bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_37a26680ecae4f08af7a3ef4ebf7f5c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e959cdf37314ad1bd42b887b131ce09"}},"0d66c774e5304bb48b8fafee89580a9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3c3ae182806d4d3fa652e12073f09ab7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":190,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":190,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_985b4634830d41ae9fdc771d39ef9e2b"}},"bb8821bea4114b7d8817557151f55db6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b9b63904855f431a98638a3ebb3b4d29","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 190/190 [00:00&lt;00:00, 4.51kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6aabf7a87d6145f9840d3367ecc9f1e3"}},"37a26680ecae4f08af7a3ef4ebf7f5c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6e959cdf37314ad1bd42b887b131ce09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c3ae182806d4d3fa652e12073f09ab7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"985b4634830d41ae9fdc771d39ef9e2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9b63904855f431a98638a3ebb3b4d29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6aabf7a87d6145f9840d3367ecc9f1e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bc6e9e6ac394364b9e66a6eae026620":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_59fdc3dc34a54eaeba08016ef662c012","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d9a24571c6d14357851610b9fdc9a6b7","IPY_MODEL_ba0d5f3828d24a2e8cddc49bae6e5c7b","IPY_MODEL_53f962c6104d4adba5dec0b0c3aa8e19"]}},"59fdc3dc34a54eaeba08016ef662c012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9a24571c6d14357851610b9fdc9a6b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a35e286b487405a9828032d28522083","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80ffbf877c874a47bd8b2cd63acf87cd"}},"ba0d5f3828d24a2e8cddc49bae6e5c7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ed918fbd8a71496388ae6ed297da2dd3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ecf492cd7ba24052b73006b825427f86"}},"53f962c6104d4adba5dec0b0c3aa8e19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_595c2d5f6bac4df2ba7b63d3efab3527","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 298kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_714af14e76444c33bc9b490502e88a46"}},"3a35e286b487405a9828032d28522083":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80ffbf877c874a47bd8b2cd63acf87cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed918fbd8a71496388ae6ed297da2dd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ecf492cd7ba24052b73006b825427f86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"595c2d5f6bac4df2ba7b63d3efab3527":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"714af14e76444c33bc9b490502e88a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b301ee3742742fca9b707fb6a97edd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_21b745160f8e4e6dbc6c2ff6136d717e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e262cc8c9aa14a42893e88f322025b30","IPY_MODEL_31c51224a6674163ab6ebe624e1a6c1f","IPY_MODEL_77dba3719f314978b80e90d6ad451d38"]}},"21b745160f8e4e6dbc6c2ff6136d717e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e262cc8c9aa14a42893e88f322025b30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3acf5bc7544e42efaa0d30cde2b25245","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db157393425c4e7dbc45bb273ef7584e"}},"31c51224a6674163ab6ebe624e1a6c1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b5a91531c55142628146dca7fbc1c2b1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4791279366d543a4bfb82bf932989596"}},"77dba3719f314978b80e90d6ad451d38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_165f8848b5384bbf88ad28ebbda5e206","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 589B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d74206e7d48416b82cffdb7470a2087"}},"3acf5bc7544e42efaa0d30cde2b25245":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db157393425c4e7dbc45bb273ef7584e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5a91531c55142628146dca7fbc1c2b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4791279366d543a4bfb82bf932989596":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"165f8848b5384bbf88ad28ebbda5e206":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6d74206e7d48416b82cffdb7470a2087":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53c78832b0bd4f79b4f24805a87a3b25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8e83e56496b74624b07748a1845c1e08","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_02f153672590426492f117dc9836e676","IPY_MODEL_c3c41da3535048fe9a19ce054a5201e0","IPY_MODEL_03aff828076342b18e11ed2a385ed6ad"]}},"8e83e56496b74624b07748a1845c1e08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02f153672590426492f117dc9836e676":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b3b938cbd2ef46a3ad72fb5973da3978","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be38f540024c42b6886d562a48aa7d2b"}},"c3c41da3535048fe9a19ce054a5201e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d393a83755b541b0a31a1b4a4b5e511a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7118bfd17cf8478bb4372ae76afaeb1d"}},"03aff828076342b18e11ed2a385ed6ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8461b9d3c22f466983bdfea0f56aa470","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 417kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02a95caee1c94a85b60216ae8622a4a9"}},"b3b938cbd2ef46a3ad72fb5973da3978":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be38f540024c42b6886d562a48aa7d2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d393a83755b541b0a31a1b4a4b5e511a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7118bfd17cf8478bb4372ae76afaeb1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8461b9d3c22f466983bdfea0f56aa470":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02a95caee1c94a85b60216ae8622a4a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc4f65a3dfa144b09dc3f921db0cafb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2ce94ecf40ff41389ffb7542d7d61bf1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_64178f1a3cad47c28450c135eacf0a29","IPY_MODEL_f5401de8afd549d78afb4ec530dda602","IPY_MODEL_e601032d250047748b62822eb0f38f4e"]}},"2ce94ecf40ff41389ffb7542d7d61bf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64178f1a3cad47c28450c135eacf0a29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6bb30e515bba44538c947cb70d65394b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce9d70fe1e18419581f5768345faf654"}},"f5401de8afd549d78afb4ec530dda602":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_804c4eba9c9345af9e7d32804a299f14","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":483,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":483,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_470779d6f98b4aa8b34dfbdd6e62af3f"}},"e601032d250047748b62822eb0f38f4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d67d841ec19c422596ee63b9da20d8f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 483/483 [00:00&lt;00:00, 11.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9c54bbea8e9499abc8f13b8f1f7b168"}},"6bb30e515bba44538c947cb70d65394b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce9d70fe1e18419581f5768345faf654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"804c4eba9c9345af9e7d32804a299f14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"470779d6f98b4aa8b34dfbdd6e62af3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d67d841ec19c422596ee63b9da20d8f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9c54bbea8e9499abc8f13b8f1f7b168":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7070bdcf26c48b5b90c7ead1460d249":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_58098a6910954f448cb4590549040cb2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fd4698f33de345e199e26463aac2ebd8","IPY_MODEL_b3589054d7f44c3a885994a97b0a633a","IPY_MODEL_d4538e50c4b640f1b4c5efcbbcc8c778"]}},"58098a6910954f448cb4590549040cb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd4698f33de345e199e26463aac2ebd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_468f3a04cb4a48359a0a7fd0863b53aa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f10cd6db4e154eb6a224f628a602a1f4"}},"b3589054d7f44c3a885994a97b0a633a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ab2e7f2de19a40b1a71d159ce4f907f6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e7d3b0d8d0144a8b620374176990d2f"}},"d4538e50c4b640f1b4c5efcbbcc8c778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f21d7877bc974b6eb97a0edaf90104be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256M/256M [00:07&lt;00:00, 39.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22bff991f8894ee9a6636b39deed2c76"}},"468f3a04cb4a48359a0a7fd0863b53aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f10cd6db4e154eb6a224f628a602a1f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab2e7f2de19a40b1a71d159ce4f907f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e7d3b0d8d0144a8b620374176990d2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f21d7877bc974b6eb97a0edaf90104be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"22bff991f8894ee9a6636b39deed2c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"D4wDuxUrGNQv","executionInfo":{"status":"ok","timestamp":1635268408014,"user_tz":-120,"elapsed":389,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["import pandas as pd\n","import numpy as np\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBX5RM_kvXZ4","executionInfo":{"status":"ok","timestamp":1635254390063,"user_tz":-120,"elapsed":29373,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"9efbc102-ba73-4ec2-96dd-0a47a1fa658b"},"source":["!pip install imbalance-xgboost\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting imbalance-xgboost\n","  Downloading imbalance_xgboost-0.8.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from imbalance-xgboost) (1.19.5)\n","Collecting xgboost>=1.1.1\n","  Downloading xgboost-1.5.0-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n","\u001b[K     |████████████████████████████████| 173.5 MB 42 kB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from imbalance-xgboost) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->imbalance-xgboost) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->imbalance-xgboost) (1.4.1)\n","Installing collected packages: xgboost, imbalance-xgboost\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","Successfully installed imbalance-xgboost-0.8.1 xgboost-1.5.0\n"]}]},{"cell_type":"code","metadata":{"id":"t_Xq5PtJvaTU","executionInfo":{"status":"ok","timestamp":1635268411549,"user_tz":-120,"elapsed":1578,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"92si5Y_UIDe8","executionInfo":{"status":"ok","timestamp":1635268412717,"user_tz":-120,"elapsed":1173,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["from sklearn.svm import LinearSVC\n","from nltk.tokenize import TreebankWordTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.model_selection import cross_validate\n","from sklearn import metrics\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.svm import SVC\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","import sys\n","import argparse\n","import csv\n","from scipy.sparse import *\n","import pandas as pd\n","import regex \n","from sklearn.base import TransformerMixin\n","from nltk.tokenize import TreebankWordTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from nltk.util import ngrams\n","from sklearn.model_selection import StratifiedKFold, train_test_split"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMfAMTyKIQDP","executionInfo":{"status":"ok","timestamp":1635268414416,"user_tz":-120,"elapsed":632,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n","import gensim"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cK9JNL5Ec9w","executionInfo":{"status":"ok","timestamp":1635268415242,"user_tz":-120,"elapsed":5,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"000b93a9-51d6-4002-dc44-004936067f24"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"WpXt7AxEEgH2","executionInfo":{"status":"ok","timestamp":1635268418113,"user_tz":-120,"elapsed":421,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["df=pd.read_csv('/content/drive/MyDrive/Isarcasm/Dataset/train.En.csv')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDaY9QDjEhxn","executionInfo":{"status":"ok","timestamp":1635268418887,"user_tz":-120,"elapsed":5,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["df=df[['tweet','sarcastic']]\n","df.dropna(inplace=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulvrjoMJEj54"},"source":["# train, validate, test = \\\n","#               np.split(df.sample(frac=1, random_state=42), \n","#                        [int(.6*len(df)), int(.8*len(df))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amSUYV6nElxz","executionInfo":{"status":"ok","timestamp":1635267535812,"user_tz":-120,"elapsed":3,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n","bow = bow_vectorizer.fit_transform(df['tweet'])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"rd-GDK8sErTH","executionInfo":{"status":"ok","timestamp":1635254422490,"user_tz":-120,"elapsed":2,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n","tfidf = tfidf_vectorizer.fit_transform(df['tweet'])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xi-IYR_LECd","executionInfo":{"status":"ok","timestamp":1635268044621,"user_tz":-120,"elapsed":1098,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0af688ee-7cb5-4f54-ac71-5a2fc926c9dd"},"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt')\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsKNUm1-E0-t","executionInfo":{"status":"ok","timestamp":1635254441473,"user_tz":-120,"elapsed":15029,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"87bc82d6-9760-4c20-e72b-129c00d5f461"},"source":["tokenized_tweet = df['tweet'].apply(word_tokenize) # tokenizing \n","\n","model_w2v = gensim.models.Word2Vec(\n","            tokenized_tweet,\n","            size=200, # desired no. of features/independent variables\n","            window=5, # context window size\n","            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n","            sg = 1, # 1 for skip-gram model\n","            hs = 0,\n","            negative = 10, # for negative sampling\n","            workers= 32, # no.of cores\n","            seed = 34\n",") \n","\n","model_w2v.train(tokenized_tweet, total_examples= len(df['tweet']), epochs=20)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000350, 1528100)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"JQEJpKKgE9Kt","executionInfo":{"status":"ok","timestamp":1635259113176,"user_tz":-120,"elapsed":908,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["def word_vector(tokens, size):\n","    vec = np.zeros(size).reshape((1, size))\n","    count = 0\n","    for word in tokens:\n","        try:\n","            # print(model_w2v[word].shape)\n","            vec += model_w2v[word].reshape((1, size))\n","            count += 1.\n","        except KeyError:  # handling the case where the token is not in vocabulary\n","            continue\n","    if count != 0:\n","        vec /= count\n","    return vec"],"execution_count":112,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_bxrEEyFAdF","executionInfo":{"status":"ok","timestamp":1635259114716,"user_tz":-120,"elapsed":898,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"e27c80f1-181c-4c3a-ea12-80521d96b5cf"},"source":["wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n","for i in range(len(tokenized_tweet)):\n","    # print(i)\n","    wordvec_arrays[i,:] = word_vector(tokenized_tweet.iloc[i], 200)\n","wordvec_df = pd.DataFrame(wordvec_arrays)"],"execution_count":113,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  import sys\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8Y-Fx_xFBPC","executionInfo":{"status":"ok","timestamp":1635254443859,"user_tz":-120,"elapsed":11,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"9eeeb7b9-b416-419e-f149-580d15e2dd29"},"source":["from tqdm import tqdm \n","tqdm.pandas(desc=\"progress-bar\") \n","from gensim.models.doc2vec import LabeledSentence\n","def add_label(twt):\n","    output = []\n","    for i, s in zip(twt.index, twt):\n","        output.append(LabeledSentence(s, [\"tweet_\" + str(i)]))\n","    return output\n","\n","labeled_tweets = add_label(tokenized_tweet) "],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n","  import sys\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qIeKRxPFJAC","executionInfo":{"status":"ok","timestamp":1635254455296,"user_tz":-120,"elapsed":11443,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"42f29ea0-bacd-432d-a706-3b5801163a4b"},"source":["%%time \n","model_d2v = gensim.models.Doc2Vec(dm=1, # dm = 1 for ‘distributed memory’ model\n","                                  dm_mean=1, # dm_mean = 1 for using mean of the context word vectors\n","                                  vector_size=200, # no. of desired features\n","                                  window=5, # width of the context window                                  \n","                                  negative=7, # if > 0 then negative sampling will be used\n","                                  min_count=5, # Ignores all words with total frequency lower than 5.                                  \n","                                  workers=32, # no. of cores                                  \n","                                  alpha=0.1, # learning rate                                  \n","                                  seed = 23, # for reproducibility\n","                                 ) \n","\n","model_d2v.build_vocab([i for i in tqdm(labeled_tweets)])\n","\n","model_d2v.train(labeled_tweets, total_examples= len(df['tweet']), epochs=15)\n","docvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n","for i in range(len(df)):\n","    docvec_arrays[i,:] = model_d2v.docvecs[i].reshape((1,200))    \n","\n","docvec_df = pd.DataFrame(docvec_arrays) "],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3467/3467 [00:00<00:00, 1342347.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 11.1 s, sys: 2.64 s, total: 13.7 s\n","Wall time: 10 s\n"]}]},{"cell_type":"code","metadata":{"id":"yjs5Two9FXrR","executionInfo":{"status":"ok","timestamp":1635254455297,"user_tz":-120,"elapsed":14,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["xtrain_bow, xtest_bow, ytrain_bow, yvtest_bow = train_test_split(bow, df['sarcastic'], random_state=42, test_size=0.3)\n","xtrain_tfidf, xtest_tfidf, ytrain_tfidf, yvtest_tfidf = train_test_split(tfidf, df['sarcastic'], random_state=42, test_size=0.3)\n","xtrain_wordvec, xtest_wordvec, ytrain_wordvec, yvtest_wordvec = train_test_split(wordvec_df, df['sarcastic'], random_state=42, test_size=0.3)\n","xtrain_docvec, xtest_docvec, ytrain_docvec, yvtest_docvec = train_test_split(docvec_df, df['sarcastic'], random_state=42, test_size=0.3)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOLk604wG_W6","executionInfo":{"status":"ok","timestamp":1635268428222,"user_tz":-120,"elapsed":473,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["from sklearn.svm import SVC\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn import metrics\n","from sklearn import utils\n","import sklearn\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","import xgboost as xgb\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"80Y0DpqRIeLI","executionInfo":{"status":"ok","timestamp":1635268431209,"user_tz":-120,"elapsed":967,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["def print_statistics(y, y_pred):\n","    accuracy = metrics.accuracy_score(y, y_pred)\n","    precision = metrics.precision_score(y, y_pred, average='weighted')\n","    recall = metrics.recall_score(y, y_pred, average='weighted')\n","    f_score = metrics.f1_score(y, y_pred, average='weighted')\n","    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n","          % (accuracy, precision, recall, f_score))\n","    print(metrics.classification_report(y, y_pred))\n","    return accuracy, precision, recall, f_score\n","\n","\n","\n","def plot_coefficients(classifier, feature_names, top_features=20, plot_name=\"/bow_models/bow_binary_\"):\n","    # Get the top most positive/negative coefficients\n","    coef = classifier.coef_.ravel()\n","    top_positive_coefficients = np.argsort(coef)[-top_features:]\n","    top_negative_coefficients = np.argsort(coef)[:top_features]\n","    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n","    x_names = [feature_names[feature] for feature in top_coefficients]\n","\n","    # Plot the coefficients\n","    plt.figure(figsize=(15, 5))\n","    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n","    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n","    plt.xticks(np.arange(0, 2 * top_features), x_names, rotation=30, ha='right')\n","    plt.ylabel(\"Coefficient Value\")\n","    plt.title(\"Visualising the top %d features taken up by an SVM model\" % top_features)\n","    to_save_filename = path + \"/plots/\" + plot_name + \"top%d_coefficients.png\" % top_features\n","    plt.savefig(to_save_filename)\n","    print(\"Coefficients' visualisation saved to %s\\n\" % to_save_filename)\n","\n","def get_regularization_params(a=-1, b=1, c=3, d=1, e=5):\n","    reg_range = np.outer(np.logspace(a, b, c), np.array([d, e]))\n","    reg_range = reg_range.flatten()\n","    return reg_range\n","\n","\n","def grid_classifier(x_train, y_train, x_test, y_test, model, parameters,\n","                    make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n","    grid = GridSearchCV(estimator=model, param_grid=parameters, verbose=0)\n","    grid.fit(x_train, y_train)\n","    sorted(grid.cv_results_.keys())\n","    classifier = grid.best_estimator_\n","    if make_feature_analysis:\n","        plot_coefficients(classifier, feature_names, top_features, plot_name)\n","    y_hat = classifier.predict(x_test)\n","    print_statistics(y_test, y_hat)\n","\n","# Method to print the header of the currently running model\n","def print_model_title(name):\n","    print(\"\\n==================================================================\")\n","    print('{:>20}'.format(name))\n","    print(\"==================================================================\\n\")\n","\n","\n","def linear_svm_grid(x_train, y_train, x_test, y_test, class_ratio,\n","               make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n","    print_model_title(\"Linear SVM\")\n","    C_range = get_regularization_params()\n","    parameters = {'C': C_range}\n","    linear_svm = LinearSVC(C=1.0, class_weight=class_ratio, penalty='l2')\n","    grid_classifier(x_train, y_train, x_test, y_test, linear_svm, parameters,\n","                    make_feature_analysis, feature_names, top_features, plot_name)\n","\n","\n","def nonlinear_svm_grid(x_train, y_train, x_test, y_test, class_ratio,\n","                  make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n","    print_model_title(\"Nonlinear SVM\")\n","    C_range = get_regularization_params(a=-1, b=0, c=2, d=1, e=5)\n","    gamma_range = get_regularization_params(a=-2, b=-1, c=2, d=1, e=5)\n","    parameters = {'kernel': ['rbf'], 'C': C_range, 'gamma': gamma_range}\n","    nonlinear_svm = SVC(class_weight=class_ratio)\n","    grid_classifier(x_train, y_train, x_test, y_test, nonlinear_svm, parameters,\n","                    make_feature_analysis, feature_names, top_features, plot_name)\n","\n","\n","def logistic_regression_grid(x_train, y_train, x_test, y_test, class_ratio,\n","                        make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n","    print_model_title(\"Logistic Regression\")\n","    C_range = [0.001, 0.01, 0.1, 1, 10, 100]\n","    parameters = {'C': C_range}\n","    log_regr = LogisticRegression(C=1.0, class_weight=class_ratio, penalty='l2')\n","    grid_classifier(x_train, y_train, x_test, y_test, log_regr, parameters,\n","                    make_feature_analysis, feature_names, top_features, plot_name)\n","\n","\n","def linear_svm(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n","    print_model_title(\"Linear SVM\")\n","    svm = LinearSVC(C=0.01, class_weight=class_ratio, penalty='l2')\n","    svm.fit(x_train, y_train)\n","    y_hat = svm.predict(x_test)\n","    print_statistics(y_test, y_hat)\n","    # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/svm_model_bin.sav'\n","    # joblib.dump(svm, filename)\n","\n","\n","def logistic_regression(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n","    print_model_title(\"Logistic Regression\")\n","    regr = LogisticRegression(C=0.01, class_weight=class_ratio, penalty='l2')\n","    regr.fit(x_train, y_train)\n","    y_hat = regr.predict(x_test)\n","    print_statistics(y_test, y_hat)\n","    # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","    # joblib.dump(regr, filename)\n","\n","\n","def random_forest(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n","  print_model_title(\"Random Forest\")\n","  rf = RandomForestClassifier(n_estimators=400, random_state=11)\n","  rf.fit(x_train, y_train)\n","  y_hat = rf.predict(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","def xg_boost(x_train, y_train, x_test, y_test):\n","  print_model_title(\"XGBoost\")\n","  xgb_model =XGBClassifier(max_depth=6, n_estimators=1000)\n","  xgb_model .fit(x_train, y_train)\n","  y_hat = xgb_model .predict(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","\n","def xg_boost_focal_loss(x_train, y_train, x_test, y_test):\n","  print_model_title(\"XGBoost Focal\")\n","  xgboster_focal = imb_xgb(special_objective='focal')\n","  CV_focal_booster = GridSearchCV(xgboster_focal, {\"focal_gamma\":[1.0,1.5,2.0,2.5,3.0]})\n","  CV_focal_booster.fit(x_train, y_train)\n","  opt_focal_booster = CV_focal_booster.best_estimator_\n","  # xgb_model .fit(x_train, y_train)\n","  y_hat = opt_focal_booster.predict_determine(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","def xg_boost_weighted_loss(x_train, y_train, x_test, y_test):\n","  print_model_title(\"XGBoost Weighted\")\n","  xgboster_focal = imb_xgb(special_objective='weighted')\n","  CV_focal_booster = GridSearchCV(xgboster_focal, {\"imbalance_alpha\":[1.5,2.0,2.5,3.0,4.0]})\n","  CV_focal_booster.fit(x_train, y_train)\n","  opt_focal_booster = CV_focal_booster.best_estimator_\n","  # xgb_model .fit(x_train, y_train)\n","  y_hat = opt_focal_booster.predict_determine(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","\n","def feature_selection(x_train, y_train, x_test, y_test):\n","    print(\"Feature selection with LinearSVC\")\n","    model = LinearSVC(C=0.1, penalty='l2')\n","    rfe = RFE(model, 5)\n","    best_features_model = rfe.fit(x_train, y_train)\n","    y_hat = best_features_model.predict(x_test)\n","    print_statistics(y_test, y_hat)\n","\n","\n","def ensemble_stacked(x_train, y_train, x_test, y_test):\n","  print_model_title(\"Ensemble Stacked Classifiers\")\n","  estimators = [ ('lr',LogisticRegression(C=0.01, class_weight='balanced', penalty='l2')),('xgb',XGBClassifier(max_depth=16, n_estimators=1000)),('svm_linear',LinearSVC(C=0.01, class_weight='balanced', penalty='l2')),('rf', RandomForestClassifier(n_estimators=10, random_state=42))]\n","  from sklearn.ensemble import StackingClassifier\n","  clf = StackingClassifier(\n","      estimators=estimators )\n","  clf.fit(x_train, y_train)\n","  y_hat = clf .predict(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","\n","\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","def voting_classifiers(x_train, y_train, x_test, y_test,voting_type='hard'):\n","  print_model_title(\"Voting Classifier\")\n","  estimators = [ ('lr',LogisticRegression(C=0.01, class_weight='balanced', penalty='l2')),('xgb',XGBClassifier(max_depth=16, n_estimators=1000)),('svm_linear',LinearSVC(C=0.01, class_weight='balanced', penalty='l2')),('rf', RandomForestClassifier(n_estimators=10, random_state=42))]\n","  from sklearn.ensemble import StackingClassifier\n","  clf = VotingClassifier(\n","      estimators=estimators , voting=voting_type)\n","  clf.fit(x_train, y_train)\n","  y_hat = clf .predict(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","\n","\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.ensemble import BaggingClassifier\n","def Bagging_Classifier_LR(x_train, y_train, x_test, y_test):\n","  print_model_title(\"Bagging Calssifier LR\")\n"," \n","  clf =BaggingClassifier(base_estimator=LogisticRegression(C=0.01, class_weight='balanced', penalty='l2'),\n","                       n_estimators=10, random_state=42)\n","  clf.fit(x_train, y_train)\n","  y_hat = clf .predict(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","\n","def Bagging_Classifier_SVM(x_train, y_train, x_test, y_test):\n","  print_model_title(\"Bagging Calssifier SVM\")\n"," \n","  clf =BaggingClassifier(base_estimator=LinearSVC(C=0.01, class_weight='balanced', penalty='l2'),\n","                       n_estimators=10, random_state=42)\n","  clf.fit(x_train, y_train)\n","  y_hat = clf .predict(x_test)\n","  print_statistics(y_test, y_hat)\n","  # filename = '/content/drive/MyDrive/Omdena_dialect_identification/Saved_models/lr_model_bin.sav'\n","  # joblib.dump(regr, filename)\n","\n","\n","from sklearn.ensemble import GradientBoostingClassifier\n","def gradient_boosting(x_train, y_train, x_test, y_test):\n","  print_model_title(\"Gradient Boosting\")\n"," \n","  clf =GradientBoostingClassifier(n_estimators=100, learning_rate=0.01,max_depth=30, random_state=42)\n","  clf.fit(x_train, y_train)\n","  y_hat = clf .predict(x_test)\n","  print_statistics(y_test, y_hat)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDm7gcw4NH9I","executionInfo":{"status":"ok","timestamp":1635254556862,"user_tz":-120,"elapsed":420,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["xtrain_bow, xtest_bow, ytrain_bow, yvtest_bow = train_test_split(bow, df['sarcastic'], random_state=42, test_size=0.3)\n","xtrain_tfidf, xtest_tfidf, ytrain_tfidf, yvtest_tfidf = train_test_split(tfidf, df['sarcastic'], random_state=42, test_size=0.3)\n","xtrain_wordvec, xtest_wordvec, ytrain_wordvec, yvtest_wordvec = train_test_split(wordvec_df, df['sarcastic'], random_state=42, test_size=0.3)\n","xtrain_docvec, xtest_docvec, ytrain_docvec, yvtest_docvec = train_test_split(docvec_df, df['sarcastic'], random_state=42, test_size=0.3)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4whhkKyM21a","executionInfo":{"status":"ok","timestamp":1635254561679,"user_tz":-120,"elapsed":1650,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"c62c9bd9-9ab2-40b5-81f9-7c8ac610e15e"},"source":["linear_svm_grid(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow,class_ratio='balanced')"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.605\n","Precision: 0.635\n","Recall: 0.605\n","F_score: 0.617\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.68      0.71       754\n","           1       0.33      0.41      0.36       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.54      0.55      0.54      1041\n","weighted avg       0.63      0.61      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PpYLfLWWNYvj","executionInfo":{"status":"ok","timestamp":1635254562302,"user_tz":-120,"elapsed":639,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"36c143ee-951a-444a-f922-8dd88df634f8"},"source":["linear_svm_grid(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf,class_ratio='balanced')"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.605\n","Precision: 0.635\n","Recall: 0.605\n","F_score: 0.617\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.68      0.71       754\n","           1       0.33      0.41      0.36       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.54      0.55      0.54      1041\n","weighted avg       0.63      0.61      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXE2Nbm1NfhR","executionInfo":{"status":"ok","timestamp":1635254586508,"user_tz":-120,"elapsed":24209,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"7876c635-701e-41a5-bf38-3d2cd7fc8ac7"},"source":["linear_svm_grid(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec,class_ratio='balanced')"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.611\n","Precision: 0.641\n","Recall: 0.611\n","F_score: 0.623\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.68      0.72       754\n","           1       0.34      0.43      0.38       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.55      0.55      0.55      1041\n","weighted avg       0.64      0.61      0.62      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOQ3-U7ANpsB","executionInfo":{"status":"ok","timestamp":1635254614184,"user_tz":-120,"elapsed":27695,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"6c93b7c1-6b5e-4442-adf4-fb7222844a17"},"source":["linear_svm_grid(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec,class_ratio='balanced')"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.660\n","Precision: 0.633\n","Recall: 0.660\n","F_score: 0.644\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.81      0.78       754\n","           1       0.35      0.26      0.30       287\n","\n","    accuracy                           0.66      1041\n","   macro avg       0.54      0.54      0.54      1041\n","weighted avg       0.63      0.66      0.64      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"TNA7odECPWRY","executionInfo":{"status":"ok","timestamp":1635254614186,"user_tz":-120,"elapsed":10,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioIlem_sOAUU","executionInfo":{"status":"ok","timestamp":1635254645437,"user_tz":-120,"elapsed":31260,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"32505d69-83fc-4695-f3cc-25516b3d230e"},"source":["nonlinear_svm_grid(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow,class_ratio='balanced')"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.713\n","Precision: 0.643\n","Recall: 0.713\n","F_score: 0.640\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.95      0.83       754\n","           1       0.41      0.09      0.15       287\n","\n","    accuracy                           0.71      1041\n","   macro avg       0.57      0.52      0.49      1041\n","weighted avg       0.64      0.71      0.64      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6C-2NAAAOCWX","executionInfo":{"status":"ok","timestamp":1635254677520,"user_tz":-120,"elapsed":32095,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"89a656dc-9ab0-4752-c122-5d5bf724c154"},"source":["nonlinear_svm_grid(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf,class_ratio='balanced')"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.672\n","Precision: 0.645\n","Recall: 0.672\n","F_score: 0.656\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.82      0.78       754\n","           1       0.37      0.28      0.32       287\n","\n","    accuracy                           0.67      1041\n","   macro avg       0.56      0.55      0.55      1041\n","weighted avg       0.65      0.67      0.66      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uadaQaPoOEx7","executionInfo":{"status":"ok","timestamp":1635254805308,"user_tz":-120,"elapsed":127802,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"2fd1081b-e25a-4b75-bd87-07fe246cdfd9"},"source":["nonlinear_svm_grid(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec,class_ratio='balanced')"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.611\n","Precision: 0.635\n","Recall: 0.611\n","F_score: 0.621\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.69      0.72       754\n","           1       0.33      0.40      0.36       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.54      0.54      0.54      1041\n","weighted avg       0.63      0.61      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gnZ9LoPOIfZ","executionInfo":{"status":"ok","timestamp":1635254933203,"user_tz":-120,"elapsed":127904,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fd4b5451-357f-4f93-956a-a7dd05001ee2"},"source":["nonlinear_svm_grid(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec,class_ratio='balanced')"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.684\n","Precision: 0.629\n","Recall: 0.684\n","F_score: 0.644\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.88      0.80       754\n","           1       0.35      0.17      0.23       287\n","\n","    accuracy                           0.68      1041\n","   macro avg       0.54      0.53      0.52      1041\n","weighted avg       0.63      0.68      0.64      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"Buxphn_GPVpy","executionInfo":{"status":"ok","timestamp":1635254933206,"user_tz":-120,"elapsed":31,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crqDWQYqOQ2s","executionInfo":{"status":"ok","timestamp":1635254934328,"user_tz":-120,"elapsed":1147,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"1d15054b-6dc1-4c5e-d0c1-c46172b7a562"},"source":["logistic_regression_grid(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow,class_ratio='balanced')"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.613\n","Precision: 0.638\n","Recall: 0.613\n","F_score: 0.624\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.69      0.72       754\n","           1       0.33      0.41      0.37       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.54      0.55      0.54      1041\n","weighted avg       0.64      0.61      0.62      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTJGzAJGORCl","executionInfo":{"status":"ok","timestamp":1635254935402,"user_tz":-120,"elapsed":1114,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0dee7b08-cece-4ead-ec57-5b495125cd6b"},"source":["logistic_regression_grid(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf,class_ratio='balanced')"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.600\n","Precision: 0.626\n","Recall: 0.600\n","F_score: 0.611\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.68      0.71       754\n","           1       0.32      0.38      0.35       287\n","\n","    accuracy                           0.60      1041\n","   macro avg       0.53      0.53      0.53      1041\n","weighted avg       0.63      0.60      0.61      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvwcqvZ8ORN1","executionInfo":{"status":"ok","timestamp":1635254937892,"user_tz":-120,"elapsed":2505,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"50da508f-647d-4c55-80cc-b2ec3bc1b840"},"source":["logistic_regression_grid(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec,class_ratio='balanced')"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.575\n","Precision: 0.648\n","Recall: 0.575\n","F_score: 0.597\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.59      0.67       754\n","           1       0.33      0.53      0.41       287\n","\n","    accuracy                           0.58      1041\n","   macro avg       0.55      0.56      0.54      1041\n","weighted avg       0.65      0.58      0.60      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMEHxp36ORZX","executionInfo":{"status":"ok","timestamp":1635254939790,"user_tz":-120,"elapsed":1915,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"f0c969e9-edd6-44c3-e541-38d44fda5c3f"},"source":["logistic_regression_grid(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec,class_ratio='balanced')"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.592\n","Precision: 0.642\n","Recall: 0.592\n","F_score: 0.610\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.64      0.69       754\n","           1       0.33      0.47      0.39       287\n","\n","    accuracy                           0.59      1041\n","   macro avg       0.55      0.56      0.54      1041\n","weighted avg       0.64      0.59      0.61      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"id":"0hV_OPq-O7kx","executionInfo":{"status":"ok","timestamp":1635254939790,"user_tz":-120,"elapsed":35,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3z50_-VO7u7","executionInfo":{"status":"ok","timestamp":1635254939791,"user_tz":-120,"elapsed":33,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"4c7cd537-9cf1-4439-d9c4-9d10dde22842"},"source":["linear_svm(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow,class_ratio='balanced')"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.617\n","Precision: 0.644\n","Recall: 0.617\n","F_score: 0.628\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.69      0.72       754\n","           1       0.34      0.42      0.38       287\n","\n","    accuracy                           0.62      1041\n","   macro avg       0.55      0.56      0.55      1041\n","weighted avg       0.64      0.62      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FyFtVkKO74R","executionInfo":{"status":"ok","timestamp":1635254939791,"user_tz":-120,"elapsed":26,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"06ca838a-a912-4455-d304-aeeeb18dedd7"},"source":["linear_svm(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf,class_ratio='balanced')"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.601\n","Precision: 0.643\n","Recall: 0.601\n","F_score: 0.617\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.66      0.70       754\n","           1       0.34      0.46      0.39       287\n","\n","    accuracy                           0.60      1041\n","   macro avg       0.55      0.56      0.55      1041\n","weighted avg       0.64      0.60      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34D2nTzFO8Bi","executionInfo":{"status":"ok","timestamp":1635254939792,"user_tz":-120,"elapsed":23,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"251fce69-d923-41b8-80b1-339351ada2b2"},"source":["linear_svm(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec,class_ratio='balanced')"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.572\n","Precision: 0.653\n","Recall: 0.572\n","F_score: 0.594\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.58      0.66       754\n","           1       0.33      0.56      0.42       287\n","\n","    accuracy                           0.57      1041\n","   macro avg       0.55      0.57      0.54      1041\n","weighted avg       0.65      0.57      0.59      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5KUiTr6O8Mx","executionInfo":{"status":"ok","timestamp":1635254939792,"user_tz":-120,"elapsed":20,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"ea8991fc-ffba-49da-b689-ec4df79ba679"},"source":["linear_svm(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec,class_ratio='balanced')"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.553\n","Precision: 0.631\n","Recall: 0.553\n","F_score: 0.576\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.57      0.65       754\n","           1       0.31      0.51      0.39       287\n","\n","    accuracy                           0.55      1041\n","   macro avg       0.53      0.54      0.52      1041\n","weighted avg       0.63      0.55      0.58      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"wyIpDNOUPDpC","executionInfo":{"status":"ok","timestamp":1635254939792,"user_tz":-120,"elapsed":16,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwUXd872PEM1","executionInfo":{"status":"ok","timestamp":1635254939792,"user_tz":-120,"elapsed":16,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"5ca1fbd0-f864-4c4c-e7b8-5340e3ec08b3"},"source":["logistic_regression(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow,class_ratio='balanced')"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.614\n","Precision: 0.645\n","Recall: 0.614\n","F_score: 0.626\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.68      0.72       754\n","           1       0.34      0.44      0.38       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.55      0.56      0.55      1041\n","weighted avg       0.65      0.61      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osBdhM4SPET6","executionInfo":{"status":"ok","timestamp":1635254939793,"user_tz":-120,"elapsed":13,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fdf85383-6b55-4c1e-be08-9bea8f1b83b0"},"source":["logistic_regression(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf,class_ratio='balanced')"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.602\n","Precision: 0.649\n","Recall: 0.602\n","F_score: 0.619\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.65      0.70       754\n","           1       0.34      0.48      0.40       287\n","\n","    accuracy                           0.60      1041\n","   macro avg       0.55      0.56      0.55      1041\n","weighted avg       0.65      0.60      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDJKXpzTPEb2","executionInfo":{"status":"ok","timestamp":1635254939793,"user_tz":-120,"elapsed":11,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"8111f894-fbad-4996-c55c-f98dd7140810"},"source":["logistic_regression(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec,class_ratio='balanced')"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.546\n","Precision: 0.640\n","Recall: 0.546\n","F_score: 0.570\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.54      0.63       754\n","           1       0.32      0.56      0.41       287\n","\n","    accuracy                           0.55      1041\n","   macro avg       0.54      0.55      0.52      1041\n","weighted avg       0.64      0.55      0.57      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZcqLWXAIPEtK","executionInfo":{"status":"ok","timestamp":1635254939793,"user_tz":-120,"elapsed":9,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"333b9fff-6bc6-4109-b9d9-458ed1f3a00f"},"source":["logistic_regression(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec,class_ratio='balanced')"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.568\n","Precision: 0.642\n","Recall: 0.568\n","F_score: 0.590\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.58      0.66       754\n","           1       0.32      0.52      0.40       287\n","\n","    accuracy                           0.57      1041\n","   macro avg       0.54      0.55      0.53      1041\n","weighted avg       0.64      0.57      0.59      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"ZsIzw7ZRPT7C","executionInfo":{"status":"ok","timestamp":1635254940334,"user_tz":-120,"elapsed":5,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpYCW-7aPXZS","executionInfo":{"status":"ok","timestamp":1635256771192,"user_tz":-120,"elapsed":5729,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fac692db-89db-44f6-f372-b1fcc03bed0c"},"source":["random_forest(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf,class_ratio='balanced')"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.698\n","Precision: 0.623\n","Recall: 0.698\n","F_score: 0.634\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.93      0.82       754\n","           1       0.34      0.10      0.16       287\n","\n","    accuracy                           0.70      1041\n","   macro avg       0.54      0.51      0.49      1041\n","weighted avg       0.62      0.70      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-XzxknVPXig","executionInfo":{"status":"ok","timestamp":1635254951109,"user_tz":-120,"elapsed":5737,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0fdb54d6-d084-47fd-8fae-67759c68fe5f"},"source":["random_forest(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow,class_ratio='balanced')"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.650\n","Precision: 0.619\n","Recall: 0.650\n","F_score: 0.631\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.81      0.77       754\n","           1       0.32      0.23      0.27       287\n","\n","    accuracy                           0.65      1041\n","   macro avg       0.53      0.52      0.52      1041\n","weighted avg       0.62      0.65      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Deh1bUynPXtC","executionInfo":{"status":"ok","timestamp":1635254964253,"user_tz":-120,"elapsed":13173,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"331c81f7-b7bc-4e30-b44f-83b65412d0be"},"source":["random_forest(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec,class_ratio='balanced')"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.722\n","Precision: 0.629\n","Recall: 0.722\n","F_score: 0.613\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.99      0.84       754\n","           1       0.38      0.01      0.02       287\n","\n","    accuracy                           0.72      1041\n","   macro avg       0.55      0.50      0.43      1041\n","weighted avg       0.63      0.72      0.61      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3J7x1qCPX3w","executionInfo":{"status":"ok","timestamp":1635254977209,"user_tz":-120,"elapsed":12961,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"755d7989-bbac-4dbe-a2d9-cb4e26aee2cd"},"source":["random_forest(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec,class_ratio='balanced')"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.725\n","Precision: 0.709\n","Recall: 0.725\n","F_score: 0.613\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      1.00      0.84       754\n","           1       0.67      0.01      0.01       287\n","\n","    accuracy                           0.73      1041\n","   macro avg       0.70      0.50      0.43      1041\n","weighted avg       0.71      0.73      0.61      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"6mhhLUJBQCoL","executionInfo":{"status":"ok","timestamp":1635254977210,"user_tz":-120,"elapsed":33,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZIQu0UkQCzC","executionInfo":{"status":"ok","timestamp":1635254984590,"user_tz":-120,"elapsed":7410,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"7bfa5e26-8b96-46cc-bd39-5c2f9fb6ff2d"},"source":["xg_boost(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow)"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n","[13:29:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.692\n","Precision: 0.650\n","Recall: 0.692\n","F_score: 0.661\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.87      0.80       754\n","           1       0.40      0.23      0.29       287\n","\n","    accuracy                           0.69      1041\n","   macro avg       0.57      0.55      0.55      1041\n","weighted avg       0.65      0.69      0.66      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6Q7PFwAQC67","executionInfo":{"status":"ok","timestamp":1635256788456,"user_tz":-120,"elapsed":9468,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"683e8eb6-27c5-4ecd-8d75-2e9cee0635bc"},"source":["xg_boost(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf)"],"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n","[13:59:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.680\n","Precision: 0.637\n","Recall: 0.680\n","F_score: 0.650\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.86      0.80       754\n","           1       0.36      0.21      0.27       287\n","\n","    accuracy                           0.68      1041\n","   macro avg       0.55      0.54      0.53      1041\n","weighted avg       0.64      0.68      0.65      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ejo2Nbw9QDCN","executionInfo":{"status":"ok","timestamp":1635255038215,"user_tz":-120,"elapsed":46917,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"ed6ec845-ec0d-4cc1-fc76-82a87dbca0c7"},"source":["xg_boost(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec)"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n","[13:29:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.705\n","Precision: 0.615\n","Recall: 0.705\n","F_score: 0.625\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.95      0.82       754\n","           1       0.32      0.06      0.10       287\n","\n","    accuracy                           0.71      1041\n","   macro avg       0.52      0.51      0.46      1041\n","weighted avg       0.62      0.71      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R41SNnNCQDPQ","executionInfo":{"status":"ok","timestamp":1635255079073,"user_tz":-120,"elapsed":40870,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"394a66b8-cf65-4fc8-b89b-9b9429fe8b81"},"source":["xg_boost(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n","[13:30:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.699\n","Precision: 0.603\n","Recall: 0.699\n","F_score: 0.621\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.94      0.82       754\n","           1       0.28      0.06      0.10       287\n","\n","    accuracy                           0.70      1041\n","   macro avg       0.50      0.50      0.46      1041\n","weighted avg       0.60      0.70      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"rSRTmfza2vQe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQppCG0HwupG","executionInfo":{"status":"ok","timestamp":1635256042273,"user_tz":-120,"elapsed":12832,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"f9ce4428-fecb-478c-f1f4-9c18a2248344"},"source":["xg_boost_focal_loss(xtrain_tfidf,ytrain_tfidf.to_numpy(),xtest_tfidf,yvtest_tfidf.to_numpy())"],"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       XGBoost Focal\n","==================================================================\n","\n","Accuracy: 0.716\n","Precision: 0.634\n","Recall: 0.716\n","F_score: 0.628\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.97      0.83       754\n","           1       0.38      0.05      0.09       287\n","\n","    accuracy                           0.72      1041\n","   macro avg       0.56      0.51      0.46      1041\n","weighted avg       0.63      0.72      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Za6traW6wupH","executionInfo":{"status":"ok","timestamp":1635256060636,"user_tz":-120,"elapsed":13434,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"c2d534e5-66f2-4713-8561-fdf4e3b20cd1"},"source":["xg_boost_focal_loss(xtrain_bow,ytrain_bow.to_numpy(),xtest_bow,yvtest_bow.to_numpy())"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       XGBoost Focal\n","==================================================================\n","\n","Accuracy: 0.718\n","Precision: 0.631\n","Recall: 0.718\n","F_score: 0.623\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.98      0.83       754\n","           1       0.38      0.04      0.07       287\n","\n","    accuracy                           0.72      1041\n","   macro avg       0.55      0.51      0.45      1041\n","weighted avg       0.63      0.72      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"t3uNsC6PwvBQ","executionInfo":{"status":"aborted","timestamp":1635255079681,"user_tz":-120,"elapsed":616,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OhK4v8gwvIB","executionInfo":{"status":"aborted","timestamp":1635255079682,"user_tz":-120,"elapsed":617,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjLXjWcnwvIC","executionInfo":{"status":"ok","timestamp":1635256115539,"user_tz":-120,"elapsed":11786,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"4edfd1d6-59c1-489c-ef6e-d980ed39cd60"},"source":["xg_boost_weighted_loss(xtrain_bow,ytrain_bow.to_numpy(),xtest_bow,yvtest_bow.to_numpy())"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","    XGBoost Weighted\n","==================================================================\n","\n","Accuracy: 0.720\n","Precision: 0.653\n","Recall: 0.720\n","F_score: 0.637\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.97      0.83       754\n","           1       0.44      0.07      0.12       287\n","\n","    accuracy                           0.72      1041\n","   macro avg       0.59      0.52      0.48      1041\n","weighted avg       0.65      0.72      0.64      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZg5KD1-wvIC","executionInfo":{"status":"ok","timestamp":1635256134323,"user_tz":-120,"elapsed":12771,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"1aec933f-796e-4a65-9906-ada5fdc5bd4b"},"source":["xg_boost_weighted_loss(xtrain_tfidf,ytrain_tfidf.to_numpy(),xtest_tfidf,yvtest_tfidf.to_numpy())"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","    XGBoost Weighted\n","==================================================================\n","\n","Accuracy: 0.710\n","Precision: 0.623\n","Recall: 0.710\n","F_score: 0.627\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.96      0.83       754\n","           1       0.35      0.06      0.10       287\n","\n","    accuracy                           0.71      1041\n","   macro avg       0.54      0.51      0.46      1041\n","weighted avg       0.62      0.71      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"s8Wr4thx30Wx","executionInfo":{"status":"ok","timestamp":1635256483640,"user_tz":-120,"elapsed":408,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71kf4kRR4cpA","executionInfo":{"status":"ok","timestamp":1635256878393,"user_tz":-120,"elapsed":56410,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"01aec3ba-87cd-4d85-8084-33a8461f950d"},"source":["ensemble_stacked(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow)"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n","[14:00:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:00:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:00:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:00:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:00:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:01:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.728\n","Precision: 0.757\n","Recall: 0.728\n","F_score: 0.619\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      1.00      0.84       754\n","           1       0.83      0.02      0.03       287\n","\n","    accuracy                           0.73      1041\n","   macro avg       0.78      0.51      0.44      1041\n","weighted avg       0.76      0.73      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PoRSs0i4wti","executionInfo":{"status":"ok","timestamp":1635257019359,"user_tz":-120,"elapsed":70571,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"cb2312ef-5d70-4e3f-a99d-4e612b6b7356"},"source":["ensemble_stacked(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf)"],"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n","[14:02:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:02:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:02:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:03:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:03:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:03:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.725\n","Precision: 0.801\n","Recall: 0.725\n","F_score: 0.611\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.72      1.00      0.84       754\n","           1       1.00      0.00      0.01       287\n","\n","    accuracy                           0.73      1041\n","   macro avg       0.86      0.50      0.42      1041\n","weighted avg       0.80      0.73      0.61      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1nlKlTu5mAO","executionInfo":{"status":"ok","timestamp":1635257236931,"user_tz":-120,"elapsed":214650,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"da40cfd6-bc61-4f48-ad1b-180b741e05bd"},"source":["ensemble_stacked(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec)"],"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:03:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:04:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:05:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:05:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:06:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:06:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.724\n","Precision: 0.525\n","Recall: 0.724\n","F_score: 0.608\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.72      1.00      0.84       754\n","           1       0.00      0.00      0.00       287\n","\n","    accuracy                           0.72      1041\n","   macro avg       0.36      0.50      0.42      1041\n","weighted avg       0.52      0.72      0.61      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7udurqm5qXr","executionInfo":{"status":"ok","timestamp":1635257429880,"user_tz":-120,"elapsed":192957,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"cfca32ea-80b0-465a-f763-06c086bc8ef4"},"source":["ensemble_stacked(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec)"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n","[14:07:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:07:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:08:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:08:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:09:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[14:09:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.724\n","Precision: 0.525\n","Recall: 0.724\n","F_score: 0.608\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.72      1.00      0.84       754\n","           1       0.00      0.00      0.00       287\n","\n","    accuracy                           0.72      1041\n","   macro avg       0.36      0.50      0.42      1041\n","weighted avg       0.52      0.72      0.61      1041\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"id":"0naahrzd6OjI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gOEJJ8N6Os9","executionInfo":{"status":"ok","timestamp":1635257454004,"user_tz":-120,"elapsed":10883,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"95ef3a23-ab6e-4181-84f7-00307ea4b725"},"source":["voting_classifiers(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow)"],"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n","[14:10:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.681\n","Precision: 0.646\n","Recall: 0.681\n","F_score: 0.657\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.85      0.79       754\n","           1       0.38      0.25      0.30       287\n","\n","    accuracy                           0.68      1041\n","   macro avg       0.56      0.55      0.55      1041\n","weighted avg       0.65      0.68      0.66      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28t_lRJE6RBL","executionInfo":{"status":"ok","timestamp":1635257469287,"user_tz":-120,"elapsed":13710,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"61e96f92-c1b3-41aa-af3c-b36eb39acfd7"},"source":["voting_classifiers(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf)"],"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n","[14:10:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.670\n","Precision: 0.630\n","Recall: 0.670\n","F_score: 0.644\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.84      0.79       754\n","           1       0.34      0.22      0.27       287\n","\n","    accuracy                           0.67      1041\n","   macro avg       0.54      0.53      0.53      1041\n","weighted avg       0.63      0.67      0.64      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BK_CFlf6SfY","executionInfo":{"status":"ok","timestamp":1635257516168,"user_tz":-120,"elapsed":46903,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"1b28825d-cd69-41a1-aa1f-90bf5c332f53"},"source":["voting_classifiers(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec)"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:11:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.699\n","Precision: 0.607\n","Recall: 0.699\n","F_score: 0.623\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.94      0.82       754\n","           1       0.30      0.07      0.11       287\n","\n","    accuracy                           0.70      1041\n","   macro avg       0.51      0.50      0.46      1041\n","weighted avg       0.61      0.70      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7g-z0mB6Tbc","executionInfo":{"status":"ok","timestamp":1635257557225,"user_tz":-120,"elapsed":41062,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"e0d48458-2631-4bab-d9ed-d78b1a117b6f"},"source":["voting_classifiers(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec)"],"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[14:11:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.688\n","Precision: 0.590\n","Recall: 0.688\n","F_score: 0.615\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.93      0.81       754\n","           1       0.24      0.06      0.10       287\n","\n","    accuracy                           0.69      1041\n","   macro avg       0.48      0.49      0.46      1041\n","weighted avg       0.59      0.69      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"4Rzyu-S_7n4p"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbxe834r7oCZ","executionInfo":{"status":"ok","timestamp":1635257723027,"user_tz":-120,"elapsed":431,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fa8cd301-7bca-4e6d-b3f8-87f108c5ec71"},"source":["Bagging_Classifier_LR(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow)"],"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n","Accuracy: 0.606\n","Precision: 0.635\n","Recall: 0.606\n","F_score: 0.618\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.68      0.71       754\n","           1       0.33      0.41      0.36       287\n","\n","    accuracy                           0.61      1041\n","   macro avg       0.54      0.54      0.54      1041\n","weighted avg       0.63      0.61      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Os-xnqfj7pBC","executionInfo":{"status":"ok","timestamp":1635257724814,"user_tz":-120,"elapsed":6,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"dacb5869-4502-45d4-9930-f6d98a8927dc"},"source":["Bagging_Classifier_LR(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf)"],"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n","Accuracy: 0.452\n","Precision: 0.662\n","Recall: 0.452\n","F_score: 0.458\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.33      0.46       754\n","           1       0.31      0.78      0.44       287\n","\n","    accuracy                           0.45      1041\n","   macro avg       0.55      0.55      0.45      1041\n","weighted avg       0.66      0.45      0.46      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rTt3jTvR7qAb","executionInfo":{"status":"ok","timestamp":1635257728313,"user_tz":-120,"elapsed":411,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"cb2d8761-261f-4b76-efaf-4da75f45a90d"},"source":["Bagging_Classifier_LR(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec)"],"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n","Accuracy: 0.501\n","Precision: 0.651\n","Recall: 0.501\n","F_score: 0.522\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.44      0.56       754\n","           1       0.31      0.68      0.43       287\n","\n","    accuracy                           0.50      1041\n","   macro avg       0.55      0.56      0.49      1041\n","weighted avg       0.65      0.50      0.52      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXguISE57rW5","executionInfo":{"status":"ok","timestamp":1635257733090,"user_tz":-120,"elapsed":392,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"4c71f797-7d99-4708-9260-8895690bd875"},"source":["Bagging_Classifier_LR(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec)"],"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n","Accuracy: 0.558\n","Precision: 0.649\n","Recall: 0.558\n","F_score: 0.582\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.55      0.65       754\n","           1       0.33      0.57      0.41       287\n","\n","    accuracy                           0.56      1041\n","   macro avg       0.55      0.56      0.53      1041\n","weighted avg       0.65      0.56      0.58      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"XZ6AsBXa7vH3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHWTDeWI7vTF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpxnzRw57vTF","executionInfo":{"status":"ok","timestamp":1635257736565,"user_tz":-120,"elapsed":480,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"f9137e83-ea0c-4f68-e481-601029d3f30e"},"source":["Bagging_Classifier_SVM(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow)"],"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.635\n","Precision: 0.630\n","Recall: 0.635\n","F_score: 0.633\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.76      0.75       754\n","           1       0.33      0.32      0.32       287\n","\n","    accuracy                           0.63      1041\n","   macro avg       0.54      0.54      0.54      1041\n","weighted avg       0.63      0.63      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-ZK_cNG7vTF","executionInfo":{"status":"ok","timestamp":1635257741032,"user_tz":-120,"elapsed":421,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"10567652-c0b4-46a6-ed02-4102c40dea48"},"source":["Bagging_Classifier_SVM(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf)"],"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.626\n","Precision: 0.631\n","Recall: 0.626\n","F_score: 0.628\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.73      0.74       754\n","           1       0.33      0.34      0.34       287\n","\n","    accuracy                           0.63      1041\n","   macro avg       0.54      0.54      0.54      1041\n","weighted avg       0.63      0.63      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEsWWWjs7vTG","executionInfo":{"status":"ok","timestamp":1635257744593,"user_tz":-120,"elapsed":784,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"7bf2e427-8257-4aa9-afe8-c592e38e1c4e"},"source":["Bagging_Classifier_SVM(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec)"],"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.597\n","Precision: 0.657\n","Recall: 0.597\n","F_score: 0.616\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.62      0.69       754\n","           1       0.35      0.53      0.42       287\n","\n","    accuracy                           0.60      1041\n","   macro avg       0.56      0.57      0.55      1041\n","weighted avg       0.66      0.60      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4x0b8Rl7vTH","executionInfo":{"status":"ok","timestamp":1635257747414,"user_tz":-120,"elapsed":429,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"5aca130b-9b19-4f7f-cafc-6ac2d7955f73"},"source":["Bagging_Classifier_SVM(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec)"],"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.585\n","Precision: 0.644\n","Recall: 0.585\n","F_score: 0.605\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.62      0.68       754\n","           1       0.33      0.49      0.40       287\n","\n","    accuracy                           0.59      1041\n","   macro avg       0.55      0.56      0.54      1041\n","weighted avg       0.64      0.59      0.60      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"bR8Thw8Y7vpd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GSFkqR97vyF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6C8txNlu7vyG","executionInfo":{"status":"ok","timestamp":1635257753774,"user_tz":-120,"elapsed":3311,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"3ace4614-b717-43b8-95c5-fc434fe8f4e6"},"source":["gradient_boosting(xtrain_bow,ytrain_bow,xtest_bow,yvtest_bow)"],"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.712\n","Precision: 0.629\n","Recall: 0.712\n","F_score: 0.629\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.96      0.83       754\n","           1       0.37      0.06      0.11       287\n","\n","    accuracy                           0.71      1041\n","   macro avg       0.55      0.51      0.47      1041\n","weighted avg       0.63      0.71      0.63      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYtJxnJn7vyG","executionInfo":{"status":"ok","timestamp":1635257759436,"user_tz":-120,"elapsed":5667,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"4d9a19ea-2a04-434f-89e1-b8395341b31f"},"source":["gradient_boosting(xtrain_tfidf,ytrain_tfidf,xtest_tfidf,yvtest_tfidf)"],"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.709\n","Precision: 0.616\n","Recall: 0.709\n","F_score: 0.624\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.96      0.83       754\n","           1       0.33      0.05      0.09       287\n","\n","    accuracy                           0.71      1041\n","   macro avg       0.53      0.51      0.46      1041\n","weighted avg       0.62      0.71      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLbDgkHP7vyG","executionInfo":{"status":"ok","timestamp":1635257832267,"user_tz":-120,"elapsed":71284,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"03d99a07-2f8d-4cc1-82b6-dd0a2218603d"},"source":["gradient_boosting(xtrain_wordvec,ytrain_wordvec,xtest_wordvec,yvtest_wordvec)"],"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.676\n","Precision: 0.629\n","Recall: 0.676\n","F_score: 0.644\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.86      0.79       754\n","           1       0.35      0.20      0.25       287\n","\n","    accuracy                           0.68      1041\n","   macro avg       0.54      0.53      0.52      1041\n","weighted avg       0.63      0.68      0.64      1041\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xUa2UP87vyG","executionInfo":{"status":"ok","timestamp":1635257907053,"user_tz":-120,"elapsed":74850,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fccbbcc6-e4cc-4d5c-9393-187e75084054"},"source":["gradient_boosting(xtrain_docvec,ytrain_docvec,xtest_docvec,yvtest_docvec)"],"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.640\n","Precision: 0.604\n","Recall: 0.640\n","F_score: 0.618\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.81      0.76       754\n","           1       0.28      0.20      0.23       287\n","\n","    accuracy                           0.64      1041\n","   macro avg       0.50      0.50      0.50      1041\n","weighted avg       0.60      0.64      0.62      1041\n","\n"]}]},{"cell_type":"code","metadata":{"id":"omDZMv6Z-FP4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oksrqgQ2-Fef"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFwspjNA-FiH","executionInfo":{"status":"ok","timestamp":1635257991923,"user_tz":-120,"elapsed":10106,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"a391b2af-1d5b-4315-b530-626eea344ddb"},"source":["!pip install transformers\n"],"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 43.6 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 42.9 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["72beb5ac3f6a4eb2a7b75e4d00922a76","369a4a585490425d8f6dd43fd11e0981","a0ae20d03d6749deb5b79557e1e162f2","a82251be93cd4ebcb7a9ca05d30df03e","ffdd3972063f4be083ff46d442ed6537","cd5a982c44004f63adda21a8dfa071d4","d57d9b5d71da4961b997234919488e92","0326432c939b41a9a2956c59ae8f9c55","459cdeec89f44b63821f6d6c0e23ec26","4e34e3e70e6e4bdd966a9f11b7dbee5c","aa2e4d8f21dd4a128748c743a0c39672"]},"id":"fBaMP9ke-J4b","executionInfo":{"status":"ok","timestamp":1635258131934,"user_tz":-120,"elapsed":19979,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"8b6f5c32-8cee-4155-a2dd-1655af58f6f3"},"source":["import torch\n","from transformers import BertTokenizer, BertModel\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","#logging.basicConfig(level=logging.INFO)\n","\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased',\n","           output_hidden_states = True,)\n"],"execution_count":99,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72beb5ac3f6a4eb2a7b75e4d00922a76","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"id":"ubE69Syl-Nfl","executionInfo":{"status":"ok","timestamp":1635259331109,"user_tz":-120,"elapsed":532,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["def bert_text_preparation(text, tokenizer):\n","    \"\"\"Preparing the input for BERT\n","    \n","    Takes a string argument and performs\n","    pre-processing like adding special tokens,\n","    tokenization, tokens to ids, and tokens to\n","    segment ids. All tokens are mapped to seg-\n","    ment id = 1.\n","    \n","    Args:\n","        text (str): Text to be converted\n","        tokenizer (obj): Tokenizer object\n","            to convert text into BERT-re-\n","            adable tokens and ids\n","        \n","    Returns:\n","        list: List of BERT-readable tokens\n","        obj: Torch tensor with token ids\n","        obj: Torch tensor segment ids\n","    \n","    \n","    \"\"\"\n","    marked_text = \"[CLS] \" + text + \" [SEP]\"\n","    tokenized_text = tokenizer.tokenize(marked_text)\n","    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","    segments_ids = [1]*len(indexed_tokens)\n","\n","    # Convert inputs to PyTorch tensors\n","    tokens_tensor = torch.tensor([indexed_tokens])\n","    segments_tensors = torch.tensor([segments_ids])\n","\n","    return tokenized_text, tokens_tensor, segments_tensors"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXkduT5t-bIe","executionInfo":{"status":"ok","timestamp":1635259330043,"user_tz":-120,"elapsed":716,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n","    \"\"\"Get embeddings from an embedding model\n","    \n","    Args:\n","        tokens_tensor (obj): Torch tensor size [n_tokens]\n","            with token ids for each token in text\n","        segments_tensors (obj): Torch tensor size [n_tokens]\n","            with segment ids for each token in text\n","        model (obj): Embedding model to generate embeddings\n","            from token and segment ids\n","    \n","    Returns:\n","        list: List of list of floats of size\n","            [n_tokens, n_embedding_dimensions]\n","            containing embeddings for each token\n","    \n","    \"\"\"\n","    \n","    # Gradient calculation id disabled\n","    # Model is in inference mode\n","    with torch.no_grad():\n","        outputs = model(tokens_tensor, segments_tensors)\n","        # Removing the first hidden state\n","        # The first state is the input state\n","        hidden_states = outputs[2][1:]\n","\n","    # Getting embeddings from the final BERT layer\n","    token_embeddings = hidden_states[-1]\n","    # Collapsing the tensor into 1-dimension\n","    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n","    # print(token_embeddings.shape)\n","    # token_vecs_cat = []\n","    # for token in token_embeddings:\n","    #   cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n","    # Converting torchtensors to lists\n","    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n","\n","    return list_token_embeddings"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1KWFP8N-2Ja","executionInfo":{"status":"ok","timestamp":1635268458073,"user_tz":-120,"elapsed":1316,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["train, validate, test = \\\n","              np.split(df.sample(frac=1, random_state=42), \n","                       [int(.6*len(df)), int(.8*len(df))])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"80bQMsRQ-3Ky","executionInfo":{"status":"ok","timestamp":1635268458491,"user_tz":-120,"elapsed":1,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["train=train.append(validate, ignore_index=True)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxhBDgmE-q_a","executionInfo":{"status":"ok","timestamp":1635260062413,"user_tz":-120,"elapsed":398973,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["target_word_embeddings = []\n","wordvec_arrays = np.zeros((len(train['tweet']), 768)) \n","i=0\n","# for i in range(len(tokenized_tweet)):\n","#     # print(i)\n","    \n","\n","\n","for text in train['tweet'].values:\n","    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n","    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n","    def word_vector(tokens, size):\n","      vec = np.zeros(size).reshape((1, size))\n","      count = 0\n","      for word in list_token_embeddings:\n","          try:\n","              # print(model_w2v[word].shape)\n","              vec += np.array(word).reshape((1, size))\n","              count += 1.\n","          except KeyError:  # handling the case where the token is not in vocabulary\n","              continue\n","      if count != 0:\n","          vec /= count\n","      return vec\n","    wordvec_arrays[i,:] = word_vector(list_token_embeddings, 768)\n","    i=i+1\n","    # print(len(list_token_embeddings))\n","    # target_word_embeddings.append(np.array(list_token_embeddings))\n","    \n","    # # Find the position 'bank' in list of tokens\n","    # word_index = tokenized_text.index('bank')\n","    # # Get the embedding for bank\n","    # word_embedding = list_token_embeddings[word_index]\n","\n","    # target_word_embeddings.append(word_embedding)"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0PPegSeHE-K","executionInfo":{"status":"ok","timestamp":1635260430757,"user_tz":-120,"elapsed":97660,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["target_word_embeddings = []\n","wordvec_arrays = np.zeros((len(test['tweet']), 768)) \n","i=0\n","# for i in range(len(tokenized_tweet)):\n","#     # print(i)\n","    \n","\n","\n","for text in test['tweet'].values:\n","    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n","    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n","    def word_vector(tokens, size):\n","      vec = np.zeros(size).reshape((1, size))\n","      count = 0\n","      for word in list_token_embeddings:\n","          try:\n","              # print(model_w2v[word].shape)\n","              vec += np.array(word).reshape((1, size))\n","              count += 1.\n","          except KeyError:  # handling the case where the token is not in vocabulary\n","              continue\n","      if count != 0:\n","          vec /= count\n","      return vec\n","    wordvec_arrays[i,:] = word_vector(list_token_embeddings, 768)\n","    i=i+1\n","    # print(len(list_token_embeddings))\n","    # target_word_embeddings.append(np.array(list_token_embeddings))\n","    \n","    # # Find the position 'bank' in list of tokens\n","    # word_index = tokenized_text.index('bank')\n","    # # Get the embedding for bank\n","    # word_embedding = list_token_embeddings[word_index]\n","\n","    # target_word_embeddings.append(word_embedding)"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-SdBjQP_hcW","executionInfo":{"status":"ok","timestamp":1635260180099,"user_tz":-120,"elapsed":412,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_df_new = pd.DataFrame(wordvec_arrays)"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTFuTEWGHJHv","executionInfo":{"status":"ok","timestamp":1635260432644,"user_tz":-120,"elapsed":2,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_df_test= pd.DataFrame(wordvec_arrays)"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCIzf-08Hay2","executionInfo":{"status":"ok","timestamp":1635260828349,"user_tz":-120,"elapsed":244750,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"77bd4a65-4da3-4dfe-9ef5-12ccbe0a8088"},"source":["gradient_boosting(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.692\n","Precision: 0.662\n","Recall: 0.692\n","F_score: 0.675\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.84      0.81       532\n","           1       0.28      0.21      0.24       162\n","\n","    accuracy                           0.69       694\n","   macro avg       0.53      0.52      0.52       694\n","weighted avg       0.66      0.69      0.67       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yNAXnV9IF0N","executionInfo":{"status":"ok","timestamp":1635261005076,"user_tz":-120,"elapsed":6306,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"27cf6ed4-c623-4fdd-9ae5-7210d8eaecb1"},"source":["Bagging_Classifier_SVM(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":127,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.700\n","Precision: 0.721\n","Recall: 0.700\n","F_score: 0.709\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.77      0.80       532\n","           1       0.38      0.46      0.42       162\n","\n","    accuracy                           0.70       694\n","   macro avg       0.60      0.62      0.61       694\n","weighted avg       0.72      0.70      0.71       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33selZxsIISe","executionInfo":{"status":"ok","timestamp":1635261005648,"user_tz":-120,"elapsed":579,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"6e19bf7c-0112-4294-9385-24f8d956b102"},"source":["Bagging_Classifier_LR(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n","Accuracy: 0.656\n","Precision: 0.723\n","Recall: 0.656\n","F_score: 0.678\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.68      0.75       532\n","           1       0.35      0.56      0.43       162\n","\n","    accuracy                           0.66       694\n","   macro avg       0.59      0.62      0.59       694\n","weighted avg       0.72      0.66      0.68       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xXMAmMpIKdv","executionInfo":{"status":"ok","timestamp":1635261168455,"user_tz":-120,"elapsed":161704,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0e5e6697-e5d6-472c-b640-3261ecb0087c"},"source":["voting_classifiers(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:10:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.761\n","Precision: 0.702\n","Recall: 0.761\n","F_score: 0.699\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.96      0.86       532\n","           1       0.45      0.10      0.17       162\n","\n","    accuracy                           0.76       694\n","   macro avg       0.61      0.53      0.52       694\n","weighted avg       0.70      0.76      0.70       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rde6lnBuINB4","executionInfo":{"status":"ok","timestamp":1635261887256,"user_tz":-120,"elapsed":718805,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"03e2aca8-92e6-4a00-d070-7e04c036c40e"},"source":["ensemble_stacked(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:12:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:15:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:17:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:19:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:21:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:22:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.767\n","Precision: 0.709\n","Recall: 0.767\n","F_score: 0.683\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.99      0.87       532\n","           1       0.50      0.04      0.08       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.64      0.52      0.47       694\n","weighted avg       0.71      0.77      0.68       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uq7UmwS_IPfp","executionInfo":{"status":"ok","timestamp":1635262049590,"user_tz":-120,"elapsed":160863,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"c05381eb-0bd0-4216-d555-4bc3c9945864"},"source":["xg_boost(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:24:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.762\n","Precision: 0.708\n","Recall: 0.762\n","F_score: 0.705\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.96      0.86       532\n","           1       0.47      0.12      0.20       162\n","\n","    accuracy                           0.76       694\n","   macro avg       0.62      0.54      0.53       694\n","weighted avg       0.71      0.76      0.71       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oUGN-DUIR5u","executionInfo":{"status":"ok","timestamp":1635262080383,"user_tz":-120,"elapsed":30803,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"19a5f41d-26c5-4ec7-c1cb-aba217f98414"},"source":["random_forest(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.764\n","Precision: 0.587\n","Recall: 0.764\n","F_score: 0.664\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.76       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.76      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYRWILNVIXVy","executionInfo":{"status":"ok","timestamp":1635262080383,"user_tz":-120,"elapsed":14,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0881799b-69cd-4f2c-90c8-7365cbd59569"},"source":["logistic_regression(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.633\n","Precision: 0.718\n","Recall: 0.633\n","F_score: 0.659\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.65      0.73       532\n","           1       0.33      0.58      0.42       162\n","\n","    accuracy                           0.63       694\n","   macro avg       0.58      0.61      0.58       694\n","weighted avg       0.72      0.63      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYpvEVYGIZ6v","executionInfo":{"status":"ok","timestamp":1635262080890,"user_tz":-120,"elapsed":520,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"18ad23f8-e857-4648-bba0-65c4e98433c4"},"source":["linear_svm(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.674\n","Precision: 0.733\n","Recall: 0.674\n","F_score: 0.694\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.71      0.77       532\n","           1       0.37      0.57      0.45       162\n","\n","    accuracy                           0.67       694\n","   macro avg       0.61      0.64      0.61       694\n","weighted avg       0.73      0.67      0.69       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNzofFXHIb0o","executionInfo":{"status":"ok","timestamp":1635262087149,"user_tz":-120,"elapsed":6266,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"a377307e-1bdc-4c04-d48f-5fad260ccc00"},"source":["logistic_regression_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.671\n","Precision: 0.719\n","Recall: 0.671\n","F_score: 0.689\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.72      0.77       532\n","           1       0.36      0.51      0.42       162\n","\n","    accuracy                           0.67       694\n","   macro avg       0.59      0.62      0.60       694\n","weighted avg       0.72      0.67      0.69       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArTPLmUsIe3D","executionInfo":{"status":"ok","timestamp":1635262711949,"user_tz":-120,"elapsed":624819,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"5159cb57-f45b-4aed-d6c0-2757197d4ce9"},"source":["nonlinear_svm_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.765\n","Precision: 0.587\n","Recall: 0.765\n","F_score: 0.665\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.77      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lo7VxoLIhnz","executionInfo":{"status":"ok","timestamp":1635262820371,"user_tz":-120,"elapsed":108439,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"401b99dd-aa77-4cb0-cf4a-a4a111459fa6"},"source":["linear_svm_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.661\n","Precision: 0.712\n","Recall: 0.661\n","F_score: 0.680\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.71      0.76       532\n","           1       0.34      0.50      0.41       162\n","\n","    accuracy                           0.66       694\n","   macro avg       0.58      0.61      0.59       694\n","weighted avg       0.71      0.66      0.68       694\n","\n"]}]},{"cell_type":"code","metadata":{"id":"sIz0KZzsJwjK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LoLaUI4VJws1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9uGbQsqGJwvP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfCrU_m2Jwz4","executionInfo":{"status":"ok","timestamp":1635262881395,"user_tz":-120,"elapsed":5872,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"998757ce-766d-460a-aaab-e9251df39298"},"source":["!pip install -U sentence-transformers"],"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n","  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n","\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.11.3)\n","Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.19)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=1453b7860ffb35dd4e72842e5ea7ce2517691749e2bb837ac6f8190541b46d39\n","  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n","Successfully built sentence-transformers\n","Installing collected packages: sentencepiece, sentence-transformers\n","Successfully installed sentence-transformers-2.1.0 sentencepiece-0.1.96\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465,"referenced_widgets":["421d86ef54464e57a82f7d2d8966e6be","61ac26f1b5464bf9bc36e835e22c2936","538159e0c1f94623b9765a39d0ca77ae","7688d0391df84abfb5fecf214ae6345b","efdee16a08794d60b823181c572fa1b8","ccc8b4c833df415fb330163728b4b1cc","f924ea693c4648d28b186d1a3babeec2","8c3a7549522840fead1b78519727e620","4dbc6af5ffbf45caae5135fb1924ff46","7f51cbe0444d45e3954266abc88b2eae","de61c8ba8ad4419dbfb9620c7813e8e2","75f2ddc72bbf46f2a9cb7a2d667153f7","ad97ac6775f74f13ab118af51d3b1952","76f21dd075da4625bfbac8c90de59091","fd44050aeb3c4a9ab2dd6a2ca6bd645b","130f2df38c0a45bcb6c0b565aab4f017","e236c445eb8648b4994c13937eb02b62","9dffd63ab8734ffd8ffba1d1a7902ca4","a291e1e133714e99b4108262ac6c0cbc","24b3690fffd3458ca115f32d5fb2cf61","b4aac39b13c8422a9dae80c815578364","cfd3ae45282641579d56870e2f607c07","1f6721e2d96a432c838fdc550e2cb802","fdeebb7cccc3472e988bee5ad8463117","722c610192dc4316be15da59b6c47b26","d39f987a0f1e4891828795c74e49cd29","4eadf00d92c04ec691662b5fedd5deb3","aec8ec5d7034470abde5a201f37b60cd","c55574f4141140a48469b0c31c9c69a1","3b67bc6fd5ad4ff2a18ec94b00753812","6c3beba3594d4fe28bd7a14c682b65af","84c6e85374d4447c8adc272594a6b179","aa1f76fdca7b45c1919ea7143e6d0200","54e497109d99459581c2d1c4a284e6b6","b66b27280f6a4ab387d8a719834d6b0f","1d00f608a739481a962258a49ebb350b","bbe96c0a95a14430ae610e06c125dd15","b149efbc9d654f7f844671c3549245c1","2b2ba097a5f4456da4866bc33da6ba0c","2d3d9e6179b8495b9deb1a463bbd3eb5","b93be0da838d49bd97d1677b3485be57","3f622680fa854f6b91f0027fbc079442","137ef2463f484949b80773f872aeff91","f19397b33eef4f3b8cf3629ae7148e02","09b528a1794a49ba9af40e00db856969","317de30212154693987b20e3b5a61dc1","59c044f99d7b46188b82a01f2f7225e7","439f2ae4fa0b45f38f5a67b09caee1b0","d8edbce4c8b049e29226912a3c8df4bd","7ff6b032bb3c4cadb14ecf5b33dbff26","c41a8b200d7648608187217b0603743c","89d2a8419012483187688e79e619b21a","81e65d7f05834b1aadeb28681d147db8","6931d7cd9d2a4c7598154db25ca711b6","35ed4d5e44264a8ca5cc50d19fdd90aa","910fa093cf4f4b2fa2ec6a0fd095243b","d6e72ac3e0af4bcda409e58e5a44d433","36cb522c9e534621a7782d15e75e9260","c7ee615e5a7849b08e16b7486d5054fc","9ac8bd223b99421594e30abc314ea819","daae8c1281484d5e8e4c20f3e5d7f653","a4e69c30c36445b48cfc0ca28ff2eee9","2e29be9dc1404f71afc92057275f54fb","28ad5c38ff60416aa2bbf99f84470b2b","cfd76643d79f4c92b402a58606292393","34ec17e9c84e42a6a5cbc5cf71d170c5","503d5d2f93ad4720aeb9a2681547b80b","29b0955ce1144d0cbbc05aff1f99daeb","b9dd590294704dee89cbce72544f604a","0de7021fad1e41e1a45918cc9df4ed51","1d902f95af9d4148bdb0df43a6b0ed6c","6cbe87065fd54394be9f5568cb4b366c","4c87b2365dae4d12b2a0ed18de65f051","ca5f2d88f84d495ea19e048b5620e4ae","11578e21181f4212a5bf2a855c38e9aa","d53de598c5564950a574df83d3bf9670","eb817d98975a488698e5286edc718e0f","f0298e4e44844048b3f768c4e02d6fa5","126345447ac44cdd808f4d690a07409c","d4c47b71c1d64bee90d30304811092d1","25b37fc82d094c6d875b561bcc5f70ca","08dcc25afdff4303a588ab14d0f2730a","2a41424a3683425aa3595c6568ffb5a2","9e9cb8220645408eaf29f7510579440d","7586ec0ade1d4998a8a4c7a580fedf7f","c63776394cb04a73a915d2197657c16d","f40f0a4a95c347f08b19ca27bcb134cc","f12a56d0b37e4ab78115453bfbd87679","dd1b583487d74c8cb3b1013e0604e60e","cebf38ce7b26424ea03445aa8c1e2202","632b9610dc834bceaa88241996566f86","5401b4e5f3ff40ba96f5c781d4d7d35b","c9e1b5181bf248a8acbea44515ba8ec6","b8e47211d69a4c83b5677afc5347cdae","8f4f323a0bdd4a40b232d8bdff728603","8ab3caee0734438db56db2d2386e3c29","38239817b1e64a37babd3c665c1c19b1","87bb3bce417947a5b487276ff69740a1","0dc6619782334bedbf6e59037e3f43ab","7ac2b5e90f2b4ab8b20bcff23624c40d","177bd2aeeba14652aa6c02dfbcfc2c17","1e3e60faa56c4e8d8c7ec9cced2ccd22","23d85af386cc4050b02a9fcd25333eeb","918d742e16994bfb8fd0966506b53b8f","05a4f0a3973742e2a81acf990b4f93d8","8859e8b6b3cd47e4931418672cda7c26","10285752e08f43c1b11f5e26be22e418","91cd2b182e734470b957b83863768f97","2cef2ae31d6f4c0a916f0217684e62d5","bd69925905f3432081b2d350a0928bef","7462495951e648dd96846771b67c7450","1a84ddb9478f435498303fb7e70c3b28","72c98a9b436149028097d170a61a2984","f316a115bc4b40849bfeef2910622f15","3186dc18d27447fa81909a9954d5b0ec","c9f871f9d112403b9f690259a31b40e3","3448daf2362a48bebf4fc4caed7b4b33","1906fee778f249269411afc2530fa65d","072861dccce549028e0693b9b2bab5b4","4a6998243c024a0a8f55b1941ffb265e","2365e2289d154433a8eaefc309d388b5","fd1fcfaa0965448b9019df9f99c84428","d4d9e061dc3c4f91a4d5acea41aa4983","52eaad8de0954d93ba2b0a6f064c1d7b","f88d01a6a0c641cc855875dda2f33563","a7de38bdd5274113bfadea3e33b15985","e0348263ba9141ba9afcc6a3a1116351","f632b8f909414a5894e145494895cc87","63db7c99f68549b59b0f173f84a0875e","8056c0118f7947efaa0500add508f1a0","ff068175eb3545abbe1556fceedee668","a29df5c30d104f2d8961ca04b4c2f203","d05a14a3ec464c95a28a3bda0cf66ebd","cd08fbd7459742d3a73429535c3edf06","987e6c0ade3e465c9c11ee1f9048eed4","30398c37e17d42f9a213a4de6e91663a","d7ac66829b8e448985bcb8e3e4d58464","ca0db0ff0e4d475c9e631417549f1f9c","d8e7aec33dc546318aff8ed85c3d66dc","dbb0b5337b264dc3ab7912d6422e6532","1abc50f08a9b4e91a7b77a1f47948920","87c6bf72da7e420d926d2cf318ab3e81","4532cf7ccec447079f60cb7ef754d3fe","60ffa8a42b5a47e5a6cf6a586de31d4c","ec837f5ec138400c888095609362819e","891fe06b5ca84acda4a0f83a0bf826bb","0d66c774e5304bb48b8fafee89580a9e","bb8821bea4114b7d8817557151f55db6","37a26680ecae4f08af7a3ef4ebf7f5c0","6e959cdf37314ad1bd42b887b131ce09","3c3ae182806d4d3fa652e12073f09ab7","985b4634830d41ae9fdc771d39ef9e2b","b9b63904855f431a98638a3ebb3b4d29","6aabf7a87d6145f9840d3367ecc9f1e3"]},"id":"8JZHQtugJ1f_","executionInfo":{"status":"ok","timestamp":1635262924909,"user_tz":-120,"elapsed":26979,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"be5bbe15-cf1e-4c0c-ba07-115270614776"},"source":["from sentence_transformers import SentenceTransformer\n","model = SentenceTransformer('all-MiniLM-L6-v2')"],"execution_count":139,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"421d86ef54464e57a82f7d2d8966e6be","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75f2ddc72bbf46f2a9cb7a2d667153f7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f6721e2d96a432c838fdc550e2cb802","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54e497109d99459581c2d1c4a284e6b6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09b528a1794a49ba9af40e00db856969","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"910fa093cf4f4b2fa2ec6a0fd095243b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"503d5d2f93ad4720aeb9a2681547b80b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0298e4e44844048b3f768c4e02d6fa5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd1b583487d74c8cb3b1013e0604e60e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ac2b5e90f2b4ab8b20bcff23624c40d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7462495951e648dd96846771b67c7450","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd1fcfaa0965448b9019df9f99c84428","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d05a14a3ec464c95a28a3bda0cf66ebd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60ffa8a42b5a47e5a6cf6a586de31d4c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"rx7fe3QsKFRb","executionInfo":{"status":"ok","timestamp":1635263130129,"user_tz":-120,"elapsed":67609,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["target_sent_embeddings_train = []\n","for text in train['tweet'].values:\n","  sentence_embeddings = model.encode(text)\n","  # print(sentence_embeddings)\n","  target_sent_embeddings_train.append(sentence_embeddings)\n","\n","sent2_vec_df_new_train = pd.DataFrame(target_sent_embeddings_train)"],"execution_count":145,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bnyt-fC7KkGo","executionInfo":{"status":"ok","timestamp":1635263146738,"user_tz":-120,"elapsed":16611,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["target_sent_embeddings_test = []\n","for text in test['tweet'].values:\n","  sentence_embeddings = model.encode(text)\n","  target_sent_embeddings_test.append(sentence_embeddings)\n","\n","sent2_vec_df_new_test = pd.DataFrame(target_sent_embeddings_test)"],"execution_count":146,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZbHsy8WKop0","executionInfo":{"status":"ok","timestamp":1635263316516,"user_tz":-120,"elapsed":143942,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"063dcf57-8acd-4400-a48d-70dfc1ef3764"},"source":["gradient_boosting(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'])"],"execution_count":148,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.669\n","Precision: 0.639\n","Recall: 0.669\n","F_score: 0.652\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.82      0.79       532\n","           1       0.23      0.17      0.20       162\n","\n","    accuracy                           0.67       694\n","   macro avg       0.50      0.50      0.49       694\n","weighted avg       0.64      0.67      0.65       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmhGAb-zK0KA","executionInfo":{"status":"ok","timestamp":1635263319493,"user_tz":-120,"elapsed":925,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"bcdc627e-86b6-491f-b442-9be8f773344d"},"source":["Bagging_Classifier_SVM(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'])"],"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.621\n","Precision: 0.703\n","Recall: 0.621\n","F_score: 0.648\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.65      0.72       532\n","           1       0.32      0.54      0.40       162\n","\n","    accuracy                           0.62       694\n","   macro avg       0.57      0.59      0.56       694\n","weighted avg       0.70      0.62      0.65       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T33nAvgzK3Nc","executionInfo":{"status":"ok","timestamp":1635263320218,"user_tz":-120,"elapsed":730,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"b136c16b-0cbf-439d-cd3a-b1bad5a273b9"},"source":["Bagging_Classifier_LR(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'])"],"execution_count":150,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n","Accuracy: 0.640\n","Precision: 0.707\n","Recall: 0.640\n","F_score: 0.663\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.68      0.74       532\n","           1       0.33      0.52      0.40       162\n","\n","    accuracy                           0.64       694\n","   macro avg       0.58      0.60      0.57       694\n","weighted avg       0.71      0.64      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taIkgdVNK50e","executionInfo":{"status":"ok","timestamp":1635263407351,"user_tz":-120,"elapsed":87144,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"a3ea9492-e16e-4baa-efd0-cf6581b60361"},"source":["voting_classifiers(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'])"],"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:48:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.758\n","Precision: 0.694\n","Recall: 0.758\n","F_score: 0.696\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.96      0.86       532\n","           1       0.42      0.10      0.16       162\n","\n","    accuracy                           0.76       694\n","   macro avg       0.60      0.53      0.51       694\n","weighted avg       0.69      0.76      0.70       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KtYK6HsyK8Co","executionInfo":{"status":"ok","timestamp":1635263802200,"user_tz":-120,"elapsed":394862,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0c8ecb12-ebb5-4466-e115-21a3186fc161"},"source":["ensemble_stacked(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'])"],"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:51:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:52:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:53:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:54:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[15:55:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.767\n","Precision: 0.709\n","Recall: 0.767\n","F_score: 0.683\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.99      0.87       532\n","           1       0.50      0.04      0.08       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.64      0.52      0.47       694\n","weighted avg       0.71      0.77      0.68       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7jJUadRK9-a","executionInfo":{"status":"ok","timestamp":1635263890412,"user_tz":-120,"elapsed":88234,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"5cca845e-abe0-4269-f010-3f9a18fc8bd2"},"source":["xg_boost(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'])"],"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[15:56:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.768\n","Precision: 0.718\n","Recall: 0.768\n","F_score: 0.702\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.97      0.87       532\n","           1       0.52      0.10      0.17       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.65      0.54      0.52       694\n","weighted avg       0.72      0.77      0.70       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38en_ON_LEF_","executionInfo":{"status":"ok","timestamp":1635263914726,"user_tz":-120,"elapsed":24322,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"832d8b30-3c9d-48a8-89df-adb9d3898b03"},"source":["random_forest(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.765\n","Precision: 0.587\n","Recall: 0.765\n","F_score: 0.665\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.77      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zaIVpaJPLIFv","executionInfo":{"status":"ok","timestamp":1635263914727,"user_tz":-120,"elapsed":46,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"edebf2c6-c7ca-4a2f-e6f6-3c0c89cc12b5"},"source":["logistic_regression(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":155,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.578\n","Precision: 0.703\n","Recall: 0.578\n","F_score: 0.610\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.57      0.67       532\n","           1       0.30      0.60      0.40       162\n","\n","    accuracy                           0.58       694\n","   macro avg       0.56      0.59      0.54       694\n","weighted avg       0.70      0.58      0.61       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gh3u54WTLKYZ","executionInfo":{"status":"ok","timestamp":1635263914727,"user_tz":-120,"elapsed":38,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"a31445b9-e432-490a-8615-3c1955dfafed"},"source":["linear_svm(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.591\n","Precision: 0.702\n","Recall: 0.591\n","F_score: 0.622\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.59      0.69       532\n","           1       0.30      0.58      0.40       162\n","\n","    accuracy                           0.59       694\n","   macro avg       0.56      0.59      0.54       694\n","weighted avg       0.70      0.59      0.62       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cXe9GXNLMhA","executionInfo":{"status":"ok","timestamp":1635263918363,"user_tz":-120,"elapsed":3666,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"4454b5c9-ac90-45bc-bf0c-c40fbac55323"},"source":["logistic_regression_grid(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.608\n","Precision: 0.701\n","Recall: 0.608\n","F_score: 0.637\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.63      0.71       532\n","           1       0.31      0.55      0.40       162\n","\n","    accuracy                           0.61       694\n","   macro avg       0.56      0.59      0.55       694\n","weighted avg       0.70      0.61      0.64       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfL111ZtLP02","executionInfo":{"status":"ok","timestamp":1635264224274,"user_tz":-120,"elapsed":305939,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"b32f5145-c6a4-4a57-b015-fa2376ccfd57"},"source":["nonlinear_svm_grid(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":158,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.233\n","Precision: 0.054\n","Recall: 0.233\n","F_score: 0.088\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       532\n","           1       0.23      1.00      0.38       162\n","\n","    accuracy                           0.23       694\n","   macro avg       0.12      0.50      0.19       694\n","weighted avg       0.05      0.23      0.09       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"po7r17kWLSz1","executionInfo":{"status":"ok","timestamp":1635264252231,"user_tz":-120,"elapsed":27979,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"db969cb7-8be7-46af-bc37-0a2b6c26bea4"},"source":["linear_svm_grid(sent2_vec_df_new_train,train['sarcastic'],sent2_vec_df_new_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":159,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.602\n","Precision: 0.699\n","Recall: 0.602\n","F_score: 0.632\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.62      0.70       532\n","           1       0.30      0.55      0.39       162\n","\n","    accuracy                           0.60       694\n","   macro avg       0.56      0.58      0.55       694\n","weighted avg       0.70      0.60      0.63       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"_pJL080nVmIC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuMkzJ31VmZ6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzCcQ-M-Vmcl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rgLcyNDuVmfM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["5bc6e9e6ac394364b9e66a6eae026620","59fdc3dc34a54eaeba08016ef662c012","d9a24571c6d14357851610b9fdc9a6b7","ba0d5f3828d24a2e8cddc49bae6e5c7b","53f962c6104d4adba5dec0b0c3aa8e19","3a35e286b487405a9828032d28522083","80ffbf877c874a47bd8b2cd63acf87cd","ed918fbd8a71496388ae6ed297da2dd3","ecf492cd7ba24052b73006b825427f86","595c2d5f6bac4df2ba7b63d3efab3527","714af14e76444c33bc9b490502e88a46","0b301ee3742742fca9b707fb6a97edd9","21b745160f8e4e6dbc6c2ff6136d717e","e262cc8c9aa14a42893e88f322025b30","31c51224a6674163ab6ebe624e1a6c1f","77dba3719f314978b80e90d6ad451d38","3acf5bc7544e42efaa0d30cde2b25245","db157393425c4e7dbc45bb273ef7584e","b5a91531c55142628146dca7fbc1c2b1","4791279366d543a4bfb82bf932989596","165f8848b5384bbf88ad28ebbda5e206","6d74206e7d48416b82cffdb7470a2087","53c78832b0bd4f79b4f24805a87a3b25","8e83e56496b74624b07748a1845c1e08","02f153672590426492f117dc9836e676","c3c41da3535048fe9a19ce054a5201e0","03aff828076342b18e11ed2a385ed6ad","b3b938cbd2ef46a3ad72fb5973da3978","be38f540024c42b6886d562a48aa7d2b","d393a83755b541b0a31a1b4a4b5e511a","7118bfd17cf8478bb4372ae76afaeb1d","8461b9d3c22f466983bdfea0f56aa470","02a95caee1c94a85b60216ae8622a4a9","bc4f65a3dfa144b09dc3f921db0cafb2","2ce94ecf40ff41389ffb7542d7d61bf1","64178f1a3cad47c28450c135eacf0a29","f5401de8afd549d78afb4ec530dda602","e601032d250047748b62822eb0f38f4e","6bb30e515bba44538c947cb70d65394b","ce9d70fe1e18419581f5768345faf654","804c4eba9c9345af9e7d32804a299f14","470779d6f98b4aa8b34dfbdd6e62af3f","d67d841ec19c422596ee63b9da20d8f5","e9c54bbea8e9499abc8f13b8f1f7b168","f7070bdcf26c48b5b90c7ead1460d249","58098a6910954f448cb4590549040cb2","fd4698f33de345e199e26463aac2ebd8","b3589054d7f44c3a885994a97b0a633a","d4538e50c4b640f1b4c5efcbbcc8c778","468f3a04cb4a48359a0a7fd0863b53aa","f10cd6db4e154eb6a224f628a602a1f4","ab2e7f2de19a40b1a71d159ce4f907f6","2e7d3b0d8d0144a8b620374176990d2f","f21d7877bc974b6eb97a0edaf90104be","22bff991f8894ee9a6636b39deed2c76"]},"id":"WWS8AaszVmkQ","executionInfo":{"status":"ok","timestamp":1635264538333,"user_tz":-120,"elapsed":23697,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0a113fe0-7b24-49e3-e613-9df95ec78cb7"},"source":["tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = BertModel.from_pretrained('distilbert-base-uncased',\n","           output_hidden_states = True,)"],"execution_count":163,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bc6e9e6ac394364b9e66a6eae026620","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b301ee3742742fca9b707fb6a97edd9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53c78832b0bd4f79b4f24805a87a3b25","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc4f65a3dfa144b09dc3f921db0cafb2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7070bdcf26c48b5b90c7ead1460d249","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertModel: ['distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"_CmmPqiTVrOb","executionInfo":{"status":"ok","timestamp":1635264937396,"user_tz":-120,"elapsed":396247,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_arrays_train = np.zeros((len(train['tweet']), 768)) \n","i=0\n","# for i in range(len(tokenized_tweet)):\n","#     # print(i)\n","    \n","\n","\n","for text in train['tweet'].values:\n","    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n","    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n","    def word_vector(tokens, size):\n","      vec = np.zeros(size).reshape((1, size))\n","      count = 0\n","      for word in list_token_embeddings:\n","          try:\n","              # print(model_w2v[word].shape)\n","              vec += np.array(word).reshape((1, size))\n","              count += 1.\n","          except KeyError:  # handling the case where the token is not in vocabulary\n","              continue\n","      if count != 0:\n","          vec /= count\n","      return vec\n","    wordvec_arrays_train[i,:] = word_vector(list_token_embeddings, 768)\n","    i=i+1\n","    # print(len(list_token_embeddings))\n","    # target_word_embeddings.append(np.array(list_token_embeddings))\n","    \n","    # # Find the position 'bank' in list of tokens\n","    # word_index = tokenized_text.index('bank')\n","    # # Get the embedding for bank\n","    # word_embedding = list_token_embeddings[word_index]\n","\n","    # target_word_embeddings.append(word_embedding)"],"execution_count":164,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hM7wBdWVywV","executionInfo":{"status":"ok","timestamp":1635265036222,"user_tz":-120,"elapsed":97408,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_arrays_test = np.zeros((len(test['tweet']), 768)) \n","i=0\n","# for i in range(len(tokenized_tweet)):\n","#     # print(i)\n","    \n","\n","\n","for text in test['tweet'].values:\n","    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n","    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n","    def word_vector(tokens, size):\n","      vec = np.zeros(size).reshape((1, size))\n","      count = 0\n","      for word in list_token_embeddings:\n","          try:\n","              # print(model_w2v[word].shape)\n","              vec += np.array(word).reshape((1, size))\n","              count += 1.\n","          except KeyError:  # handling the case where the token is not in vocabulary\n","              continue\n","      if count != 0:\n","          vec /= count\n","      return vec\n","    wordvec_arrays_test[i,:] = word_vector(list_token_embeddings, 768)\n","    i=i+1\n","    # print(len(list_token_embeddings))\n","    # target_word_embeddings.append(np.array(list_token_embeddings))\n","    \n","    # # Find the position 'bank' in list of tokens\n","    # word_index = tokenized_text.index('bank')\n","    # # Get the embedding for bank\n","    # word_embedding = list_token_embeddings[word_index]\n","\n","    # target_word_embeddings.append(word_embedding)"],"execution_count":165,"outputs":[]},{"cell_type":"code","metadata":{"id":"YhOKD5omVywV","executionInfo":{"status":"ok","timestamp":1635265036222,"user_tz":-120,"elapsed":48,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_df_new = pd.DataFrame(wordvec_arrays_train)"],"execution_count":166,"outputs":[]},{"cell_type":"code","metadata":{"id":"88IXsgaiVywV","executionInfo":{"status":"ok","timestamp":1635265036223,"user_tz":-120,"elapsed":13,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_df_test= pd.DataFrame(wordvec_arrays_test)"],"execution_count":167,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3FtHyewVywV","executionInfo":{"status":"ok","timestamp":1635265336918,"user_tz":-120,"elapsed":300707,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fc90c664-59b7-49d2-caaf-145dab54b195"},"source":["gradient_boosting(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":168,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.657\n","Precision: 0.642\n","Recall: 0.657\n","F_score: 0.649\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.80      0.78       532\n","           1       0.23      0.20      0.22       162\n","\n","    accuracy                           0.66       694\n","   macro avg       0.50      0.50      0.50       694\n","weighted avg       0.64      0.66      0.65       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lzxVhJxVywW","executionInfo":{"status":"ok","timestamp":1635265369056,"user_tz":-120,"elapsed":32158,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"2ec9cd61-d8c5-42bc-af3d-676e3998021a"},"source":["Bagging_Classifier_SVM(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n","Accuracy: 0.634\n","Precision: 0.694\n","Recall: 0.634\n","F_score: 0.656\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.68      0.74       532\n","           1       0.31      0.48      0.38       162\n","\n","    accuracy                           0.63       694\n","   macro avg       0.56      0.58      0.56       694\n","weighted avg       0.69      0.63      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6_kFN1zVywW","executionInfo":{"status":"ok","timestamp":1635265370599,"user_tz":-120,"elapsed":1565,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"9baab586-dda2-4f7f-f685-629423460c7d"},"source":["Bagging_Classifier_LR(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.592\n","Precision: 0.687\n","Recall: 0.592\n","F_score: 0.622\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.61      0.70       532\n","           1       0.29      0.52      0.37       162\n","\n","    accuracy                           0.59       694\n","   macro avg       0.55      0.57      0.54       694\n","weighted avg       0.69      0.59      0.62       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I67GUPIQVywW","executionInfo":{"status":"ok","timestamp":1635265541093,"user_tz":-120,"elapsed":170500,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"a526cfaf-5057-425a-b9df-b938403a4598"},"source":["voting_classifiers(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[16:22:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.748\n","Precision: 0.664\n","Recall: 0.748\n","F_score: 0.680\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.95      0.85       532\n","           1       0.31      0.07      0.11       162\n","\n","    accuracy                           0.75       694\n","   macro avg       0.54      0.51      0.48       694\n","weighted avg       0.66      0.75      0.68       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ds6SX_WDVywW","executionInfo":{"status":"ok","timestamp":1635266301204,"user_tz":-120,"elapsed":760133,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"c56af7df-23ef-4b54-c860-38c2077ab1a9"},"source":["ensemble_stacked(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":172,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[16:25:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[16:28:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[16:30:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[16:32:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[16:34:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[16:36:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.767\n","Precision: 0.588\n","Recall: 0.767\n","F_score: 0.665\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.77      0.67       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da9zU-gaVywW","executionInfo":{"status":"ok","timestamp":1635266469077,"user_tz":-120,"elapsed":167911,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"1e172c84-2a48-439a-f9e4-6296cbf14c75"},"source":["xg_boost(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":173,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n","[16:38:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.756\n","Precision: 0.690\n","Recall: 0.756\n","F_score: 0.693\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.96      0.86       532\n","           1       0.41      0.09      0.15       162\n","\n","    accuracy                           0.76       694\n","   macro avg       0.59      0.53      0.50       694\n","weighted avg       0.69      0.76      0.69       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JToCHn8VywW","executionInfo":{"status":"ok","timestamp":1635266500410,"user_tz":-120,"elapsed":31353,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"8d4df784-4cba-41ca-8c16-547261eab1ed"},"source":["random_forest(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":174,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.765\n","Precision: 0.587\n","Recall: 0.765\n","F_score: 0.665\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.77      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VmOZArFVywW","executionInfo":{"status":"ok","timestamp":1635266500930,"user_tz":-120,"elapsed":555,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"6d92249d-11aa-4094-d563-39598e7760c3"},"source":["logistic_regression(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":175,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.578\n","Precision: 0.687\n","Recall: 0.578\n","F_score: 0.610\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.59      0.68       532\n","           1       0.29      0.54      0.38       162\n","\n","    accuracy                           0.58       694\n","   macro avg       0.55      0.57      0.53       694\n","weighted avg       0.69      0.58      0.61       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMUWAlC2VywX","executionInfo":{"status":"ok","timestamp":1635266503283,"user_tz":-120,"elapsed":2364,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"8cb52d3e-6acd-49c3-81a6-47d5c684a385"},"source":["linear_svm(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":176,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.592\n","Precision: 0.694\n","Recall: 0.592\n","F_score: 0.623\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.61      0.69       532\n","           1       0.30      0.55      0.39       162\n","\n","    accuracy                           0.59       694\n","   macro avg       0.56      0.58      0.54       694\n","weighted avg       0.69      0.59      0.62       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IBbKj5cQVywX","executionInfo":{"status":"ok","timestamp":1635266510664,"user_tz":-120,"elapsed":7401,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"4c395a3c-40cf-4083-b74a-a640d2abe70d"},"source":["logistic_regression_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":177,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.598\n","Precision: 0.680\n","Recall: 0.598\n","F_score: 0.626\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.63      0.71       532\n","           1       0.29      0.48      0.36       162\n","\n","    accuracy                           0.60       694\n","   macro avg       0.54      0.56      0.53       694\n","weighted avg       0.68      0.60      0.63       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_FTPo-KVywX","executionInfo":{"status":"ok","timestamp":1635267133846,"user_tz":-120,"elapsed":623194,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"0f0eef2a-c864-4477-aed0-fb0144bc3ef6"},"source":["nonlinear_svm_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":178,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.765\n","Precision: 0.587\n","Recall: 0.765\n","F_score: 0.665\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.77      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgtxcEx-VywX","executionInfo":{"status":"ok","timestamp":1635267290899,"user_tz":-120,"elapsed":157096,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"db1354ba-e217-4271-d322-573959891f1f"},"source":["linear_svm_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":179,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.741\n","Precision: 0.663\n","Recall: 0.741\n","F_score: 0.681\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.94      0.85       532\n","           1       0.30      0.09      0.13       162\n","\n","    accuracy                           0.74       694\n","   macro avg       0.54      0.51      0.49       694\n","weighted avg       0.66      0.74      0.68       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"bFE7-MeGXlhm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKsYzMRpXlv7","executionInfo":{"status":"ok","timestamp":1635270646191,"user_tz":-120,"elapsed":412,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["def word_vector_for_sent(list_token_embeddings, size):\n","      vec = np.zeros(size).reshape((1, size))\n","      count = 0\n","      for word in list_token_embeddings:\n","          try:\n","              # print(model_w2v[word].shape)\n","              vec += np.array(word).reshape((1, size))\n","              count += 1.\n","          except KeyError:  # handling the case where the token is not in vocabulary\n","              continue\n","      if count != 0:\n","          vec /= count\n","      return vec"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"EJIGsXxGXlyO","executionInfo":{"status":"ok","timestamp":1635270648215,"user_tz":-120,"elapsed":2,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n"," \n"," \n","def get_word_idx(sent: str, word: str):\n","    diff_vals=sent.split(\" \")\n","    idxs=np.arange(start=0, stop=len(diff_vals), step=1)\n","\n","    return idxs\n","\n","\n","def get_hidden_states(encoded, token_ids_word, model, layers):\n","    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n","      Select only those subword token outputs that belong to our word of interest\n","      and average them.\"\"\"\n","    with torch.no_grad():\n","        output = model(**encoded)\n","\n","    # Get all hidden states\n","    states = output.hidden_states\n","    # Stack and sum all requested layers\n","    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n","    # print(output.shape)\n","    # Only select the tokens that constitute the requested word\n","    # word_tokens_output = output[token_ids_word]\n","\n","    return word_vector_for_sent(output,output.shape[1])\n","\n","\n","def get_word_vector(sent, idx, tokenizer, model, layers):\n","    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n","      that make up the word of interest, and then `get_hidden_states`.\"\"\"\n","    encoded = tokenizer(sent, return_tensors=\"pt\")\n","    # get all token idxs that belong to the word of interest\n","    token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n","    # print(encoded,token_ids_word)\n","\n","    return get_hidden_states(encoded, token_ids_word, model, layers)\n","\n","\n","def Run(model_name='bert-base-cased',layers=None):\n","    # Use last four layers by default\n","    layers = [-4, -3, -2, -1] if layers is None else layers\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n","\n","    embedding_train=[]\n","    for text in train['tweet'].values:    \n","      idx = get_word_idx(text, '')\n","      # print(len(idx))\n","      word_embedding = get_word_vector(text, idx, tokenizer, model, layers)\n","      # print(word_embedding)\n","      embedding_train.append(word_embedding)\n","    embedding_test=[]\n","    for text in test['tweet'].values:    \n","      idx = get_word_idx(text, ' ')\n","      word_embedding = get_word_vector(text, idx, tokenizer, model, layers)\n","      embedding_test.append(word_embedding)\n","    \n","    return embedding_train, embedding_test"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_SiZvoRnuMBC","executionInfo":{"status":"ok","timestamp":1635270652350,"user_tz":-120,"elapsed":569,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"bde47daf-e8ec-4335-b5b7-1e5f6a1c5471"},"source":["import gc\n","gc.collect()"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["129"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYomTGzgmVJd","executionInfo":{"status":"ok","timestamp":1635271214699,"user_tz":-120,"elapsed":561002,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"e6633c14-e99a-4d4e-93b3-6c0528d07452"},"source":["embedding_train, embedding_test= Run(\"xlm-roberta-base\")"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"]}]},{"cell_type":"code","metadata":{"id":"jZnz37VpXl1W","executionInfo":{"status":"ok","timestamp":1635268185795,"user_tz":-120,"elapsed":42990,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["# from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","# def mean_pooling(model_output, attention_mask):\n","#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","#     sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","#     sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","#     return sum_embeddings / sum_mask\n","  \n","# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","# model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"-W58IkHoYKoJ"},"source":["# embedding_train=[]\n","# for text in train['tweet'].values:\n","#   encoded_input = tokenizer(text, return_tensors='pt')\n","#   model_output = model(**encoded_input)\n","#   # print(mean_pooling(model_output, encoded_input['attention_mask']).shape)\n","#   embedding_train.append(mean_pooling(model_output, encoded_input['attention_mask'])[:700])\n","# # embedding_train=np.array(embedding_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-H7n9d6zYSjw"},"source":["# embedding_test=[]\n","# for text in test['tweet'].values:\n","#   encoded_input = tokenizer(text, return_tensors='pt')\n","#   model_output = model(**encoded_input)\n","#   embedding_test.append(mean_pooling(model_output, encoded_input['attention_mask'])[:700])\n","# embedding_test=np.array(embedding_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bAPu1lfwt3y","executionInfo":{"status":"ok","timestamp":1635271306019,"user_tz":-120,"elapsed":741,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["embedding_train=np.array(embedding_train)\n","embedding_test=np.array(embedding_test)"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"aN5T4GK3w10z","executionInfo":{"status":"ok","timestamp":1635271308324,"user_tz":-120,"elapsed":3,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["embedding_train=np.squeeze(embedding_train)\n","embedding_test=np.squeeze(embedding_test)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"2v5bPQRVYb6i","executionInfo":{"status":"ok","timestamp":1635271312145,"user_tz":-120,"elapsed":520,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_df_new = pd.DataFrame(embedding_train)"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATaSNCjGYb6j","executionInfo":{"status":"ok","timestamp":1635271317695,"user_tz":-120,"elapsed":1391,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":["wordvec_df_test= pd.DataFrame(embedding_test)"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhERdIjlYb6j","executionInfo":{"status":"ok","timestamp":1635271586132,"user_tz":-120,"elapsed":265847,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"93552b89-1b3c-42c1-a051-5de8a96002cb"},"source":["gradient_boosting(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Gradient Boosting\n","==================================================================\n","\n","Accuracy: 0.695\n","Precision: 0.667\n","Recall: 0.695\n","F_score: 0.679\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.84      0.81       532\n","           1       0.30      0.22      0.25       162\n","\n","    accuracy                           0.69       694\n","   macro avg       0.54      0.53      0.53       694\n","weighted avg       0.67      0.69      0.68       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wr5CVHMTYb6k","executionInfo":{"status":"ok","timestamp":1635271627309,"user_tz":-120,"elapsed":39513,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"6c89c4e9-6a65-4dea-9f92-c0684de43d6d"},"source":["Bagging_Classifier_SVM(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.690\n","Precision: 0.718\n","Recall: 0.690\n","F_score: 0.702\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.76      0.79       532\n","           1       0.37      0.47      0.41       162\n","\n","    accuracy                           0.69       694\n","   macro avg       0.60      0.61      0.60       694\n","weighted avg       0.72      0.69      0.70       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saJCR6NYYb6l","executionInfo":{"status":"ok","timestamp":1635271631169,"user_tz":-120,"elapsed":3891,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"6d472d20-e119-4671-952a-3af921470900"},"source":["Bagging_Classifier_LR(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Bagging Calssifier LR\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.667\n","Precision: 0.723\n","Recall: 0.667\n","F_score: 0.687\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.71      0.77       532\n","           1       0.36      0.54      0.43       162\n","\n","    accuracy                           0.67       694\n","   macro avg       0.60      0.62      0.60       694\n","weighted avg       0.72      0.67      0.69       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wbMMEvPYb6l","executionInfo":{"status":"ok","timestamp":1635271796174,"user_tz":-120,"elapsed":165024,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"e7a10e1c-a721-4c51-d1d8-afdc8038b01b"},"source":["voting_classifiers(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","   Voting Classifier\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[18:07:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.780\n","Precision: 0.747\n","Recall: 0.780\n","F_score: 0.731\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.96      0.87       532\n","           1       0.59      0.18      0.27       162\n","\n","    accuracy                           0.78       694\n","   macro avg       0.69      0.57      0.57       694\n","weighted avg       0.75      0.78      0.73       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSl2spdPYb6l","executionInfo":{"status":"ok","timestamp":1635272537235,"user_tz":-120,"elapsed":741079,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"fec29e70-3e4c-46d0-9153-9ad822632ba0"},"source":["ensemble_stacked(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","Ensemble Stacked Classifiers\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[18:09:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[18:12:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[18:14:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[18:16:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[18:18:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[18:20:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.777\n","Precision: 0.749\n","Recall: 0.777\n","F_score: 0.708\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.98      0.87       532\n","           1       0.64      0.10      0.17       162\n","\n","    accuracy                           0.78       694\n","   macro avg       0.71      0.54      0.52       694\n","weighted avg       0.75      0.78      0.71       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpBMCWsFYb6m","executionInfo":{"status":"ok","timestamp":1635272694836,"user_tz":-120,"elapsed":157626,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"5b91ddbd-9ad5-49e3-8350-c381bc34897f"},"source":["xg_boost(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'])"],"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","             XGBoost\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[18:22:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","Accuracy: 0.762\n","Precision: 0.716\n","Recall: 0.762\n","F_score: 0.719\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.94      0.86       532\n","           1       0.48      0.18      0.26       162\n","\n","    accuracy                           0.76       694\n","   macro avg       0.63      0.56      0.56       694\n","weighted avg       0.72      0.76      0.72       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWosUnMvYb6m","executionInfo":{"status":"ok","timestamp":1635272723663,"user_tz":-120,"elapsed":28850,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"ce6221e5-f48e-4d9a-e5df-85a42f7aa65a"},"source":["random_forest(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Random Forest\n","==================================================================\n","\n","Accuracy: 0.765\n","Precision: 0.587\n","Recall: 0.765\n","F_score: 0.665\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      1.00      0.87       532\n","           1       0.00      0.00      0.00       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.38      0.50      0.43       694\n","weighted avg       0.59      0.77      0.66       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSLb4qYiYb6m","executionInfo":{"status":"ok","timestamp":1635272724210,"user_tz":-120,"elapsed":568,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"142ecb6f-3ac3-43bb-812c-0b29090194d9"},"source":["logistic_regression(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n","Accuracy: 0.654\n","Precision: 0.732\n","Recall: 0.654\n","F_score: 0.678\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.67      0.75       532\n","           1       0.36      0.60      0.45       162\n","\n","    accuracy                           0.65       694\n","   macro avg       0.60      0.63      0.60       694\n","weighted avg       0.73      0.65      0.68       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rj-4RAecYb6n","executionInfo":{"status":"ok","timestamp":1635272730820,"user_tz":-120,"elapsed":6627,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"1f98fb03-26e8-4651-9cb4-9d5a5350c85a"},"source":["linear_svm(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n","Accuracy: 0.653\n","Precision: 0.718\n","Recall: 0.653\n","F_score: 0.675\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.69      0.75       532\n","           1       0.35      0.54      0.42       162\n","\n","    accuracy                           0.65       694\n","   macro avg       0.59      0.61      0.59       694\n","weighted avg       0.72      0.65      0.67       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsULykc9Yb6n","executionInfo":{"status":"ok","timestamp":1635272740040,"user_tz":-120,"elapsed":9241,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"bca886a3-5618-44e1-a9bf-6b22169ab8ae"},"source":["logistic_regression_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n"," Logistic Regression\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.650\n","Precision: 0.714\n","Recall: 0.650\n","F_score: 0.672\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.69      0.75       532\n","           1       0.34      0.53      0.41       162\n","\n","    accuracy                           0.65       694\n","   macro avg       0.58      0.61      0.58       694\n","weighted avg       0.71      0.65      0.67       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RntB0-xYb6n","executionInfo":{"status":"ok","timestamp":1635273389586,"user_tz":-120,"elapsed":649576,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"cf578332-c0f4-40c8-ce6a-059622dd5c51"},"source":["nonlinear_svm_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","       Nonlinear SVM\n","==================================================================\n","\n","Accuracy: 0.772\n","Precision: 0.734\n","Recall: 0.772\n","F_score: 0.731\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.95      0.86       532\n","           1       0.53      0.20      0.29       162\n","\n","    accuracy                           0.77       694\n","   macro avg       0.66      0.57      0.58       694\n","weighted avg       0.73      0.77      0.73       694\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zWsPMJFYb6o","executionInfo":{"status":"ok","timestamp":1635273540930,"user_tz":-120,"elapsed":151373,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}},"outputId":"87f33a99-ab55-47f1-edca-79a191f87ee4"},"source":["linear_svm_grid(wordvec_df_new,train['sarcastic'],wordvec_df_test,test['sarcastic'],class_ratio='balanced')"],"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================================\n","          Linear SVM\n","==================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.739\n","Precision: 0.711\n","Recall: 0.739\n","F_score: 0.721\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.88      0.84       532\n","           1       0.41      0.28      0.34       162\n","\n","    accuracy                           0.74       694\n","   macro avg       0.61      0.58      0.59       694\n","weighted avg       0.71      0.74      0.72       694\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"MLCRQHyQYb6o","executionInfo":{"status":"ok","timestamp":1635273540931,"user_tz":-120,"elapsed":26,"user":{"displayName":"brain pinky","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64","userId":"06438107502629971890"}}},"source":[""],"execution_count":79,"outputs":[]}]}