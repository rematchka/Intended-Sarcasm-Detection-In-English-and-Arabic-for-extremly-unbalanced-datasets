{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08esTFOYO99"
      },
      "source": [
        "# Main imports and code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnHQoayhBYlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7491b65d-b42a-4e95-89ed-1cb11854880c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 14 14:18:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check which gpu we're using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYhFR7nSYOjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f08706-f930-4e45-c070-1445122d615c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip  install transformers\n",
        "!pip install pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJC8wj73Zd_p"
      },
      "outputs": [],
      "source": [
        "# Any results you write to the current directory are saved as output.\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "from transformers import BertTokenizer,BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from argparse import ArgumentParser\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.engine.engine import Engine, State, Events\n",
        "from ignite.handlers import EarlyStopping\n",
        "from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n",
        "from ignite.utils import convert_tensor\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvKeryw3eQPw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utils\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fezs8xASSS28"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3FDM6BjTLwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa193b39-635a-484c-e48d-5e83b96aaced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSzWEX54ScQi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2J-Qx3ekn_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae6aa33-c7bd-43f3-dafe-a754aa1cb656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "oT2dbUWN294h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3c87a9-57a7-4e44-fb42-0366df55543f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 39.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169313 sha256=5996be1a8da8e715271b173b79d38d17b627e2f39b47dc2f1632d9522ca21ed9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from emoji import demojize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "\n",
        "def normalizeToken(token):\n",
        "    lowercased_token = token.lower()\n",
        "    if token.startswith(\"@\"):\n",
        "        return \"@USER\"\n",
        "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "        return \"HTTPURL\"\n",
        "    elif len(token) == 1:\n",
        "        return demojize(token)\n",
        "    else:\n",
        "        if token == \"’\":\n",
        "            return \"'\"\n",
        "        elif token == \"…\":\n",
        "            return \"...\"\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "\n",
        "def normalizeTweet(tweet):\n",
        "    tweet=str(tweet)\n",
        "    tokens = tokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
        "\n",
        "    normTweet = (\n",
        "        normTweet.replace(\"cannot \", \"can not \")\n",
        "        .replace(\"n't \", \" n't \")\n",
        "        .replace(\"n 't \", \" n't \")\n",
        "        .replace(\"ca n't\", \"can't\")\n",
        "        .replace(\"ai n't\", \"ain't\")\n",
        "    )\n",
        "    normTweet = (\n",
        "        normTweet.replace(\"'m \", \" 'm \")\n",
        "        .replace(\"'re \", \" 're \")\n",
        "        .replace(\"'s \", \" 's \")\n",
        "        .replace(\"'ll \", \" 'll \")\n",
        "        .replace(\"'d \", \" 'd \")\n",
        "        .replace(\"'ve \", \" 've \")\n",
        "    )\n",
        "    normTweet = (\n",
        "        normTweet.replace(\" p . m .\", \"  p.m.\")\n",
        "        .replace(\" p . m \", \" p.m \")\n",
        "        .replace(\" a . m .\", \" a.m.\")\n",
        "        .replace(\" a . m \", \" a.m \")\n",
        "    )\n",
        "\n",
        "    return \" \".join(normTweet.split())"
      ],
      "metadata": {
        "id": "7T6tMzSaeBmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/ISarcasm/DataSet/train.En.csv')\n",
        "df['clean_text']=df['tweet'].apply(normalizeTweet)\n",
        "df=df[['clean_text','sarcastic']]\n"
      ],
      "metadata": {
        "id": "VjoRy3-22MLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, validate, test = \\\n",
        "              np.split(df.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(df)), int(.8*len(df))])"
      ],
      "metadata": {
        "id": "y6Fd8UBBdTQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.concat([train, validate], ignore_index=True)"
      ],
      "metadata": {
        "id": "PJrh2l2qdXf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tedf1.to_csv('/content/drive/MyDrive/PCL/test_task_1',index=False)"
      ],
      "metadata": {
        "id": "X5DMNjrTGT8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trdf1.to_csv('/content/drive/MyDrive/PCL/train_task_1',index=False)"
      ],
      "metadata": {
        "id": "l18cECm4GhQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6FY70KZ6TY"
      },
      "source": [
        "# RoBERTa Baseline for Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA9QzHTCl5F6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlT2IDHumPNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1429b420-9ea2-45a3-da45-fab446af2070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 306 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 78.1 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 65.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 56.1 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2022.1.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-E_jNQbV_NL"
      },
      "outputs": [],
      "source": [
        "class PCLTrainDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length,displacemnt):\n",
        "        self.df = df\n",
        "        self.max_len = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = df['clean_text'].values\n",
        "        self.label=df['sarcastic'].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        # summary = self.summary[index]\n",
        "        inputs_text = self.tokenizer.encode_plus(\n",
        "                                text,\n",
        "                                truncation=True,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length=self.max_len,\n",
        "                                padding='max_length'\n",
        "                            )\n",
        "        \n",
        "                            \n",
        "        target = self.label[index]\n",
        "        \n",
        "        text_ids = inputs_text['input_ids']\n",
        "        text_mask = inputs_text['attention_mask']\n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "        return {\n",
        "            \n",
        "            'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
        "            'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
        "            'target': torch.tensor(target, dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "    return 1/(1+math.exp(-x))"
      ],
      "metadata": {
        "id": "WLXkQK5Bawae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Recall_Loss(nn.Module):\n",
        "    '''Calculate F1 score. Can work with gpu tensors\n",
        "    \n",
        "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        `ndim` == 1. epsilon <= val <= 1\n",
        "    \n",
        "    Reference\n",
        "    ---------\n",
        "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
        "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
        "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n",
        "    '''\n",
        "    def __init__(self, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true,):\n",
        "        # assert y_pred.ndim == 2\n",
        "        # assert y_true.ndim == 1\n",
        "        # print(y_pred.shape)\n",
        "        # print(y_true.shape)\n",
        "        # y_pred[y_pred<0.5]=0\n",
        "        # y_pred[y_pred>=0.5]=0\n",
        "\n",
        "\n",
        "        \n",
        "        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2).to(torch.float32)\n",
        "        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n",
        "        \n",
        "        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        # f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
        "        # f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        # f1=f1.detach()\n",
        "        # print(f1.shape)\n",
        "        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n",
        "        # y_true=y_true.reshape((y_true.shape[0], 1))\n",
        "\n",
        "        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n",
        "        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n",
        "\n",
        "\n",
        "        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n",
        "        # print(y_pred)\n",
        "        # print(y_true_one_hot)\n",
        "        recall=recall.detach()\n",
        "        CE =torch.nn.CrossEntropyLoss(weight=( 1 - recall))(y_pred, y_true_one_hot)\n",
        "        # loss = ( 1 - f1)  * CE\n",
        "        return  CE.mean()"
      ],
      "metadata": {
        "id": "skGp5I4wM_Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZa-chAxXf5r"
      },
      "outputs": [],
      "source": [
        "class PCL_Model_Arch(nn.Module):\n",
        "    def __init__(self,pre_trained='bert-base-cased'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = AutoModel.from_pretrained(pre_trained, output_hidden_states=True)\n",
        "        output_channel = 16  # number of kernels\n",
        "        num_classes = 2  # number of targets to predict\n",
        "        dropout = 0.2  # dropout value\n",
        "        embedding_dim = 768   # length of embedding dim\n",
        "\n",
        "        ks = 3  # three conv nets here\n",
        "\n",
        "        # input_channel = word embeddings at a value of 1; 3 for RGB images\n",
        "        input_channel = 4  # for single embedding, input_channel = 1\n",
        "\n",
        "        # [3, 4, 5] = window height\n",
        "        # padding = padding to account for height of search window\n",
        "\n",
        "        # 3 convolutional nets\n",
        "        self.conv1 = nn.Conv2d(input_channel, output_channel, (3, embedding_dim), padding=(2, 0), groups=4)\n",
        "        self.conv2 = nn.Conv2d(input_channel, output_channel, (4, embedding_dim), padding=(3, 0), groups=4)\n",
        "        self.conv3 = nn.Conv2d(input_channel, output_channel, (5, embedding_dim), padding=(4, 0), groups=4)\n",
        "\n",
        "        # apply dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fully connected layer for classification\n",
        "        # 3x conv nets * output channel\n",
        "        self.fc1 = nn.Linear(ks * output_channel, num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, text_id, text_mask):\n",
        "        # get the last 4 layers\n",
        "        outputs= self.bert(text_id, attention_mask=text_mask)\n",
        "        # all_layers  = [4, 16, 256, 768]\n",
        "        hidden_layers = outputs[2]  # get hidden layers\n",
        "\n",
        "        hidden_layers = torch.stack(hidden_layers, dim=1)\n",
        "        x = hidden_layers[:, -4:] \n",
        "        # x = x.unsqueeze(1)\n",
        "        # x = torch.mean(x, 0)\n",
        "        # print(hidden_layers.size())\n",
        "      \n",
        "        torch.cuda.empty_cache()\n",
        "        x = [F.relu(self.conv1(x)).squeeze(3), F.relu(self.conv2(x)).squeeze(3), F.relu(self.conv3(x)).squeeze(3)]\n",
        "        # max-over-time pooling; # (batch, channel_output) * ks\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "        # concat results; (batch, channel_output * ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        # add dropout\n",
        "        x = self.dropout(x)\n",
        "        # generate logits (batch, target_size)\n",
        "        logit = self.fc1(x)\n",
        "        torch.cuda.empty_cache()\n",
        "        return self.softmax(logit)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class PCL_Model_Arch(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(PCL_Model_Arch, self).__init__()\n",
        "#         self.bert = AutoModel.from_pretrained('google/canine-c', output_hidden_states=False)\n",
        "#         self.drop = nn.Dropout(p=0.2)\n",
        "#         self.fc = nn.Linear(768, 2)\n",
        "\n",
        "        \n",
        "#         self.softmax = nn.Softmax()\n",
        "\n",
        "#     def forward(self, text_id, text_mask):\n",
        "#         # get the last 4 layers\n",
        "#         outputs= self.bert(text_id, attention_mask=text_mask)\n",
        "#         # all_layers  = [4, 16, 256, 768]\n",
        "#         hidden_layers = outputs[1]  # get hidden layers\n",
        "#         torch.cuda.empty_cache()\n",
        "\n",
        "        \n",
        "#         x = self.drop(hidden_layers)\n",
        "#         torch.cuda.empty_cache()\n",
        "#         # generate logits (batch, target_size)\n",
        "#         logit = self.fc(x)\n",
        "#         torch.cuda.empty_cache()\n",
        "#         return self.softmax(logit)"
      ],
      "metadata": {
        "id": "IfQwNPiRx_6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuODW43NYhTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f5dbdc0dc7d04f818fcebdffda6885b3",
            "136430824d604e61b8f337be55095c52",
            "d4baed5bd5454abeb0130c2e5ed444f4",
            "5d4719a7f2f54d81b246ca4e5b20d1df",
            "697f59b2a0a846e6b6a6146b8e0561d1",
            "9c62f7aeb00542af8c3ff26dd3d713c4",
            "82e1523f809248d4ad1e32d19c639760",
            "963983e526154684bccd4bdfc071becb",
            "e9ab4e63d3564ce5bfee2a0088c1b5a6",
            "fc9382cf1f6e42f49f8a472630554756",
            "4df0949669d64925b3d7ecab5c2c7da8",
            "feb3d65291394d528bacd330aeaa4457",
            "2b459dc7924a4eaaa801421633713199",
            "4a8784b17f5f4577bb7ab30af5dd425f",
            "f4e99795fc1240ee940f91325a0b784b",
            "ee799c6a34914470824fc2b800389d51",
            "19b1d3b927714cccabcdb297ae5ff9a6",
            "9c5822d480124cd58d02cca44cf48611",
            "b34c784d41054d5da9a456feff370daf",
            "fdf1eb1297a94fa48e4dba3a728b0266",
            "dff1bc74e98e41c49128b405cfaab836",
            "1f31320bd7c14b86ac1cd7ff04c779a3",
            "ef94eea500b94bf4813379c3c79cbfec",
            "0d31126381ff4a0295e31d80396cdcf8",
            "03cb9dd2b59a41738aad83ea4b35d65d",
            "6d5d7c0ff910449e83ad5a8a16d71e7f",
            "5e14b34dafc441c692bfb9062107c30e",
            "4d393230d3364f348b8b61b32835f69e",
            "9a920f52735d46a6a4995ae3a8de01c7",
            "db5bc8182cd048ee98fe85bd10b5c99a",
            "da4337e500114bee8d9fd0f0e5b2ee8a",
            "3e6e45a633074078b23cf22006dd9d98",
            "4b6ca0b127cc4df1a6afa7928d67d792",
            "435bd88ce35a445ea89c421888a72cd9",
            "e81a583bf2c34bc9b8e452959a2976f4",
            "6418c56fa86841cdb467ddbd6aa97dff",
            "79fb9710d5064c4aab5194be21c32e0b",
            "ac5e088d98ca42c8abd5d918d4664e4e",
            "4eeeb7658c034117933a5a13dc1442b5",
            "0160be6458c1445b8f7a87dd593f515d",
            "8521ea5ca56d42ada7898dfa31013d45",
            "1a972d51403f4ee39cae309226d1fd41",
            "bcd20c55932e45b2ac0275013f4332b3",
            "08ff2b0a8a85482783ecbd9cc7c297a6"
          ]
        },
        "outputId": "40ca838b-aaaf-483e-8d34-4672bbe035bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5dbdc0dc7d04f818fcebdffda6885b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feb3d65291394d528bacd330aeaa4457",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef94eea500b94bf4813379c3c79cbfec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "435bd88ce35a445ea89c421888a72cd9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer= AutoTokenizer.from_pretrained('bert-base-cased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0XUHerFY2jd"
      },
      "outputs": [],
      "source": [
        "def criterion(outputs1,  targets):\n",
        "\n",
        "    criterion = Recall_Loss()\n",
        "    loss = criterion(outputs1, targets)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
        "    \"\"\"\n",
        "    Samples elements randomly from a given list of indices for imbalanced dataset\n",
        "    Arguments:\n",
        "        indices (list, optional): a list of indices\n",
        "        num_samples (int, optional): number of samples to draw\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, indices=None, num_samples=None):\n",
        "        # if indices is not provided,\n",
        "        # all elements in the dataset will be considered\n",
        "        self.indices = list(range(len(dataset.sarcastic))) \\\n",
        "            if indices is None else indices\n",
        "\n",
        "        # if num_samples is not provided,\n",
        "        # draw `len(indices)` samples in each iteration\n",
        "        self.num_samples = len(self.indices) \\\n",
        "            if num_samples is None else num_samples\n",
        "\n",
        "        # distribution of classes in the dataset\n",
        "        label_to_count = {}\n",
        "        for idx in self.indices:\n",
        "            label = self._get_label(dataset, idx)\n",
        "            if label in label_to_count:\n",
        "                label_to_count[label] += 1\n",
        "            else:\n",
        "                label_to_count[label] = 1\n",
        "\n",
        "        # weight for each sample\n",
        "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n",
        "        self.weights = torch.DoubleTensor(weights)\n",
        "\n",
        "    def _get_label(self, dataset, id_):\n",
        "        return dataset.sarcastic[id_]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "metadata": {
        "id": "Zeh7f_UdC6dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRX0b55VaxmS"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\"seed\": 2021,\n",
        "          \"epochs\": 3,\n",
        "          \"model_name\": \"bert-base-cased\",\n",
        "          \"train_batch_size\": 16,\n",
        "          \"valid_batch_size\": 64,\n",
        "          \"max_length\": 256,\n",
        "          \"learning_rate\": 1e-4,\n",
        "          \"scheduler\": 'CosineAnnealingLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"num_classes\": 1,\n",
        "          \"margin\": 0.5,\n",
        "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4afl1P8LaD07"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        \n",
        "        text_ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        text_mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        targets = data['target'].to(device, dtype=torch.long)\n",
        "        # print(text_ids.shape)\n",
        "        \n",
        "        batch_size = text_ids.size(0)\n",
        "        # print(targets)\n",
        "\n",
        "        outputs = model(text_ids, text_mask)\n",
        "        # print(outputs.shape)\n",
        "        \n",
        "        # print(outputs.shape)\n",
        "\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        loss = loss / CONFIG['n_accumulate']\n",
        "        loss.backward()\n",
        "    \n",
        "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
        "            optimizer.step()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
        "                        LR=optimizer.param_groups[0]['lr'])\n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdWI_KWRafLZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:        \n",
        "        \n",
        "        text_ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        text_mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        targets = data['target'].to(device, dtype=torch.long)\n",
        "        # print(text_ids.shape)\n",
        "       \n",
        "        \n",
        "        batch_size = text_ids.size(0)\n",
        "\n",
        "        outputs = model(text_ids, text_mask)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "        # print(outputs.shape)\n",
        "        # print(targets.shape)\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
        "                        LR=optimizer.param_groups[0]['lr'])   \n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1wtBAJJbEou"
      },
      "outputs": [],
      "source": [
        "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
        "    # To automatically log gradients\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "    \n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1): \n",
        "        gc.collect()\n",
        "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           device=CONFIG['device'], epoch=epoch)\n",
        "        \n",
        "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
        "                                         epoch=epoch)\n",
        "    \n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "        \n",
        "       \n",
        "        \n",
        "        # deep copy the model\n",
        "        if val_epoch_loss <= best_epoch_loss:\n",
        "            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
        "            best_epoch_loss = val_epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = f\"/content/drive/MyDrive/ISarcasm/Models/xlnet_based_model/Loss-Fold-{fold}.bin\"\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            # Save a model file from the current directory\n",
        "            print(\"Model Saved\")\n",
        "            \n",
        "        print()\n",
        "    \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
        "    \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSXiJa2-bRiX"
      },
      "outputs": [],
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
        "                                                   eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
        "                                                             eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6nXhK_ObVNe"
      },
      "outputs": [],
      "source": [
        "def prepare_loaders(fold):\n",
        "    displacemnt_list=[0,512,1024,1536,2048,2560,3072,3584,4096,4608,4950]\n",
        "    df_train = train[train.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = train[train.kfold == fold].reset_index(drop=True)\n",
        "    sampler = ImbalancedDatasetSampler(df_train)\n",
        "    \n",
        "    train_dataset = PCLTrainDataset(df_train, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=displacemnt_list[fold])\n",
        "    valid_dataset = PCLTrainDataset(df_valid, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=displacemnt_list[fold])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True, drop_last=True,sampler=sampler)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)\n",
        "    \n",
        "    return train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCN4vwBOeaLb"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
        "\n",
        "for fold, ( _, val_) in enumerate(skf.split(X=train, y=train.sarcastic)):\n",
        "    train.loc[val_ , \"kfold\"] = int(fold)\n",
        "    \n",
        "train[\"kfold\"] = train[\"kfold\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOtw3nW-2X58"
      },
      "outputs": [],
      "source": [
        "# del model,train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoQghNKN2Cy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c6e7a4-e158-4878-d29d-b6a56780284a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://seekinginference.com/applied_nlp/bert-cnn.html"
      ],
      "metadata": {
        "id": "QCwmBcvPlNaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXC4SsiDbbGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180bf44c-b29d-413f-d26d-9c397b2fea89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== Fold: 1 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:15<00:00,  9.25s/it, Epoch=1, LR=8.25e-5, Train_Loss=0.279]\n",
            "100%|██████████| 9/9 [00:28<00:00,  3.13s/it, Epoch=1, LR=8.25e-5, Valid_Loss=0.267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.2671384742668083)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:15<00:00,  9.24s/it, Epoch=2, LR=4.24e-5, Train_Loss=0.113]\n",
            "100%|██████████| 9/9 [00:28<00:00,  3.12s/it, Epoch=2, LR=4.24e-5, Valid_Loss=0.292]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:14<00:00,  9.23s/it, Epoch=3, LR=8.05e-6, Train_Loss=0.0422]\n",
            "100%|██████████| 9/9 [00:27<00:00,  3.11s/it, Epoch=3, LR=8.05e-6, Valid_Loss=0.237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.2671384742668083 ---> 0.23671568014600256)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 1h 5m 18s\n",
            "Best Loss: 0.2367\n",
            "\n",
            "====== Fold: 2 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:14<00:00,  9.23s/it, Epoch=1, LR=8.25e-5, Train_Loss=0.298]\n",
            "100%|██████████| 9/9 [00:28<00:00,  3.12s/it, Epoch=1, LR=8.25e-5, Valid_Loss=0.336]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.3363144699517671)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:14<00:00,  9.24s/it, Epoch=2, LR=4.24e-5, Train_Loss=0.152]\n",
            "100%|██████████| 9/9 [00:28<00:00,  3.11s/it, Epoch=2, LR=4.24e-5, Valid_Loss=0.258]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.3363144699517671 ---> 0.2581280060179599)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:15<00:00,  9.25s/it, Epoch=3, LR=8.05e-6, Train_Loss=0.051]\n",
            "100%|██████████| 9/9 [00:28<00:00,  3.11s/it, Epoch=3, LR=8.05e-6, Valid_Loss=0.231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.2581280060179599 ---> 0.23100227869308745)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 1h 5m 18s\n",
            "Best Loss: 0.2310\n",
            "\n",
            "====== Fold: 3 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [21:27<00:00,  9.33s/it, Epoch=1, LR=8.25e-5, Train_Loss=0.271]\n",
            "100%|██████████| 9/9 [00:28<00:00,  3.13s/it, Epoch=1, LR=8.25e-5, Valid_Loss=0.236]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.23589450786779592)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 115/138 [17:41<03:32,  9.23s/it, Epoch=2, LR=4.96e-5, Train_Loss=0.11]"
          ]
        }
      ],
      "source": [
        "for fold in range(1, CONFIG['n_fold']):\n",
        "    print(f\"====== Fold: {fold} ======\")\n",
        "\n",
        "    \n",
        "    # Create Dataloaders\n",
        "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
        "    \n",
        "    model = PCL_Model_Arch()\n",
        "    model.to(CONFIG['device'])\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Define Optimizer and Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
        "    scheduler = fetch_scheduler(optimizer)\n",
        "    \n",
        "    model, history = run_training(model, optimizer, scheduler,\n",
        "                                  device=CONFIG['device'],\n",
        "                                  num_epochs=CONFIG['epochs'],\n",
        "                                  fold=fold)\n",
        "    \n",
        "    \n",
        "    del model, history, train_loader, valid_loader\n",
        "    _ = gc.collect()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(3, CONFIG['n_fold']):\n",
        "    print(f\"====== Fold: {fold} ======\")\n",
        "\n",
        "    \n",
        "    # Create Dataloaders\n",
        "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
        "    \n",
        "    model = PCL_Model_Arch()\n",
        "    model.to(CONFIG['device'])\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Define Optimizer and Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
        "    scheduler = fetch_scheduler(optimizer)\n",
        "    \n",
        "    model, history = run_training(model, optimizer, scheduler,\n",
        "                                  device=CONFIG['device'],\n",
        "                                  num_epochs=CONFIG['epochs'],\n",
        "                                  fold=fold)\n",
        "    \n",
        "    \n",
        "    del model, history, train_loader, valid_loader\n",
        "    _ = gc.collect()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902,
          "referenced_widgets": [
            "e869e7641fdc4558950e5bf48fe753d4",
            "bd2dc0ca71504a2bbf6b7f6b64c8249e",
            "9a02280895d048a2b3bab28803eb00f9",
            "a4d42981292b484f9e28b9bd907fba83",
            "a13787e34df140d1a720e2d2891caee6",
            "63f482e70b45465f89d52f1ef0346383",
            "a1943ebee9a34e8298aa56360ce75e76",
            "2bef07c1f04c49569f5f0f9a991d60eb",
            "63a257f83eb34fdd88709bfe144fdd0f",
            "18e45dfc4f83498b813ecfc894fa1bab",
            "770f1f9bea874338970728f2d27deb3c"
          ]
        },
        "id": "soQSXwup9B6B",
        "outputId": "b2034333-9c20-4eaa-babc-bb5d98a60da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== Fold: 3 ======\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e869e7641fdc4558950e5bf48fe753d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:21<00:00,  1.90s/it, Epoch=1, LR=8.25e-5, Train_Loss=0.279]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.29s/it, Epoch=1, LR=8.25e-5, Valid_Loss=0.243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.24348884343026994)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=2, LR=4.24e-5, Train_Loss=0.132]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.29s/it, Epoch=2, LR=4.24e-5, Valid_Loss=0.208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.24348884343026994 ---> 0.20784927424009855)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=3, LR=8.05e-6, Train_Loss=0.0547]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.30s/it, Epoch=3, LR=8.05e-6, Valid_Loss=0.199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.20784927424009855 ---> 0.19883991635597503)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 0h 14m 5s\n",
            "Best Loss: 0.1988\n",
            "\n",
            "====== Fold: 4 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=1, LR=8.25e-5, Train_Loss=0.296]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.30s/it, Epoch=1, LR=8.25e-5, Valid_Loss=0.286]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.2855491978166766)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=2, LR=4.24e-5, Train_Loss=0.122]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.30s/it, Epoch=2, LR=4.24e-5, Valid_Loss=0.224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.2855491978166766 ---> 0.22390019312662338)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=3, LR=8.05e-6, Train_Loss=0.0483]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.30s/it, Epoch=3, LR=8.05e-6, Valid_Loss=0.221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.22390019312662338 ---> 0.22116129041148436)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 0h 14m 2s\n",
            "Best Loss: 0.2212\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(0, 1):\n",
        "    print(f\"====== Fold: {fold} ======\")\n",
        "\n",
        "    \n",
        "    # Create Dataloaders\n",
        "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
        "    \n",
        "    model = PCL_Model_Arch()\n",
        "    model.to(CONFIG['device'])\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Define Optimizer and Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
        "    scheduler = fetch_scheduler(optimizer)\n",
        "    \n",
        "    model, history = run_training(model, optimizer, scheduler,\n",
        "                                  device=CONFIG['device'],\n",
        "                                  num_epochs=CONFIG['epochs'],\n",
        "                                  fold=fold)\n",
        "    \n",
        "    \n",
        "    del model, history, train_loader, valid_loader\n",
        "    _ = gc.collect()\n",
        "    print()"
      ],
      "metadata": {
        "id": "6iS3tXLk-SCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f058f0d-3867-4b8a-ef28-fa23dc8b57e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== Fold: 0 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=1, LR=8.25e-5, Train_Loss=0.292]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.31s/it, Epoch=1, LR=8.25e-5, Valid_Loss=0.378]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.3781926797853934)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=2, LR=4.24e-5, Train_Loss=0.115]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.30s/it, Epoch=2, LR=4.24e-5, Valid_Loss=0.226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.3781926797853934 ---> 0.2262677931570792)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [04:26<00:00,  1.93s/it, Epoch=3, LR=8.05e-6, Train_Loss=0.0467]\n",
            "100%|██████████| 9/9 [00:11<00:00,  1.29s/it, Epoch=3, LR=8.05e-6, Valid_Loss=0.227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete in 0h 14m 1s\n",
            "Best Loss: 0.2263\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "XSvm2lLPAf0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = PCLTrainDataset(test, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "ujNNMM9HAGtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_fn(model, dataloader, device):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    PREDS = []\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        \n",
        "        outputs = model(ids, mask)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "#         print(len(outputs))\n",
        "#         print(len(np.max(outputs.cpu().detach().numpy(),axis=1)))\n",
        "        PREDS.append(outputs.detach().cpu().numpy()) \n",
        "    \n",
        "    PREDS = np.concatenate(PREDS)\n",
        "    gc.collect()\n",
        "    \n",
        "    return PREDS"
      ],
      "metadata": {
        "id": "piuXPwW433gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model_paths, dataloader, device):\n",
        "    final_preds = []\n",
        "    for i, path in enumerate(model_paths):\n",
        "        model = PCL_Model_Arch()\n",
        "        model.to(CONFIG['device'])\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        \n",
        "        print(f\"Getting predictions for model {i+1}\")\n",
        "        preds = valid_fn(model, dataloader, device)\n",
        "        final_preds.append(preds)\n",
        "    \n",
        "    final_preds = np.array(final_preds)\n",
        "    final_preds = np.mean(final_preds, axis=0)\n",
        "    final_preds= np.argmax(final_preds,axis=1)\n",
        "    return final_preds"
      ],
      "metadata": {
        "id": "zaxyuvUP3Md0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models/xlnet_based_model/Loss-Fold-0.bin','/content/drive/MyDrive/ISarcasm/Models/xlnet_based_model/Loss-Fold-1.bin','/content/drive/MyDrive/ISarcasm/Models/xlnet_based_model/Loss-Fold-2.bin','/content/drive/MyDrive/ISarcasm/Models/xlnet_based_model/Loss-Fold-3.bin','/content/drive/MyDrive/ISarcasm/Models/xlnet_based_model/Loss-Fold-4.bin']\n",
        "preds = inference(MODEL_PATH_2, valid_loader, CONFIG['device'])"
      ],
      "metadata": {
        "id": "-mbRltZW4Dvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c68e20-1a23-4cdf-eb80-98306a2b545b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:14<00:00,  1.30s/it]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:14<00:00,  1.36s/it]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:14<00:00,  1.34s/it]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:14<00:00,  1.33s/it]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:14<00:00,  1.31s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKQV51HyommQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import jaccard_score,f1_score,accuracy_score,recall_score,precision_score,classification_report\n",
        "def print_statistics(y, y_pred):\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision =precision_score(y, y_pred, average='weighted')\n",
        "    recall = recall_score(y, y_pred, average='weighted')\n",
        "    f_score = f1_score(y, y_pred, average='weighted')\n",
        "    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n",
        "          % (accuracy, precision, recall, f_score))\n",
        "    print(classification_report(y, y_pred))\n",
        "    return accuracy, precision, recall, f_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3965a5XAooJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2717229a-8b20-4ee3-e111-a64e2af28b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.741\n",
            "Precision: 0.721\n",
            "Recall: 0.741\n",
            "F_score: 0.729\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84       532\n",
            "           1       0.43      0.33      0.38       162\n",
            "\n",
            "    accuracy                           0.74       694\n",
            "   macro avg       0.62      0.60      0.61       694\n",
            "weighted avg       0.72      0.74      0.73       694\n",
            "\n",
            "(0.7406340057636888, 0.7208553917162921, 0.7406340057636888, 0.7286678019386955)\n"
          ]
        }
      ],
      "source": [
        "print(print_statistics(test['sarcastic'],preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8hjnxbbfJq"
      },
      "source": [
        "## Prepare submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7HICl8MJQf0"
      },
      "outputs": [],
      "source": [
        "!cat task1.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCjziGtxJRif"
      },
      "outputs": [],
      "source": [
        "!cat task2.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZDLUcYZbhYg"
      },
      "outputs": [],
      "source": [
        "!zip submission.zip task1.txt task2.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bert base cased+kim cnn+ recall CE loss+ Imbalance datasampler.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5dbdc0dc7d04f818fcebdffda6885b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_136430824d604e61b8f337be55095c52",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4baed5bd5454abeb0130c2e5ed444f4",
              "IPY_MODEL_5d4719a7f2f54d81b246ca4e5b20d1df",
              "IPY_MODEL_697f59b2a0a846e6b6a6146b8e0561d1"
            ]
          }
        },
        "136430824d604e61b8f337be55095c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4baed5bd5454abeb0130c2e5ed444f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c62f7aeb00542af8c3ff26dd3d713c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82e1523f809248d4ad1e32d19c639760"
          }
        },
        "5d4719a7f2f54d81b246ca4e5b20d1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_963983e526154684bccd4bdfc071becb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9ab4e63d3564ce5bfee2a0088c1b5a6"
          }
        },
        "697f59b2a0a846e6b6a6146b8e0561d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc9382cf1f6e42f49f8a472630554756",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 747B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4df0949669d64925b3d7ecab5c2c7da8"
          }
        },
        "9c62f7aeb00542af8c3ff26dd3d713c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82e1523f809248d4ad1e32d19c639760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "963983e526154684bccd4bdfc071becb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9ab4e63d3564ce5bfee2a0088c1b5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc9382cf1f6e42f49f8a472630554756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4df0949669d64925b3d7ecab5c2c7da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "feb3d65291394d528bacd330aeaa4457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b459dc7924a4eaaa801421633713199",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a8784b17f5f4577bb7ab30af5dd425f",
              "IPY_MODEL_f4e99795fc1240ee940f91325a0b784b",
              "IPY_MODEL_ee799c6a34914470824fc2b800389d51"
            ]
          }
        },
        "2b459dc7924a4eaaa801421633713199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a8784b17f5f4577bb7ab30af5dd425f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19b1d3b927714cccabcdb297ae5ff9a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c5822d480124cd58d02cca44cf48611"
          }
        },
        "f4e99795fc1240ee940f91325a0b784b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b34c784d41054d5da9a456feff370daf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdf1eb1297a94fa48e4dba3a728b0266"
          }
        },
        "ee799c6a34914470824fc2b800389d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dff1bc74e98e41c49128b405cfaab836",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 18.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f31320bd7c14b86ac1cd7ff04c779a3"
          }
        },
        "19b1d3b927714cccabcdb297ae5ff9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c5822d480124cd58d02cca44cf48611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b34c784d41054d5da9a456feff370daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdf1eb1297a94fa48e4dba3a728b0266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dff1bc74e98e41c49128b405cfaab836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f31320bd7c14b86ac1cd7ff04c779a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef94eea500b94bf4813379c3c79cbfec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d31126381ff4a0295e31d80396cdcf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03cb9dd2b59a41738aad83ea4b35d65d",
              "IPY_MODEL_6d5d7c0ff910449e83ad5a8a16d71e7f",
              "IPY_MODEL_5e14b34dafc441c692bfb9062107c30e"
            ]
          }
        },
        "0d31126381ff4a0295e31d80396cdcf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03cb9dd2b59a41738aad83ea4b35d65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d393230d3364f348b8b61b32835f69e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a920f52735d46a6a4995ae3a8de01c7"
          }
        },
        "6d5d7c0ff910449e83ad5a8a16d71e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db5bc8182cd048ee98fe85bd10b5c99a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da4337e500114bee8d9fd0f0e5b2ee8a"
          }
        },
        "5e14b34dafc441c692bfb9062107c30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e6e45a633074078b23cf22006dd9d98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 208k/208k [00:00&lt;00:00, 2.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b6ca0b127cc4df1a6afa7928d67d792"
          }
        },
        "4d393230d3364f348b8b61b32835f69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a920f52735d46a6a4995ae3a8de01c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db5bc8182cd048ee98fe85bd10b5c99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da4337e500114bee8d9fd0f0e5b2ee8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e6e45a633074078b23cf22006dd9d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b6ca0b127cc4df1a6afa7928d67d792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "435bd88ce35a445ea89c421888a72cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e81a583bf2c34bc9b8e452959a2976f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6418c56fa86841cdb467ddbd6aa97dff",
              "IPY_MODEL_79fb9710d5064c4aab5194be21c32e0b",
              "IPY_MODEL_ac5e088d98ca42c8abd5d918d4664e4e"
            ]
          }
        },
        "e81a583bf2c34bc9b8e452959a2976f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6418c56fa86841cdb467ddbd6aa97dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4eeeb7658c034117933a5a13dc1442b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0160be6458c1445b8f7a87dd593f515d"
          }
        },
        "79fb9710d5064c4aab5194be21c32e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8521ea5ca56d42ada7898dfa31013d45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a972d51403f4ee39cae309226d1fd41"
          }
        },
        "ac5e088d98ca42c8abd5d918d4664e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bcd20c55932e45b2ac0275013f4332b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426k/426k [00:00&lt;00:00, 4.61MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08ff2b0a8a85482783ecbd9cc7c297a6"
          }
        },
        "4eeeb7658c034117933a5a13dc1442b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0160be6458c1445b8f7a87dd593f515d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8521ea5ca56d42ada7898dfa31013d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a972d51403f4ee39cae309226d1fd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcd20c55932e45b2ac0275013f4332b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08ff2b0a8a85482783ecbd9cc7c297a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e869e7641fdc4558950e5bf48fe753d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd2dc0ca71504a2bbf6b7f6b64c8249e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a02280895d048a2b3bab28803eb00f9",
              "IPY_MODEL_a4d42981292b484f9e28b9bd907fba83",
              "IPY_MODEL_a13787e34df140d1a720e2d2891caee6"
            ]
          }
        },
        "bd2dc0ca71504a2bbf6b7f6b64c8249e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a02280895d048a2b3bab28803eb00f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63f482e70b45465f89d52f1ef0346383",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1943ebee9a34e8298aa56360ce75e76"
          }
        },
        "a4d42981292b484f9e28b9bd907fba83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2bef07c1f04c49569f5f0f9a991d60eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63a257f83eb34fdd88709bfe144fdd0f"
          }
        },
        "a13787e34df140d1a720e2d2891caee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18e45dfc4f83498b813ecfc894fa1bab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 416M/416M [00:07&lt;00:00, 53.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_770f1f9bea874338970728f2d27deb3c"
          }
        },
        "63f482e70b45465f89d52f1ef0346383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1943ebee9a34e8298aa56360ce75e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bef07c1f04c49569f5f0f9a991d60eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63a257f83eb34fdd88709bfe144fdd0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e45dfc4f83498b813ecfc894fa1bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "770f1f9bea874338970728f2d27deb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}