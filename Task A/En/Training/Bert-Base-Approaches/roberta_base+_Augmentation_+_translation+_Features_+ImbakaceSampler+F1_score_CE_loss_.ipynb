{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08esTFOYO99"
      },
      "source": [
        "# Main imports and code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnHQoayhBYlm",
        "outputId": "0c7d68b6-4b18-4882-d5ad-e87390b645e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 29 15:56:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    70W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check which gpu we're using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nlpaug"
      ],
      "metadata": {
        "id": "Ck2SJM-uKdgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYhFR7nSYOjG",
        "outputId": "a358bfae-910b-4258-9712-0177928b8709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.8)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip  install transformers\n",
        "!pip install pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJC8wj73Zd_p"
      },
      "outputs": [],
      "source": [
        "# Any results you write to the current directory are saved as output.\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "from transformers import BertTokenizer,BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from argparse import ArgumentParser\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.engine.engine import Engine, State, Events\n",
        "from ignite.handlers import EarlyStopping\n",
        "from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n",
        "from ignite.utils import convert_tensor\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvKeryw3eQPw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utils\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fezs8xASSS28"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3FDM6BjTLwW",
        "outputId": "a72f44c1-89b1-4298-ed58-07a572ef9c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSzWEX54ScQi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2J-Qx3ekn_N",
        "outputId": "856f4554-83a5-4050-8fd6-9253e258aa33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxQ6QkH3BmR_"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/ISarcasm/DataSet/train.En.csv')\n",
        "df=df[['tweet','sarcastic']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, validate, test = \\\n",
        "              np.split(df.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(df)), int(.8*len(df))])"
      ],
      "metadata": {
        "id": "w5pyLfxJKO7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.concat([train, validate], ignore_index=True)"
      ],
      "metadata": {
        "id": "q87OCoHfKQtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqWxdHEZej7W"
      },
      "outputs": [],
      "source": [
        "new_sarastic_traslation_train = train[train['sarcastic'] == 1].reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRIAMZIvessn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqCl9GmKewtE"
      },
      "outputs": [],
      "source": [
        "# import nlpaug.augmenter.char as nac\n",
        "# import nlpaug.augmenter.word as naw\n",
        "# import nlpaug.augmenter.sentence as nas\n",
        "# import nlpaug.flow as nafc\n",
        "\n",
        "# from nlpaug.util import Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vw20Bbdez3a"
      },
      "outputs": [],
      "source": [
        "# back_translation_aug = naw.BackTranslationAug(\n",
        "#     from_model_name='facebook/wmt19-en-de', \n",
        "#     to_model_name='facebook/wmt19-de-en'\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8ktoL4Ke5OS"
      },
      "outputs": [],
      "source": [
        "def back_translate(paragraph) :\n",
        "  return back_translation_aug.augment(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS2rCPbue7w5"
      },
      "outputs": [],
      "source": [
        "# new_sarastic_traslation_train['tweet'] = new_sarastic_traslation_train['tweet'].apply(back_translate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8-CEHXBC4mt"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas==1.1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcETniZ-fVFP"
      },
      "outputs": [],
      "source": [
        "# new_sarastic_traslation_train.to_csv('/content/drive/MyDrive/ISarcasm/DataSet/train_En_translated.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsyTOndx1NpU"
      },
      "outputs": [],
      "source": [
        "# new_sarastic_traslation_train=pd.read_csv('/content/drive/MyDrive/ISarcasm/DataSet/train_En_translated.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train = pd.concat([train,new_sarastic_traslation_train]).sample(frac=1)\n"
      ],
      "metadata": {
        "id": "WukO72_atei9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "aVQcsJKXhPIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_xSVLXPzhV7B",
        "outputId": "3b76fe33-04e4-40fc-fb23-573825798a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-500adc2f-8465-4775-af4b-46851244e896\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Less than 5 minutes after getting my phone bac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Love seeing 15 year olds being vaccinated in t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>im about to just walk into a place and start w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Every time I comment on a TikTok asking for ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2769</th>\n",
              "      <td>2769</td>\n",
              "      <td>This weekend I hit a delivery biker with a car...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2770</th>\n",
              "      <td>2770</td>\n",
              "      <td>This country is screwed let’s be honest</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>2771</td>\n",
              "      <td>I always come up with some pretty interesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2772</th>\n",
              "      <td>2772</td>\n",
              "      <td>@andy_mansell72 @VicOtley @garry_whu @NiaAnts ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>2773</td>\n",
              "      <td>Poor Steve Clifford. Next hire has to be right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2774 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-500adc2f-8465-4775-af4b-46851244e896')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-500adc2f-8465-4775-af4b-46851244e896 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-500adc2f-8465-4775-af4b-46851244e896');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index                                              tweet  sarcastic\n",
              "0         0  Less than 5 minutes after getting my phone bac...          0\n",
              "1         1  Love seeing 15 year olds being vaccinated in t...          1\n",
              "2         2  I get a lot of boy who cried wolf vibes from t...          1\n",
              "3         3  im about to just walk into a place and start w...          1\n",
              "4         4  Every time I comment on a TikTok asking for ca...          0\n",
              "...     ...                                                ...        ...\n",
              "2769   2769  This weekend I hit a delivery biker with a car...          0\n",
              "2770   2770            This country is screwed let’s be honest          0\n",
              "2771   2771  I always come up with some pretty interesting ...          0\n",
              "2772   2772  @andy_mansell72 @VicOtley @garry_whu @NiaAnts ...          1\n",
              "2773   2773  Poor Steve Clifford. Next hire has to be right...          0\n",
              "\n",
              "[2774 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz9DGE_1DJeW"
      },
      "outputs": [],
      "source": [
        "# augmented_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GombW9vzCGB5"
      },
      "outputs": [],
      "source": [
        "# len(trdf1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt0ir0RICD28"
      },
      "outputs": [],
      "source": [
        "# len(augmented_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6FY70KZ6TY"
      },
      "source": [
        "# RoBERTa Baseline for Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA9QzHTCl5F6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlT2IDHumPNi",
        "outputId": "de4ab1c4-d5d9-4b26-d0ff-84b05701042d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA_D3Dl81I4a"
      },
      "outputs": [],
      "source": [
        "# trdf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-E_jNQbV_NL"
      },
      "outputs": [],
      "source": [
        "class PCLTrainDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length,displacemnt):\n",
        "        self.df = df\n",
        "        self.max_len = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = df['tweet'].values\n",
        "        self.label=df['sarcastic'].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        # summary = self.summary[index]\n",
        "        inputs_text = self.tokenizer.encode_plus(\n",
        "                                text,\n",
        "                                truncation=True,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length=self.max_len,\n",
        "                                padding='max_length'\n",
        "                            )\n",
        "        \n",
        "                            \n",
        "        target = self.label[index]\n",
        "        \n",
        "        text_ids = inputs_text['input_ids']\n",
        "        text_mask = inputs_text['attention_mask']\n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "        return {\n",
        "            \n",
        "            'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
        "            'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
        "            'target': torch.tensor(target, dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLXkQK5Bawae"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "    return 1/(1+math.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skGp5I4wM_Zn"
      },
      "outputs": [],
      "source": [
        "class Recall_Loss(nn.Module):\n",
        "    '''Calculate F1 score. Can work with gpu tensors\n",
        "    \n",
        "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        `ndim` == 1. epsilon <= val <= 1\n",
        "    \n",
        "    Reference\n",
        "    ---------\n",
        "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
        "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
        "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n",
        "    '''\n",
        "    def __init__(self, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true,):\n",
        "        # assert y_pred.ndim == 2\n",
        "        # assert y_true.ndim == 1\n",
        "        # print(y_pred.shape)\n",
        "        # print(y_true.shape)\n",
        "        # y_pred[y_pred<0.5]=0\n",
        "        # y_pred[y_pred>=0.5]=0\n",
        "\n",
        "\n",
        "        \n",
        "        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2).to(torch.float32)\n",
        "        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n",
        "        \n",
        "        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        # f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
        "        # f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        # f1=f1.detach()\n",
        "        # print(f1.shape)\n",
        "        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n",
        "        # y_true=y_true.reshape((y_true.shape[0], 1))\n",
        "\n",
        "        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n",
        "        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n",
        "\n",
        "\n",
        "        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n",
        "        recall=recall.detach()\n",
        "        CE =torch.nn.CrossEntropyLoss(weight=( 1 - recall))(y_pred, y_true_one_hot)\n",
        "        # loss = ( 1 - f1)  * CE\n",
        "        return  CE.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oD2n6r7N9Aq"
      },
      "outputs": [],
      "source": [
        "# class PCL_Model_Arch(nn.Module):\n",
        "#     def __init__(self,pre_trained='xlnet-base-cased'):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.bert = AutoModel.from_pretrained(pre_trained, output_hidden_states=True)\n",
        "#         output_channel = 16  # number of kernels\n",
        "#         num_classes = 6  # number of targets to predict\n",
        "#         dropout = 0.2  # dropout value\n",
        "#         embedding_dim = 768   # length of embedding dim\n",
        "\n",
        "#         ks = 3  # three conv nets here\n",
        "\n",
        "#         # input_channel = word embeddings at a value of 1; 3 for RGB images\n",
        "#         input_channel = 4  # for single embedding, input_channel = 1\n",
        "\n",
        "#         # [3, 4, 5] = window height\n",
        "#         # padding = padding to account for height of search window\n",
        "\n",
        "#         # 3 convolutional nets\n",
        "#         self.conv1 = nn.Conv2d(input_channel, output_channel, (3, embedding_dim), padding=(2, 0), groups=4)\n",
        "#         self.conv2 = nn.Conv2d(input_channel, output_channel, (4, embedding_dim), padding=(3, 0), groups=4)\n",
        "#         self.conv3 = nn.Conv2d(input_channel, output_channel, (5, embedding_dim), padding=(4, 0), groups=4)\n",
        "\n",
        "#         # apply dropout\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#         # fully connected layer for classification\n",
        "#         # 3x conv nets * output channel\n",
        "#         self.fc1 = nn.Linear(ks * output_channel, num_classes)\n",
        "#         self.softmax = nn.Sigmoid()\n",
        "\n",
        "#     def forward(self, text_id, text_mask):\n",
        "#         # get the last 4 layers\n",
        "#         outputs= self.bert(text_id, attention_mask=text_mask)\n",
        "#         # all_layers  = [4, 16, 256, 768]\n",
        "#         hidden_layers = outputs[2]  # get hidden layers\n",
        "\n",
        "#         hidden_layers = torch.stack(hidden_layers, dim=1)\n",
        "#         x = hidden_layers[:, -4:] \n",
        "#         # x = x.unsqueeze(1)\n",
        "#         # x = torch.mean(x, 0)\n",
        "#         # print(hidden_layers.size())\n",
        "      \n",
        "#         torch.cuda.empty_cache()\n",
        "#         x = [F.relu(self.conv1(x)).squeeze(3), F.relu(self.conv2(x)).squeeze(3), F.relu(self.conv3(x)).squeeze(3)]\n",
        "#         x = [F.dropout(i) for i in x]\n",
        "#         # max-over-time pooling; # (batch, channel_output) * ks\n",
        "#         x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "#         # concat results; (batch, channel_output * ks)\n",
        "#         x = torch.cat(x, 1)\n",
        "#         # add dropout\n",
        "#         x = self.dropout(x)\n",
        "#         # generate logits (batch, target_size)\n",
        "#         logit = self.fc1(x)\n",
        "#         torch.cuda.empty_cache()\n",
        "#         return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZa-chAxXf5r"
      },
      "outputs": [],
      "source": [
        "class PCL_Model_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PCL_Model_Arch, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained('roberta-base', output_hidden_states=True)\n",
        "        output_channel = 16  # number of kernels\n",
        "        num_classes = 2  # number of targets to predict\n",
        "        dropout = 0.2  # dropout value\n",
        "        embedding_dim = 768   # length of embedding dim\n",
        "\n",
        "        ks = 3  # three conv nets here\n",
        "\n",
        "        # input_channel = word embeddings at a value of 1; 3 for RGB images\n",
        "        input_channel = 4  # for single embedding, input_channel = 1\n",
        "\n",
        "        # [3, 4, 5] = window height\n",
        "        # padding = padding to account for height of search window\n",
        "\n",
        "        # 3 convolutional nets\n",
        "        self.conv1 = nn.Conv2d(input_channel, output_channel, (3, embedding_dim), padding=(2, 0), groups=4)\n",
        "        self.conv2 = nn.Conv2d(input_channel, output_channel, (4, embedding_dim), padding=(3, 0), groups=4)\n",
        "        self.conv3 = nn.Conv2d(input_channel, output_channel, (5, embedding_dim), padding=(4, 0), groups=4)\n",
        "\n",
        "        # apply dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fully connected layer for classification\n",
        "        # 3x conv nets * output channel\n",
        "        self.fc1 = nn.Linear(ks * output_channel, num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, text_id, text_mask):\n",
        "        # get the last 4 layers\n",
        "        outputs= self.bert(text_id, attention_mask=text_mask)\n",
        "        # all_layers  = [4, 16, 256, 768]\n",
        "        # print(outputs)\n",
        "        hidden_layers = outputs[-1]  # get hidden layers\n",
        "\n",
        "        hidden_layers = torch.stack(hidden_layers, dim=1)\n",
        "        x = hidden_layers[:, -7:-3] \n",
        "        # x = x.unsqueeze(1)\n",
        "        # x = torch.mean(x, 0)\n",
        "        # print(hidden_layers.size())\n",
        "      \n",
        "        torch.cuda.empty_cache()\n",
        "        x = [F.relu(self.conv1(x)).squeeze(3), F.relu(self.conv2(x)).squeeze(3), F.relu(self.conv3(x)).squeeze(3)]\n",
        "        x = [F.dropout(i,0.65) for i in x]\n",
        "        # max-over-time pooling; # (batch, channel_output) * ks\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "        # concat results; (batch, channel_output * ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        # add dropout\n",
        "        x = self.dropout(x)\n",
        "        # generate logits (batch, target_size)\n",
        "        logit = self.fc1(x)\n",
        "        torch.cuda.empty_cache()\n",
        "        return self.softmax(logit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuODW43NYhTz"
      },
      "outputs": [],
      "source": [
        "tokenizer= AutoTokenizer.from_pretrained('roberta-base')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iRb3EdFy0ym"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class AsymmetricLoss(nn.Module):\n",
        "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=True):\n",
        "        super(AsymmetricLoss, self).__init__()\n",
        "\n",
        "        self.gamma_neg = gamma_neg\n",
        "        self.gamma_pos = gamma_pos\n",
        "        self.clip = clip\n",
        "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: input logits\n",
        "        y: targets (multi-label binarized vector)\n",
        "        \"\"\"\n",
        "\n",
        "        # Calculating Probabilities\n",
        "        x_sigmoid = torch.sigmoid(x)\n",
        "        xs_pos = x_sigmoid\n",
        "        xs_neg = 1 - x_sigmoid\n",
        "\n",
        "        # Asymmetric Clipping\n",
        "        if self.clip is not None and self.clip > 0:\n",
        "            xs_neg = (xs_neg + self.clip).clamp(max=1)\n",
        "\n",
        "        # Basic CE calculation\n",
        "        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n",
        "        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n",
        "        loss = los_pos + los_neg\n",
        "\n",
        "        # Asymmetric Focusing\n",
        "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
        "            if self.disable_torch_grad_focal_loss:\n",
        "                torch.set_grad_enabled(False)\n",
        "            pt0 = xs_pos * y\n",
        "            pt1 = xs_neg * (1 - y)  # pt = p if t > 0 else 1-p\n",
        "            pt = pt0 + pt1\n",
        "            one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n",
        "            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
        "            if self.disable_torch_grad_focal_loss:\n",
        "                torch.set_grad_enabled(True)\n",
        "            loss *= one_sided_w\n",
        "\n",
        "        return -loss.sum()\n",
        "\n",
        "\n",
        "class AsymmetricLossOptimized(nn.Module):\n",
        "    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n",
        "    favors inplace operations'''\n",
        "\n",
        "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n",
        "        super(AsymmetricLossOptimized, self).__init__()\n",
        "\n",
        "        self.gamma_neg = gamma_neg\n",
        "        self.gamma_pos = gamma_pos\n",
        "        self.clip = clip\n",
        "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
        "        self.eps = eps\n",
        "\n",
        "        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n",
        "        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: input logits\n",
        "        y: targets (multi-label binarized vector)\n",
        "        \"\"\"\n",
        "\n",
        "        self.targets = y\n",
        "        self.anti_targets = 1 - y\n",
        "\n",
        "        # Calculating Probabilities\n",
        "        self.xs_pos = torch.sigmoid(x)\n",
        "        self.xs_neg = 1.0 - self.xs_pos\n",
        "\n",
        "        # Asymmetric Clipping\n",
        "        if self.clip is not None and self.clip > 0:\n",
        "            self.xs_neg.add_(self.clip).clamp_(max=1)\n",
        "\n",
        "        # Basic CE calculation\n",
        "        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n",
        "        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n",
        "\n",
        "        # Asymmetric Focusing\n",
        "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
        "            if self.disable_torch_grad_focal_loss:\n",
        "                torch.set_grad_enabled(False)\n",
        "            self.xs_pos = self.xs_pos * self.targets\n",
        "            self.xs_neg = self.xs_neg * self.anti_targets\n",
        "            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n",
        "                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n",
        "            if self.disable_torch_grad_focal_loss:\n",
        "                torch.set_grad_enabled(True)\n",
        "            self.loss *= self.asymmetric_w\n",
        "\n",
        "        return -self.loss.sum()\n",
        "\n",
        "\n",
        "class ASLSingleLabel(nn.Module):\n",
        "    '''\n",
        "    This loss is intended for single-label classification problems\n",
        "    '''\n",
        "    def __init__(self, gamma_pos=0, gamma_neg=4, eps: float = 0.1, reduction='mean'):\n",
        "        super(ASLSingleLabel, self).__init__()\n",
        "\n",
        "        self.eps = eps\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
        "        self.targets_classes = []\n",
        "        self.gamma_pos = gamma_pos\n",
        "        self.gamma_neg = gamma_neg\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, target):\n",
        "        '''\n",
        "        \"input\" dimensions: - (batch_size,number_classes)\n",
        "        \"target\" dimensions: - (batch_size)\n",
        "        '''\n",
        "        num_classes = inputs.size()[-1]\n",
        "        log_preds = self.logsoftmax(inputs)\n",
        "        self.targets_classes = torch.zeros_like(inputs).scatter_(1, target.long().unsqueeze(1), 1)\n",
        "\n",
        "        # ASL weights\n",
        "        targets = self.targets_classes\n",
        "        anti_targets = 1 - targets\n",
        "        xs_pos = torch.exp(log_preds)\n",
        "        xs_neg = 1 - xs_pos\n",
        "        xs_pos = xs_pos * targets\n",
        "        xs_neg = xs_neg * anti_targets\n",
        "        asymmetric_w = torch.pow(1 - xs_pos - xs_neg,\n",
        "                                 self.gamma_pos * targets + self.gamma_neg * anti_targets)\n",
        "        log_preds = log_preds * asymmetric_w\n",
        "\n",
        "        if self.eps > 0:  # label smoothing\n",
        "            self.targets_classes = self.targets_classes.mul(1 - self.eps).add(self.eps / num_classes)\n",
        "\n",
        "        # loss calculation\n",
        "        loss = - self.targets_classes.mul(log_preds)\n",
        "\n",
        "        loss = loss.sum(dim=-1)\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0XUHerFY2jd"
      },
      "outputs": [],
      "source": [
        "def criterion(outputs1,  targets):\n",
        "    targets = F.one_hot(targets.to(torch.int64), 2).to(torch.float32)\n",
        "\n",
        "    criterion = AsymmetricLossOptimized()\n",
        "    loss = criterion(outputs1, targets)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zeh7f_UdC6dh"
      },
      "outputs": [],
      "source": [
        "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
        "    \"\"\"\n",
        "    Samples elements randomly from a given list of indices for imbalanced dataset\n",
        "    Arguments:\n",
        "        indices (list, optional): a list of indices\n",
        "        num_samples (int, optional): number of samples to draw\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, indices=None, num_samples=None):\n",
        "        # if indices is not provided,\n",
        "        # all elements in the dataset will be considered\n",
        "        self.indices = list(range(len(dataset.sarcastic))) \\\n",
        "            if indices is None else indices\n",
        "\n",
        "        # if num_samples is not provided,\n",
        "        # draw `len(indices)` samples in each iteration\n",
        "        self.num_samples = len(self.indices) \\\n",
        "            if num_samples is None else num_samples\n",
        "\n",
        "        # distribution of classes in the dataset\n",
        "        label_to_count = {}\n",
        "        for idx in self.indices:\n",
        "            label = self._get_label(dataset, idx)\n",
        "            if label in label_to_count:\n",
        "                label_to_count[label] += 1\n",
        "            else:\n",
        "                label_to_count[label] = 1\n",
        "\n",
        "        # weight for each sample\n",
        "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n",
        "        self.weights = torch.DoubleTensor(weights)\n",
        "\n",
        "    def _get_label(self, dataset, id_):\n",
        "        return dataset.sarcastic[id_]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRX0b55VaxmS"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\"seed\": 2021,\n",
        "          \"epochs\": 3,\n",
        "          \"model_name\": \"xlnet-base-cased\",\n",
        "          \"train_batch_size\": 16,\n",
        "          \"valid_batch_size\": 64,\n",
        "          \"max_length\": 256,\n",
        "          \"learning_rate\": 1e-4,\n",
        "          \"scheduler\": 'CosineAnnealingLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"num_classes\": 1,\n",
        "          \"margin\": 0.5,\n",
        "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4afl1P8LaD07"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        \n",
        "        text_ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        text_mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        targets = data['target'].to(device, dtype=torch.long)\n",
        "        \n",
        "        batch_size = text_ids.size(0)\n",
        "        # print(targets)\n",
        "\n",
        "        outputs = model(text_ids, text_mask)\n",
        "        # print(outputs.shape)\n",
        "        \n",
        "        # print(outputs.shape)\n",
        "\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        loss = loss / CONFIG['n_accumulate']\n",
        "        loss.backward()\n",
        "    \n",
        "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
        "            optimizer.step()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
        "                        LR=optimizer.param_groups[0]['lr'])\n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdWI_KWRafLZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:        \n",
        "        \n",
        "        text_ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        text_mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        targets = data['target'].to(device, dtype=torch.long)\n",
        "        \n",
        "        batch_size = text_ids.size(0)\n",
        "\n",
        "        outputs = model(text_ids, text_mask)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
        "                        LR=optimizer.param_groups[0]['lr'])   \n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1wtBAJJbEou"
      },
      "outputs": [],
      "source": [
        "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
        "    # To automatically log gradients\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "    \n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1): \n",
        "        gc.collect()\n",
        "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           device=CONFIG['device'], epoch=epoch)\n",
        "        \n",
        "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
        "                                         epoch=epoch)\n",
        "    \n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "        \n",
        "       \n",
        "        \n",
        "        # deep copy the model\n",
        "        if val_epoch_loss <= best_epoch_loss:\n",
        "            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
        "            best_epoch_loss = val_epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = f\"/content/drive/MyDrive/ISarcasm/Models/roberta_base_translation_extra_fropout/Loss-Fold-{fold}.bin\"\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            # Save a model file from the current directory\n",
        "            print(\"Model Saved\")\n",
        "            \n",
        "        print()\n",
        "    \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
        "    \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSXiJa2-bRiX"
      },
      "outputs": [],
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
        "                                                   eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
        "                                                             eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6nXhK_ObVNe"
      },
      "outputs": [],
      "source": [
        "def prepare_loaders(fold):\n",
        "    displacemnt_list=[0,512,1024,1536,2048,2560,3072,3584,4096,4608,4950]\n",
        "    df_train = train[train.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = train[train.kfold == fold].reset_index(drop=True)\n",
        "    sampler = ImbalancedDatasetSampler(df_train)\n",
        "    \n",
        "    train_dataset = PCLTrainDataset(df_train, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=displacemnt_list[fold])\n",
        "    valid_dataset = PCLTrainDataset(df_valid, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=displacemnt_list[fold])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True, drop_last=True,sampler=sampler)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)\n",
        "    \n",
        "    return train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "YYF0WR6Th1zy",
        "outputId": "170c7c83-111e-4abb-e472-e756adef2382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c9bf01e7-b7ed-468c-9aae-302f633de885\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Less than 5 minutes after getting my phone bac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Love seeing 15 year olds being vaccinated in t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>im about to just walk into a place and start w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Every time I comment on a TikTok asking for ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2769</th>\n",
              "      <td>2769</td>\n",
              "      <td>This weekend I hit a delivery biker with a car...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2770</th>\n",
              "      <td>2770</td>\n",
              "      <td>This country is screwed let’s be honest</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>2771</td>\n",
              "      <td>I always come up with some pretty interesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2772</th>\n",
              "      <td>2772</td>\n",
              "      <td>@andy_mansell72 @VicOtley @garry_whu @NiaAnts ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>2773</td>\n",
              "      <td>Poor Steve Clifford. Next hire has to be right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2774 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9bf01e7-b7ed-468c-9aae-302f633de885')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9bf01e7-b7ed-468c-9aae-302f633de885 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9bf01e7-b7ed-468c-9aae-302f633de885');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index                                              tweet  sarcastic\n",
              "0         0  Less than 5 minutes after getting my phone bac...          0\n",
              "1         1  Love seeing 15 year olds being vaccinated in t...          1\n",
              "2         2  I get a lot of boy who cried wolf vibes from t...          1\n",
              "3         3  im about to just walk into a place and start w...          1\n",
              "4         4  Every time I comment on a TikTok asking for ca...          0\n",
              "...     ...                                                ...        ...\n",
              "2769   2769  This weekend I hit a delivery biker with a car...          0\n",
              "2770   2770            This country is screwed let’s be honest          0\n",
              "2771   2771  I always come up with some pretty interesting ...          0\n",
              "2772   2772  @andy_mansell72 @VicOtley @garry_whu @NiaAnts ...          1\n",
              "2773   2773  Poor Steve Clifford. Next hire has to be right...          0\n",
              "\n",
              "[2774 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCN4vwBOeaLb"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
        "\n",
        "for fold, ( _, val_) in enumerate(skf.split(X=train, y=train.sarcastic)):\n",
        "    train.loc[val_ , \"kfold\"] = int(fold)\n",
        "    \n",
        "train[\"kfold\"] = train[\"kfold\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOtw3nW-2X58"
      },
      "outputs": [],
      "source": [
        "# del model,train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoQghNKN2Cy2"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "# del model\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCwmBcvPlNaO"
      },
      "source": [
        "http://seekinginference.com/applied_nlp/bert-cnn.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXC4SsiDbbGR",
        "outputId": "de5cf5c6-69d8-4be8-98d1-21379be58429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== Fold: 0 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:27<00:00,  6.29s/it, Epoch=1, LR=8.25e-5, Train_Loss=4.56]\n",
            "100%|██████████| 9/9 [00:21<00:00,  2.35s/it, Epoch=1, LR=8.25e-5, Valid_Loss=16.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 16.05113700316833)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:21<00:00,  6.25s/it, Epoch=2, LR=4.24e-5, Train_Loss=4.34]\n",
            "100%|██████████| 9/9 [00:21<00:00,  2.33s/it, Epoch=2, LR=4.24e-5, Valid_Loss=17.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:23<00:00,  6.26s/it, Epoch=3, LR=8.05e-6, Train_Loss=4.34]\n",
            "100%|██████████| 9/9 [00:20<00:00,  2.33s/it, Epoch=3, LR=8.05e-6, Valid_Loss=17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete in 0h 44m 22s\n",
            "Best Loss: 16.0511\n",
            "\n",
            "====== Fold: 1 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:23<00:00,  6.26s/it, Epoch=1, LR=8.25e-5, Train_Loss=4.44]\n",
            "100%|██████████| 9/9 [00:21<00:00,  2.34s/it, Epoch=1, LR=8.25e-5, Valid_Loss=18.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 18.393827995094092)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:23<00:00,  6.26s/it, Epoch=2, LR=4.24e-5, Train_Loss=4.25]\n",
            "100%|██████████| 9/9 [00:21<00:00,  2.34s/it, Epoch=2, LR=4.24e-5, Valid_Loss=17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (18.393827995094092 ---> 17.004545452358485)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:23<00:00,  6.26s/it, Epoch=3, LR=8.05e-6, Train_Loss=3.83]\n",
            "100%|██████████| 9/9 [00:21<00:00,  2.34s/it, Epoch=3, LR=8.05e-6, Valid_Loss=16.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (17.004545452358485 ---> 16.258037543082022)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 0h 44m 24s\n",
            "Best Loss: 16.2580\n",
            "\n",
            "====== Fold: 2 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:23<00:00,  6.26s/it, Epoch=1, LR=8.25e-5, Train_Loss=4.42]\n",
            "100%|██████████| 9/9 [00:20<00:00,  2.33s/it, Epoch=1, LR=8.25e-5, Valid_Loss=17.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 17.275928638217685)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138/138 [14:21<00:00,  6.24s/it, Epoch=2, LR=4.24e-5, Train_Loss=4.28]\n",
            "100%|██████████| 9/9 [00:20<00:00,  2.32s/it, Epoch=2, LR=4.24e-5, Valid_Loss=18.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 7/138 [00:43<13:38,  6.25s/it, Epoch=3, LR=4.03e-5, Train_Loss=3.83]"
          ]
        }
      ],
      "source": [
        "for fold in range(0, CONFIG['n_fold']):\n",
        "    print(f\"====== Fold: {fold} ======\")\n",
        "\n",
        "    \n",
        "    # Create Dataloaders\n",
        "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
        "    \n",
        "    model = PCL_Model_Arch()\n",
        "    model.to(CONFIG['device'])\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Define Optimizer and Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
        "    scheduler = fetch_scheduler(optimizer)\n",
        "    \n",
        "    model, history = run_training(model, optimizer, scheduler,\n",
        "                                  device=CONFIG['device'],\n",
        "                                  num_epochs=CONFIG['epochs'],\n",
        "                                  fold=fold)\n",
        "    \n",
        "    \n",
        "    del model, history, train_loader, valid_loader\n",
        "    _ = gc.collect()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-W1WjZpJqpR"
      },
      "outputs": [],
      "source": [
        "test.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iABlWV3w2yoB"
      },
      "outputs": [],
      "source": [
        "test_dataset = PCLTrainDataset(test, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piuXPwW433gP"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_fn(model, dataloader, device):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    PREDS = []\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        \n",
        "        outputs = model(ids, mask)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "#         print(len(outputs))\n",
        "#         print(len(np.max(outputs.cpu().detach().numpy(),axis=1)))\n",
        "        PREDS.append(outputs.detach().cpu().numpy()) \n",
        "    \n",
        "    PREDS = np.concatenate(PREDS)\n",
        "    gc.collect()\n",
        "    \n",
        "    return PREDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaxyuvUP3Md0"
      },
      "outputs": [],
      "source": [
        "def inference(model_paths, dataloader, device):\n",
        "    final_preds = []\n",
        "    for i, path in enumerate(model_paths):\n",
        "        model = PCL_Model_Arch()\n",
        "        model.to(CONFIG['device'])\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        \n",
        "        print(f\"Getting predictions for model {i+1}\")\n",
        "        preds = valid_fn(model, dataloader, device)\n",
        "        final_preds.append(preds)\n",
        "    \n",
        "    final_preds = np.array(final_preds)\n",
        "    final_preds = np.mean(final_preds, axis=0)\n",
        "    final_preds= np.argmax(final_preds,axis=1)\n",
        "    return final_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg8ZieYfgMBC"
      },
      "source": [
        "Recall loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKQV51HyommQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import jaccard_score,f1_score,accuracy_score,recall_score,precision_score,classification_report\n",
        "def print_statistics(y, y_pred):\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision =precision_score(y, y_pred, average='weighted')\n",
        "    recall = recall_score(y, y_pred, average='weighted')\n",
        "    f_score = f1_score(y, y_pred, average='weighted')\n",
        "    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n",
        "          % (accuracy, precision, recall, f_score))\n",
        "    print(classification_report(y, y_pred))\n",
        "    return accuracy, precision, recall, f_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7qiC15AgPMJ"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models/roberta_base_translation_extra_fropout/Loss-Fold-0.bin','/content/drive/MyDrive/ISarcasm/Models/roberta_base_translation_extra_fropout/Loss-Fold-1.bin','/content/drive/MyDrive/ISarcasm/Models/roberta_base_translation_extra_fropout/Loss-Fold-2.bin','/content/drive/MyDrive/ISarcasm/Models/roberta_base_translation_extra_fropout/Loss-Fold-3.bin','/content/drive/MyDrive/ISarcasm/Models/roberta_base_translation_extra_fropout/Loss-Fold-4.bin']\n",
        "preds = inference(MODEL_PATH_2, test_loader, CONFIG['device'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceJe0XVIgPfl"
      },
      "outputs": [],
      "source": [
        "print(print_statistics(test['sarcatic'],preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8hjnxbbfJq"
      },
      "source": [
        "## Prepare submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7HICl8MJQf0"
      },
      "outputs": [],
      "source": [
        "!cat task1.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCjziGtxJRif"
      },
      "outputs": [],
      "source": [
        "!cat task2.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZDLUcYZbhYg"
      },
      "outputs": [],
      "source": [
        "!zip submission.zip task1.txt task2.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "roberta_base+_Augmentation_+_translation+_Features_+ImbakaceSampler+F1_score_CE_loss_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}