{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08esTFOYO99"
      },
      "source": [
        "# Main imports and code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnHQoayhBYlm",
        "outputId": "efb1e273-9761-4ca0-9017-293fa821dee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  8 17:59:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check which gpu we're using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYhFR7nSYOjG",
        "outputId": "fb772d92-460c-4282-f87f-e92d56c071b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 433 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 12.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip  install transformers\n",
        "!pip install pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJC8wj73Zd_p"
      },
      "outputs": [],
      "source": [
        "# Any results you write to the current directory are saved as output.\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "from transformers import BertTokenizer,BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from argparse import ArgumentParser\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.engine.engine import Engine, State, Events\n",
        "from ignite.handlers import EarlyStopping\n",
        "from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n",
        "from ignite.utils import convert_tensor\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvKeryw3eQPw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utils\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fezs8xASSS28"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3FDM6BjTLwW",
        "outputId": "28835fc3-a2a0-4668-a73a-afd3b4fc4f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 12.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSzWEX54ScQi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2J-Qx3ekn_N",
        "outputId": "901445a0-cd69-4101-f609-aa4ace6f5a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/ISarcasm/DataSet/train.En.csv')\n",
        "df=df[['tweet','sarcastic']]"
      ],
      "metadata": {
        "id": "VjoRy3-22MLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, validate, test = \\\n",
        "              np.split(df.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(df)), int(.8*len(df))])"
      ],
      "metadata": {
        "id": "y6Fd8UBBdTQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.concat([train, validate], ignore_index=True)"
      ],
      "metadata": {
        "id": "PJrh2l2qdXf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tedf1.to_csv('/content/drive/MyDrive/PCL/test_task_1',index=False)"
      ],
      "metadata": {
        "id": "X5DMNjrTGT8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trdf1.to_csv('/content/drive/MyDrive/PCL/train_task_1',index=False)"
      ],
      "metadata": {
        "id": "l18cECm4GhQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FE extraction"
      ],
      "metadata": {
        "id": "S4g-iv_hz5bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7NP2467T0IcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_character_type(text):\n",
        "    text=str(text)\n",
        "\n",
        "    specialChar = 0\n",
        "    for i in range(0, len(text)):\n",
        "        ch = text[i]\n",
        "        if ch == \"!\":\n",
        "            specialChar+=1\n",
        "        \n",
        "    return specialChar\n",
        "    \n",
        "def count_question_mark(text):\n",
        "    text=str(text)\n",
        "    specialChar = 0\n",
        "    for i in range(0, len(text)):\n",
        "        ch = text[i]\n",
        "        if ch == \"?\":\n",
        "            specialChar+=1\n",
        "        \n",
        "    return specialChar"
      ],
      "metadata": {
        "id": "tTeAfkLILKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python NLP library, TextBlob has a method to roughly quantify if a sentence is fact or opinion.¶\n",
        "The method outputs a number ranging from 0 to 1, an output close to 0 indicates the sentence is highly factual and close to 1 means the sentence is highly subjective. Here, we take the sum for every comment, an overall higher sum then, will be indicative of higher subjectivity"
      ],
      "metadata": {
        "id": "gVCrFvUELtuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subjectivity(text):\n",
        "    return TextBlob(str(text)).sentiment.subjectivity"
      ],
      "metadata": {
        "id": "6mveTkq8LpDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the 4 most important parts-of-speech (Noun, Verb, Adjective,Pronoun) in sarcastic and non sarcastic comments might shed some light, so let's plot it as a grouped bar chart"
      ],
      "metadata": {
        "id": "bHfBI8gGL-wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "nWb02tphQKLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgjjjxemQPDR",
        "outputId": "de62e05c-2d01-495b-8962-266ec89a3eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "id": "NTnfu4zEMkIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_counter(doc):\n",
        "    verb_count = 0\n",
        "    adj_count = 0\n",
        "    pron_count = 0\n",
        "    noun_count=0\n",
        "    for tok in doc:\n",
        "        if tok.pos_ == \"VERB\":\n",
        "            verb_count=verb_count+1\n",
        "        elif tok.pos_ == \"ADJ\":\n",
        "            adj_count=adj_count+1\n",
        "        elif tok.pos_ == \"PRON\":\n",
        "            pron_count=pron_count+1\n",
        "        elif tok.pos_ == \"PROPN\":\n",
        "            noun_count=noun_count+1\n",
        "    return (verb_count,adj_count,pron_count,noun_count)"
      ],
      "metadata": {
        "id": "6zMfSkKEL_Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_verb_count(text):\n",
        "  verb_count = 0\n",
        "  doc = nlp(str(text))\n",
        "  for tok in doc:\n",
        "        if tok.pos_ == \"VERB\":\n",
        "            verb_count=verb_count+1\n",
        "  return verb_count\n",
        "\n",
        "def get_noun_count(text):\n",
        "  noun_count = 0\n",
        "  doc = nlp(str(text))\n",
        "  for tok in doc:\n",
        "        if tok.pos_ == \"PROPN\":\n",
        "            noun_count=noun_count+1\n",
        "  return noun_count\n",
        "\n",
        "def get_pron_count(text):\n",
        "  pron_count = 0\n",
        "  doc = nlp(str(text))\n",
        "  for tok in doc:\n",
        "        if tok.pos_ == \"PRON\":\n",
        "            pron_count=pron_count+1\n",
        "  return pron_count\n",
        "\n",
        "\n",
        "def get_adj_count(text):\n",
        "  adj_count = 0\n",
        "  doc = nlp(str(text))\n",
        "  for tok in doc:\n",
        "        if tok.pos_ == \"ADJ\":\n",
        "            adj_count=adj_count+1\n",
        "  return adj_count"
      ],
      "metadata": {
        "id": "8QwE9ZNsMDF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sarcastic comments tend to have profanity interspersed within, let's get a count of both sarcastic and non sarcastic and see how they compare"
      ],
      "metadata": {
        "id": "4HeY-oz8Mpxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install better_profanity \n",
        "from better_profanity import profanity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2utbnNFMuim",
        "outputId": "7e89a1e9-7e0a-4a94-9227-105377859e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting better_profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: better-profanity\n",
            "Successfully installed better-profanity-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_profane_words(text):\n",
        "    count = 0\n",
        "    for sent in str(text).split():\n",
        "        if profanity.contains_profanity(sent) == True:\n",
        "            count = count+1\n",
        "    return count"
      ],
      "metadata": {
        "id": "O4p1uJ0EMr3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get entity cloud"
      ],
      "metadata": {
        "id": "hcsT1U-8NKgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_wordcloud(text):\n",
        "    named_entities = []    \n",
        "    sent = nlp(str(text))\n",
        "    for ent in sent.ents:\n",
        "        if ent.label_ == 'PERSON' or 'ORG' or 'GPE':\n",
        "            named_entities.append(ent.text)\n",
        "            \n",
        "    doc = \" \".join(named_entities)\n",
        "    return doc"
      ],
      "metadata": {
        "id": "nSLUNoX5M4tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I_Oh0O96NS2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/larsmans/sentiwordnet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVLiwiYyOFXn",
        "outputId": "4c8f0cb5-e306-4572-817a-ac793e21d926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentiwordnet'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "JHa4plxqSUqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class load_senti_word_net(object):\n",
        "    \"\"\"\n",
        "    constructor to load the file and read the file as CSV\n",
        "    6 columns - pos, ID, PosScore, NegScore, synsetTerms, gloss\n",
        "    synsetTerms can have multiple similar words like abducting#1 abducent#1 and will read each one and calculaye the scores\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        sent_scores = collections.defaultdict(list)\n",
        "        with io.open(\"/content/sentiwordnet/SentiWordNet_3.0.0_20130122.txt\") as fname:\n",
        "            file_content = csv.reader(fname, delimiter='\\t',quotechar='\"')\n",
        "            \n",
        "            for line in file_content:                \n",
        "                if line[0].startswith('#') :\n",
        "                    continue                    \n",
        "                pos, ID, PosScore, NegScore, synsetTerms, gloss = line\n",
        "                for terms in synsetTerms.split(\" \"):\n",
        "                    term = terms.split(\"#\")[0]\n",
        "                    term = term.replace(\"-\",\"\").replace(\"_\",\"\")\n",
        "                    key = \"%s/%s\"%(pos,term.split(\"#\")[0])\n",
        "                    try:\n",
        "                        sent_scores[key].append((float(PosScore),float(NegScore)))\n",
        "                    except:\n",
        "                        sent_scores[key].append((0,0))\n",
        "                    \n",
        "        for key, value in sent_scores.items():\n",
        "            sent_scores[key] = np.mean(value,axis=0)\n",
        "        \n",
        "        self.sent_scores = sent_scores    \n",
        "     \n",
        "    \"\"\"\n",
        "    For a word,\n",
        "    nltk.pos_tag([\"Suraj\"])\n",
        "    [('Suraj', 'NN')]\n",
        "    \"\"\"\n",
        "    \n",
        "    def score_word(self, word):\n",
        "        pos = nltk.pos_tag([word])[0][1]\n",
        "        return self.score(word, pos)\n",
        "    \n",
        "    def score(self,word, pos):\n",
        "        \"\"\"\n",
        "        Identify the type of POS, get the score from the senti_scores and return the score\n",
        "        \"\"\"\n",
        "        \n",
        "        if pos[0:2] == 'NN':\n",
        "            pos_type = 'n'\n",
        "        elif pos[0:2] == 'JJ':\n",
        "            pos_type = 'a'\n",
        "        elif pos[0:2] =='VB':\n",
        "            pos_type='v'\n",
        "        elif pos[0:2] =='RB':\n",
        "            pos_type = 'r'\n",
        "        else:\n",
        "            pos_type =  0\n",
        "            \n",
        "        if pos_type != 0 :    \n",
        "            loc = pos_type+'/'+word\n",
        "            score = self.sent_scores[loc]\n",
        "            if len(score)>1:\n",
        "                return score\n",
        "            else:\n",
        "                return np.array([0.0,0.0])\n",
        "        else:\n",
        "            return np.array([0.0,0.0])\n",
        "        \n",
        "    \"\"\"\n",
        "    Repeat the same for a sentence\n",
        "    nltk.pos_tag(word_tokenize(\"My name is Suraj\"))\n",
        "    [('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Suraj', 'NNP')]    \n",
        "    \"\"\"    \n",
        "        \n",
        "    def score_sentencce(self, sentence):\n",
        "        pos = nltk.pos_tag(sentence)\n",
        "        # print (pos)\n",
        "        mean_score = np.array([0.0, 0.0])\n",
        "        for i in range(len(pos)):\n",
        "            mean_score += self.score(pos[i][0], pos[i][1])\n",
        "            \n",
        "        return mean_score\n",
        "    \n",
        "    def pos_vector(self, sentence):\n",
        "        pos_tag = nltk.pos_tag(sentence)\n",
        "        vector = np.zeros(4)\n",
        "        \n",
        "        for i in range(0, len(pos_tag)):\n",
        "            pos = pos_tag[i][1]\n",
        "            if pos[0:2]=='NN':\n",
        "                vector[0] += 1\n",
        "            elif pos[0:2] =='JJ':\n",
        "                vector[1] += 1\n",
        "            elif pos[0:2] =='VB':\n",
        "                vector[2] += 1\n",
        "            elif pos[0:2] == 'RB':\n",
        "                vector[3] += 1\n",
        "                \n",
        "        return vector\n",
        "            "
      ],
      "metadata": {
        "id": "7JkCoAB4Nv5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_features(features,sentence):\n",
        "    sentence_rep = replace_reg(str(sentence))\n",
        "    token = nltk.word_tokenize(sentence_rep)\n",
        "    token = [porter.stem(i.lower()) for i in token]        \n",
        "    \n",
        "    bigrams = nltk.bigrams(token)\n",
        "    bigrams = [tup[0] + ' ' + tup[1] for tup in bigrams]\n",
        "    grams = token + bigrams\n",
        "    #print (grams)\n",
        "    for t in grams:\n",
        "        features['contains(%s)'%t]=1.0"
      ],
      "metadata": {
        "id": "0WkEVIG6OccU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_features(features,sentence):\n",
        "    sentence_rep = replace_reg(sentence)\n",
        "    token = nltk.word_tokenize(sentence_rep)\n",
        "    token = [ porter.stem(each.lower()) for each in token]\n",
        "    pos_vector = sentiments.pos_vector(token)\n",
        "    for j in range(len(pos_vector)):\n",
        "        features['POS_'+str(j+1)] = pos_vector[j]\n",
        "    # print (\"done\")\n",
        "    "
      ],
      "metadata": {
        "id": "QLGtTbcTOgnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def capitalization(features,sentence):\n",
        "    count = 0\n",
        "    for i in range(len(sentence)):\n",
        "        count += int(sentence[i].isupper())\n",
        "    features['Capitalization'] = int(count > 3)\n",
        "    # print (count)"
      ],
      "metadata": {
        "id": "We25-gg4Ol4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "#dictionnary to sentiment analysis\n",
        "emo_repl = {\n",
        "    #good emotions\n",
        "    \"&lt;3\" : \" good \",\n",
        "    \":d\" : \" good \",\n",
        "    \":dd\" : \" good \",\n",
        "    \":p\" : \" good \",\n",
        "    \"8)\" : \" good \",\n",
        "    \":-)\" : \" good \",\n",
        "    \":)\" : \" good \",\n",
        "    \";)\" : \" good \",\n",
        "    \"(-:\" : \" good \",\n",
        "    \"(:\" : \" good \",\n",
        "    \n",
        "    \"yay!\" : \" good \",\n",
        "    \"yay\" : \" good \",\n",
        "    \"yaay\" : \" good \",\n",
        "    \"yaaay\" : \" good \",\n",
        "    \"yaaaay\" : \" good \",\n",
        "    \"yaaaaay\" : \" good \",    \n",
        "    #bad emotions\n",
        "    \":/\" : \" bad \",\n",
        "    \":&gt;\" : \" sad \",\n",
        "    \":')\" : \" sad \",\n",
        "    \":-(\" : \" bad \",\n",
        "    \":(\" : \" bad \",\n",
        "    \":s\" : \" bad \",\n",
        "    \":-s\" : \" bad \"\n",
        "}\n",
        "\n",
        "#dictionnary for general (i.e. topic modeler)\n",
        "emo_repl2 = {\n",
        "    #good emotions\n",
        "    \"&lt;3\" : \" heart \",\n",
        "    \":d\" : \" smile \",\n",
        "    \":p\" : \" smile \",\n",
        "    \":dd\" : \" smile \",\n",
        "    \"8)\" : \" smile \",\n",
        "    \":-)\" : \" smile \",\n",
        "    \":)\" : \" smile \",\n",
        "    \";)\" : \" smile \",\n",
        "    \"(-:\" : \" smile \",\n",
        "    \"(:\" : \" smile \",\n",
        "       \n",
        "    #bad emotions\n",
        "    \":/\" : \" worry \",\n",
        "    \":&gt;\" : \" angry \",\n",
        "    \":')\" : \" sad \",\n",
        "    \":-(\" : \" sad \",\n",
        "    \":(\" : \" sad \",\n",
        "    \":s\" : \" sad \",\n",
        "    \":-s\" : \" sad \"\n",
        "}\n",
        "\n",
        "#general\n",
        "re_repl = {\n",
        "    r\"\\br\\b\" : \"are\",\n",
        "    r\"\\bu\\b\" : \"you\",\n",
        "    r\"\\bhaha\\b\" : \"ha\",\n",
        "    r\"\\bhahaha\\b\" : \"ha\",\n",
        "    r\"\\bdon't\\b\" : \"do not\",\n",
        "    r\"\\bdoesn't\\b\" : \"does not\",\n",
        "    r\"\\bdidn't\\b\" : \"did not\",\n",
        "    r\"\\bhasn't\\b\" : \"has not\",\n",
        "    r\"\\bhaven't\\b\" : \"have not\",\n",
        "    r\"\\bhadn't\\b\" : \"had not\",\n",
        "    r\"\\bwon't\\b\" : \"will not\",\n",
        "    r\"\\bwouldn't\\b\" : \"would not\",\n",
        "    r\"\\bcan't\\b\" : \"can not\",\n",
        "    r\"\\bcannot\\b\" : \"can not\"    \n",
        "}\n",
        "\n",
        "emo_repl_order = [k for (k_len,k) in reversed(sorted([(len(k),k) for k in emo_repl.keys()]))]\n",
        "emo_repl_order2 = [k for (k_len,k) in reversed(sorted([(len(k),k) for k in emo_repl2.keys()]))]\n",
        "\n",
        "def replace_emo(sentence):\n",
        "    sentence2 = sentence\n",
        "    for k in emo_repl_order:\n",
        "        sentence2 = sentence2.replace(k,emo_repl[k])\n",
        "    for r, repl in re_repl.items():\n",
        "        sentence2 = re.sub(r,repl,sentence2)\n",
        "    return sentence2\n",
        "\n",
        "def replace_reg(sentence):\n",
        "    sentence2 = sentence\n",
        "    for k in emo_repl_order2:\n",
        "        sentence2 = sentence2.replace(k,emo_repl2[k])\n",
        "    for r, repl in re_repl.items(): \n",
        "        sentence2 = re.sub(r,repl,sentence2)\n",
        "    return sentence2"
      ],
      "metadata": {
        "id": "57jsx2bKQrZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models, similarities\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class topic(object):\n",
        "    def __init__(self, nbtopic = 100, alpha=1,model=None,dicttp=None):\n",
        "        self.nbtopic = nbtopic\n",
        "        self.alpha = alpha\n",
        "        self.porter = nltk.PorterStemmer()\n",
        "        self.stop = stopwords.words('english')+['.','!','?','\"','...','\\\\',\"''\",'[',']','~',\"'m\",\"'s\",';',':','..','$']\n",
        "        if model!=None and dicttp!=None:\n",
        "            self.lda = models.ldamodel.LdaModel.load(model)\n",
        "            self.dictionary =  corpora.Dictionary.load(dicttp)\n",
        "            \n",
        "    def fit(self,documents):\n",
        "        \n",
        "        documents_mod = documents\n",
        "        tokens = [nltk.word_tokenize(sentence) for sentence in documents_mod]\n",
        "        tokens = [[self.porter.stem(t.lower()) for t in sentence if t.lower() not in self.stop] for sentence in tokens]        \n",
        "            \n",
        "        self.dictionary = corpora.Dictionary(tokens)\n",
        "        corpus = [self.dictionary.doc2bow(text) for text in tokens]\n",
        "        self.lda = models.ldamodel.LdaModel(corpus,id2word=self.dictionary, num_topics=self.nbtopic,alpha=self.alpha)\n",
        "        \n",
        "        self.lda.save('topics.tp')\n",
        "        self.dictionary.save('topics_dict.tp')\n",
        "        \n",
        "    def get_topic(self,topic_number):\n",
        "        \n",
        "        return self.lda.print_topic(topic_number)\n",
        "    \n",
        "    def transform(self,sentence):\n",
        "        \n",
        "        sentence_mod = sentence\n",
        "        tokens = nltk.word_tokenize(sentence_mod)\n",
        "        tokens = [self.porter.stem(t.lower()) for t in tokens if t.lower() not in self.stop] \n",
        "        corpus_sentence = self.dictionary.doc2bow(tokens)\n",
        "        \n",
        "        return self.lda[corpus_sentence] "
      ],
      "metadata": {
        "id": "lZl7Nrk8QiGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = nltk.PorterStemmer()\n"
      ],
      "metadata": {
        "id": "PPlJ6lczRiY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def sentiment_extract(features, sentence):\n",
        "    sentence_rep = replace_reg(sentence)\n",
        "    token = nltk.word_tokenize(sentence_rep)    \n",
        "    token = [porter.stem(i.lower()) for i in token]   \n",
        "    mean_sentiment = sentiments.score_sentencce(token)\n",
        "    features[\"Positive Sentiment\"] = mean_sentiment[0]\n",
        "    features[\"Negative Sentiment\"] = mean_sentiment[1]\n",
        "    features[\"sentiment\"] = mean_sentiment[0] - mean_sentiment[1]\n",
        "    #print(mean_sentiment[0], mean_sentiment[1])\n",
        "    \n",
        "    try:\n",
        "        text = TextBlob(\" \".join([\"\"+i if i not in string.punctuation and not i.startswith(\"'\") else i for i in token]).strip())\n",
        "        features[\"Blob Polarity\"] = text.sentiment.polarity\n",
        "        features[\"Blob Subjectivity\"] = text.sentiment.subjectivity\n",
        "        #print (text.sentiment.polarity,text.sentiment.subjectivity )\n",
        "    except:\n",
        "        features[\"Blob Polarity\"] = 0\n",
        "        features[\"Blob Subjectivity\"] = 0\n",
        "        # print(\"do nothing\")\n",
        "        \n",
        "    \n",
        "    first_half = token[0:len(token)//2]    \n",
        "    mean_sentiment_half = sentiments.score_sentencce(first_half)\n",
        "    features[\"positive Sentiment first half\"] = mean_sentiment_half[0]\n",
        "    features[\"negative Sentiment first half\"] = mean_sentiment_half[1]\n",
        "    features[\"first half sentiment\"] = mean_sentiment_half[0]-mean_sentiment_half[1]\n",
        "    try:\n",
        "        text = TextBlob(\" \".join([\"\"+i if i not in string.punctuation and not i.startswith(\"'\") else i for i in first_half]).strip())\n",
        "        features[\"first half Blob Polarity\"] = text.sentiment.polarity\n",
        "        features[\"first half Blob Subjectivity\"] = text.sentiment.subjectivity\n",
        "        #print (text.sentiment.polarity,text.sentiment.subjectivity )\n",
        "    except:\n",
        "        features[\"first Blob Polarity\"] = 0\n",
        "        features[\"first Blob Subjectivity\"] = 0\n",
        "        # print(\"do nothing\")\n",
        "    \n",
        "    second_half = token[len(token)//2:]\n",
        "    mean_sentiment_sechalf = sentiments.score_sentencce(second_half)\n",
        "    features[\"positive Sentiment second half\"] = mean_sentiment_sechalf[0]\n",
        "    features[\"negative Sentiment second half\"] = mean_sentiment_sechalf[1]\n",
        "    features[\"second half sentiment\"] = mean_sentiment_sechalf[0]-mean_sentiment_sechalf[1]\n",
        "    try:\n",
        "        text = TextBlob(\" \".join([\"\"+i if i not in string.punctuation and not i.startswith(\"'\") else i for i in second_half]).strip())\n",
        "        features[\"second half Blob Polarity\"] = text.sentiment.polarity\n",
        "        features[\"second half Blob Subjectivity\"] = text.sentiment.subjectivity\n",
        "        #print (text.sentiment.polarity,text.sentiment.subjectivity )\n",
        "    except:\n",
        "        features[\"second Blob Polarity\"] = 0\n",
        "        features[\"second Blob Subjectivity\"] = 0\n",
        "        # print(\"do nothing\")  \n",
        "    "
      ],
      "metadata": {
        "id": "-rfUOgkJRbwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X5Dle8aSgKr",
        "outputId": "9cd98b7c-fae7-4dd0-bfa2-40cfed84473f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_mod = topic(nbtopic=200,alpha='symmetric')\n",
        "topic_mod.fit(train['tweet'].values)\n",
        "# topic_mod = topic(model=os.path.join('topics.tp'),dicttp=os.path.join('topics_dict.tp'))\n",
        "def topic_feature(features,sentence,topic_modeler):    \n",
        "    topics = topic_modeler.transform(sentence)    \n",
        "    for j in range(len(topics)):\n",
        "        features['Topic :'] = topics[j][1]"
      ],
      "metadata": {
        "id": "lb-2odsDOodR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9akh8Iszd7iJ",
        "outputId": "396a7241-5ecb-42f6-bae9-9adab12a916d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 12.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=1dbf709a52e00cbefe5a727ae875830bdfab9f657b86e7c00b7cefdb77433f95\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "\n"
      ],
      "metadata": {
        "id": "nwqBmy_Od5J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yayFK20ud5Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Function to extract the below features.\n",
        "1. Presence of emoji's\n",
        "2. Count of number of Question marks\n",
        "3. Count of number of Exclamation marks\n",
        "4. presence of hashtags other than #sarcasm\n",
        "5. presence of any @user tweets\n",
        "\n",
        "\"\"\"\n",
        "from collections import defaultdict\n",
        "\n",
        "def Emoji_present(text):\n",
        "    emoji = {\n",
        "    \"&lt;3\" : \"positive\",\":D\" : \"positive\",\t\":d\" : \"positive\", \":dd\" : \"positive\", \":P\" : \"positive\", \":p\" : \"positive\",\"8)\" : \"positive\",\n",
        "    \"8-)\" : \"positive\",  \":-)\" : \"positive\",    \":)\" : \"positive\",    \";)\" : \"positive\",    \"(-:\" : \"positive\",    \"(:\" : \"positive\",\n",
        "    \":')\" : \"positive\",    \"xD\" : \"positive\",    \"XD\" : \"positive\",  \"yay!\" : \"positive\",  \"yay\" : \"positive\",  \"yaay\" : \"positive\",\n",
        "    \"yaaay\" : \"positive\",  \"yaaaay\" : \"positive\", \"yaaaaay\" : \"positive\", \"Yay!\" : \"positive\", \"Yay\" : \"positive\", \"Yaay\" : \"positive\",\n",
        "    \"Yaaay\" : \"positive\", \"Yaaaay\" : \"positive\", \"Yaaaaay\" : \"positive\",  \":/\" : \"negative\", \"&gt;\" : \"negative\", \":'(\" : \"negative\",\n",
        "    \":-(\" : \"negative\", \":(\" : \"negative\", \":s\" : \"negative\",\":-s\" : \"negative\",\"-_-\" : \"negative\", \"-.-\" : \"negative\" }\n",
        "    emoji_count =defaultdict(int) \n",
        "    isPresent=False    \n",
        "        \n",
        "    for word in str(text):\n",
        "        if word in emoji:            \n",
        "            isPresent = True\n",
        "\n",
        "    \n",
        "    count = 0\n",
        "    for emoji in UNICODE_EMOJI:\n",
        "        count += str(text).count(emoji)\n",
        "        if count>=1:\n",
        "          isPresent=True      \n",
        "\n",
        "    \n",
        "    return isPresent \n",
        "\n"
      ],
      "metadata": {
        "id": "FQH0XzS0SvNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n"
      ],
      "metadata": {
        "id": "BscD9ODz2YoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "sentiments = load_senti_word_net()\n",
        "\n",
        "def get_features(sentence, topic_modeler):\n",
        "    features = {}\n",
        "    # gram_features(features,sentence)\n",
        "    pos_features(features,sentence)\n",
        "    sentiment_extract(features, sentence)\n",
        "    capitalization(features,sentence)\n",
        "    topic_feature(features, sentence,topic_modeler)\n",
        "    return features"
      ],
      "metadata": {
        "id": "eVfzGysiOQsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPW8bqf4U5x2",
        "outputId": "f6d92434-68c4-411a-ccab-4557c7c200be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "gI5FHSbkVULf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rv4Ts96OWWOR",
        "outputId": "215f90e3-a0fb-453c-94ad-b879e1ae45e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f049827f-9dd8-4b68-98b1-3dcecf215c0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Less than 5 minutes after getting my phone bac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love seeing 15 year olds being vaccinated in t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>im about to just walk into a place and start w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Every time I comment on a TikTok asking for ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2769</th>\n",
              "      <td>This weekend I hit a delivery biker with a car...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2770</th>\n",
              "      <td>This country is screwed let’s be honest</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>I always come up with some pretty interesting ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2772</th>\n",
              "      <td>@andy_mansell72 @VicOtley @garry_whu @NiaAnts ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>Poor Steve Clifford. Next hire has to be right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2774 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f049827f-9dd8-4b68-98b1-3dcecf215c0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f049827f-9dd8-4b68-98b1-3dcecf215c0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f049827f-9dd8-4b68-98b1-3dcecf215c0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  tweet  sarcastic\n",
              "0     Less than 5 minutes after getting my phone bac...          0\n",
              "1     Love seeing 15 year olds being vaccinated in t...          1\n",
              "2     I get a lot of boy who cried wolf vibes from t...          1\n",
              "3     im about to just walk into a place and start w...          1\n",
              "4     Every time I comment on a TikTok asking for ca...          0\n",
              "...                                                 ...        ...\n",
              "2769  This weekend I hit a delivery biker with a car...          0\n",
              "2770            This country is screwed let’s be honest          0\n",
              "2771  I always come up with some pretty interesting ...          0\n",
              "2772  @andy_mansell72 @VicOtley @garry_whu @NiaAnts ...          1\n",
              "2773  Poor Steve Clifford. Next hire has to be right...          0\n",
              "\n",
              "[2774 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "featureset=[]\n",
        "for i in range(0,len(train)):\n",
        "    # if i==2774or i==2775:\n",
        "    #   continue\n",
        "    temp = str(train[\"tweet\"][i])\n",
        "    temp = re.sub(r'[^\\x00-\\x7F]+','',temp)\n",
        "    featureset.append((get_features(temp,topic_mod), train[\"sarcastic\"][i], train[\"tweet\"][i]))"
      ],
      "metadata": {
        "id": "PKad5JFRUME4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = []\n",
        "for i in range(0,len(featureset)):\n",
        "    c.append(pd.DataFrame(featureset[i][0],index=[i]))\n",
        "result = pd.concat(c)"
      ],
      "metadata": {
        "id": "ix-ZJYU8UR4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.insert(loc=0,column=\"label\",value='0')\n",
        "for i in range(0, len(featureset)):\n",
        "    result[\"label\"].loc[i] = featureset[i][1]   \n",
        "\n",
        "result.insert(loc=0,column=\"text\",value='0')\n",
        "for i in range(0, len(featureset)):\n",
        "    result[\"text\"].loc[i] = featureset[i][2]  \n",
        "    "
      ],
      "metadata": {
        "id": "C9r8-e2LUYdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "OgqIJA2MVMPe",
        "outputId": "6f83d5b7-8cd3-4a24-eb9a-cddd1ea9c732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d25648ca-b335-4d43-b124-f5ec1a993522\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>POS_1</th>\n",
              "      <th>POS_2</th>\n",
              "      <th>POS_3</th>\n",
              "      <th>POS_4</th>\n",
              "      <th>Positive Sentiment</th>\n",
              "      <th>Negative Sentiment</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Blob Polarity</th>\n",
              "      <th>Blob Subjectivity</th>\n",
              "      <th>positive Sentiment first half</th>\n",
              "      <th>negative Sentiment first half</th>\n",
              "      <th>first half sentiment</th>\n",
              "      <th>first Blob Polarity</th>\n",
              "      <th>first Blob Subjectivity</th>\n",
              "      <th>positive Sentiment second half</th>\n",
              "      <th>negative Sentiment second half</th>\n",
              "      <th>second half sentiment</th>\n",
              "      <th>second Blob Polarity</th>\n",
              "      <th>second Blob Subjectivity</th>\n",
              "      <th>Capitalization</th>\n",
              "      <th>Topic :</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Less than 5 minutes after getting my phone bac...</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.095620</td>\n",
              "      <td>0.432559</td>\n",
              "      <td>-0.336939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.076389</td>\n",
              "      <td>0.315972</td>\n",
              "      <td>-0.239583</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.116587</td>\n",
              "      <td>-0.097356</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.786919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love seeing 15 year olds being vaccinated in t...</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.980875</td>\n",
              "      <td>0.337487</td>\n",
              "      <td>0.643387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.856971</td>\n",
              "      <td>0.159856</td>\n",
              "      <td>0.697115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.123904</td>\n",
              "      <td>0.177632</td>\n",
              "      <td>-0.053728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.118817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.380556</td>\n",
              "      <td>0.743651</td>\n",
              "      <td>-0.363095</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.097222</td>\n",
              "      <td>0.251984</td>\n",
              "      <td>-0.154762</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>-0.208333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.072668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>im about to just walk into a place and start w...</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.213412</td>\n",
              "      <td>0.136337</td>\n",
              "      <td>0.077076</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.157961</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.118899</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.055451</td>\n",
              "      <td>0.097274</td>\n",
              "      <td>-0.041823</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.083048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Every time I comment on a TikTok asking for ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.717014</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>0.194792</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>-0.008333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.258681</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.078510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d25648ca-b335-4d43-b124-f5ec1a993522')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d25648ca-b335-4d43-b124-f5ec1a993522 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d25648ca-b335-4d43-b124-f5ec1a993522');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...   Topic :\n",
              "0  Less than 5 minutes after getting my phone bac...  ...  0.786919\n",
              "1  Love seeing 15 year olds being vaccinated in t...  ...  0.118817\n",
              "2  I get a lot of boy who cried wolf vibes from t...  ...  0.072668\n",
              "3  im about to just walk into a place and start w...  ...  0.083048\n",
              "4  Every time I comment on a TikTok asking for ca...  ...  0.078510\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['contain_emoji']=result['text'].apply(Emoji_present)"
      ],
      "metadata": {
        "id": "7CI75KEddocK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_special_chracter']=result['text'].apply(count_character_type)"
      ],
      "metadata": {
        "id": "3gs_qM3hjJMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_question_marks']=result['text'].apply(count_question_mark)"
      ],
      "metadata": {
        "id": "UQBcFIQ-jRsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "tFjacVPO2pj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['subjectivity']=result['text'].apply(get_subjectivity)"
      ],
      "metadata": {
        "id": "77IizoKsjaW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_verbs']=result['text'].apply(get_verb_count)"
      ],
      "metadata": {
        "id": "c7Y5sfbyjgsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_nouns']=result['text'].apply(get_noun_count)"
      ],
      "metadata": {
        "id": "AXi3mu6LjjPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_pronun']=result['text'].apply(get_pron_count)"
      ],
      "metadata": {
        "id": "asRUMhBejkyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_adjct']=result['text'].apply(get_adj_count)"
      ],
      "metadata": {
        "id": "a99m0-eqjnEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['entities']=result['text'].apply(entity_wordcloud)"
      ],
      "metadata": {
        "id": "T1V5-3jSj08_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['count_profane']=result['text'].apply(count_profane_words)"
      ],
      "metadata": {
        "id": "X2di7JK4j7ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "0WcAXdCukqk1",
        "outputId": "f13d1af5-2309-46fb-f5d6-beed770bcbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdf92b79-e844-4fae-8156-d88802884f20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>POS_1</th>\n",
              "      <th>POS_2</th>\n",
              "      <th>POS_3</th>\n",
              "      <th>POS_4</th>\n",
              "      <th>Positive Sentiment</th>\n",
              "      <th>Negative Sentiment</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Blob Polarity</th>\n",
              "      <th>Blob Subjectivity</th>\n",
              "      <th>positive Sentiment first half</th>\n",
              "      <th>negative Sentiment first half</th>\n",
              "      <th>first half sentiment</th>\n",
              "      <th>first Blob Polarity</th>\n",
              "      <th>first Blob Subjectivity</th>\n",
              "      <th>positive Sentiment second half</th>\n",
              "      <th>negative Sentiment second half</th>\n",
              "      <th>second half sentiment</th>\n",
              "      <th>second Blob Polarity</th>\n",
              "      <th>second Blob Subjectivity</th>\n",
              "      <th>Capitalization</th>\n",
              "      <th>Topic :</th>\n",
              "      <th>contain_emoji</th>\n",
              "      <th>count_special_chracter</th>\n",
              "      <th>count_question_marks</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>count_verbs</th>\n",
              "      <th>count_nouns</th>\n",
              "      <th>count_pronun</th>\n",
              "      <th>count_adjct</th>\n",
              "      <th>entities</th>\n",
              "      <th>count_profane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Less than 5 minutes after getting my phone bac...</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.095620</td>\n",
              "      <td>0.432559</td>\n",
              "      <td>-0.336939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.076389</td>\n",
              "      <td>0.315972</td>\n",
              "      <td>-0.239583</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.116587</td>\n",
              "      <td>-0.097356</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.786919</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Less than 5 minutes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love seeing 15 year olds being vaccinated in t...</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.980875</td>\n",
              "      <td>0.337487</td>\n",
              "      <td>0.643387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.856971</td>\n",
              "      <td>0.159856</td>\n",
              "      <td>0.697115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.123904</td>\n",
              "      <td>0.177632</td>\n",
              "      <td>-0.053728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.118817</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15 year olds the end of June first</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.380556</td>\n",
              "      <td>0.743651</td>\n",
              "      <td>-0.363095</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.097222</td>\n",
              "      <td>0.251984</td>\n",
              "      <td>-0.154762</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>-0.208333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.072668</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>wolf vibes the Red Cross</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>im about to just walk into a place and start w...</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.213412</td>\n",
              "      <td>0.136337</td>\n",
              "      <td>0.077076</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.157961</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.118899</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.055451</td>\n",
              "      <td>0.097274</td>\n",
              "      <td>-0.041823</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.083048</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Every time I comment on a TikTok asking for ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.717014</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>0.194792</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>-0.008333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.258681</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.078510</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdf92b79-e844-4fae-8156-d88802884f20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdf92b79-e844-4fae-8156-d88802884f20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdf92b79-e844-4fae-8156-d88802884f20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ... count_profane\n",
              "0  Less than 5 minutes after getting my phone bac...  ...             0\n",
              "1  Love seeing 15 year olds being vaccinated in t...  ...             0\n",
              "2  I get a lot of boy who cried wolf vibes from t...  ...             0\n",
              "3  im about to just walk into a place and start w...  ...             0\n",
              "4  Every time I comment on a TikTok asking for ca...  ...             0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gqZlPzMlCrU",
        "outputId": "c7bb4258-5f92-4e39-b4dd-cd74fdc139a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "694"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "feature_set_test=[]\n",
        "for i, row in test.iterrows():\n",
        "    # if i==0:\n",
        "    #   continue\n",
        "    temp = str(test[\"tweet\"][i])\n",
        "    temp = re.sub(r'[^\\x00-\\x7F]+','',temp)\n",
        "    feature_set_test.append((get_features(temp,topic_mod), test[\"sarcastic\"][i],test['tweet'][i]))"
      ],
      "metadata": {
        "id": "aeTfxr2SX1HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = []\n",
        "for i in range(0,len(feature_set_test)):\n",
        "    c.append(pd.DataFrame(feature_set_test[i][0],index=[i]))\n",
        "result_test = pd.concat(c)"
      ],
      "metadata": {
        "id": "I98P3AwQX8cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test.insert(loc=0,column=\"label\",value='0')\n",
        "for i in range(0, len(feature_set_test)):\n",
        "    result_test[\"label\"].loc[i] = feature_set_test[i][1]   \n",
        "\n",
        "result_test.insert(loc=0,column=\"text\",value='0')\n",
        "for i in range(0, len(feature_set_test)):\n",
        "    result_test[\"text\"].loc[i] = feature_set_test[i][2]   \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "iCdRH7I4X_Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "ATWpD3Qfl0ar",
        "outputId": "a09c3802-8485-483f-bd7e-f25eb2a8e0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7eead149-1069-49f8-a3e3-cc5c95200d01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>POS_1</th>\n",
              "      <th>POS_2</th>\n",
              "      <th>POS_3</th>\n",
              "      <th>POS_4</th>\n",
              "      <th>Positive Sentiment</th>\n",
              "      <th>Negative Sentiment</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Blob Polarity</th>\n",
              "      <th>Blob Subjectivity</th>\n",
              "      <th>positive Sentiment first half</th>\n",
              "      <th>negative Sentiment first half</th>\n",
              "      <th>first half sentiment</th>\n",
              "      <th>first half Blob Polarity</th>\n",
              "      <th>first half Blob Subjectivity</th>\n",
              "      <th>positive Sentiment second half</th>\n",
              "      <th>negative Sentiment second half</th>\n",
              "      <th>second half sentiment</th>\n",
              "      <th>second half Blob Polarity</th>\n",
              "      <th>second half Blob Subjectivity</th>\n",
              "      <th>Capitalization</th>\n",
              "      <th>Topic :</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The world according to Jeff Goldblum is such a...</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322917</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>-0.031250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>-0.031250</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.251250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@kevinabstract ye</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.367771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rubbing my tears into my face is part of my sk...</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.184295</td>\n",
              "      <td>-0.165064</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.184295</td>\n",
              "      <td>-0.165064</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.143572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's the German word for when you start a po...</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.922618</td>\n",
              "      <td>0.699750</td>\n",
              "      <td>0.222868</td>\n",
              "      <td>0.134091</td>\n",
              "      <td>0.188636</td>\n",
              "      <td>0.216518</td>\n",
              "      <td>0.158482</td>\n",
              "      <td>0.058036</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.706100</td>\n",
              "      <td>0.541268</td>\n",
              "      <td>0.164833</td>\n",
              "      <td>0.218182</td>\n",
              "      <td>0.277273</td>\n",
              "      <td>0</td>\n",
              "      <td>0.093709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prayers go up, blessings come down</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.077381</td>\n",
              "      <td>0.010119</td>\n",
              "      <td>0.067262</td>\n",
              "      <td>-0.155556</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.029762</td>\n",
              "      <td>-0.155556</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7eead149-1069-49f8-a3e3-cc5c95200d01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7eead149-1069-49f8-a3e3-cc5c95200d01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7eead149-1069-49f8-a3e3-cc5c95200d01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...   Topic :\n",
              "0  The world according to Jeff Goldblum is such a...  ...  0.251250\n",
              "1                                  @kevinabstract ye  ...  0.367771\n",
              "2  Rubbing my tears into my face is part of my sk...  ...  0.143572\n",
              "3  What's the German word for when you start a po...  ...  0.093709\n",
              "4                 Prayers go up, blessings come down  ...  0.200284\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['contain_emoji']=result_test['text'].apply(Emoji_present)"
      ],
      "metadata": {
        "id": "LD992kH5lqno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_special_chracter']=result_test['text'].apply(count_character_type)"
      ],
      "metadata": {
        "id": "K6CEQhtqlqnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_question_marks']=result_test['text'].apply(count_question_mark)"
      ],
      "metadata": {
        "id": "669r5-BRlqnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['subjectivity']=result_test['text'].apply(get_subjectivity)"
      ],
      "metadata": {
        "id": "LP8RbIDNlqnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_verbs']=result_test['text'].apply(get_verb_count)"
      ],
      "metadata": {
        "id": "jeWDu0iqlqnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_nouns']=result_test['text'].apply(get_noun_count)"
      ],
      "metadata": {
        "id": "g6KOyVJ2lqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_pronun']=result_test['text'].apply(get_pron_count)"
      ],
      "metadata": {
        "id": "AjISOHtklqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_adjct']=result_test['text'].apply(get_adj_count)"
      ],
      "metadata": {
        "id": "JxHWo1ttlqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['entities']=result_test['text'].apply(entity_wordcloud)"
      ],
      "metadata": {
        "id": "_X0ZgPmalqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test['count_profane']=result_test['text'].apply(count_profane_words)"
      ],
      "metadata": {
        "id": "VfaQ52lMlqnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "sElXvwyKm0PA",
        "outputId": "e91563de-b884-446b-a65c-482b1ff16131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7658a62d-14e0-4d63-8011-4c7165b664e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>POS_1</th>\n",
              "      <th>POS_2</th>\n",
              "      <th>POS_3</th>\n",
              "      <th>POS_4</th>\n",
              "      <th>Positive Sentiment</th>\n",
              "      <th>Negative Sentiment</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Blob Polarity</th>\n",
              "      <th>Blob Subjectivity</th>\n",
              "      <th>positive Sentiment first half</th>\n",
              "      <th>negative Sentiment first half</th>\n",
              "      <th>first half sentiment</th>\n",
              "      <th>first half Blob Polarity</th>\n",
              "      <th>first half Blob Subjectivity</th>\n",
              "      <th>positive Sentiment second half</th>\n",
              "      <th>negative Sentiment second half</th>\n",
              "      <th>second half sentiment</th>\n",
              "      <th>second half Blob Polarity</th>\n",
              "      <th>second half Blob Subjectivity</th>\n",
              "      <th>Capitalization</th>\n",
              "      <th>Topic :</th>\n",
              "      <th>contain_emoji</th>\n",
              "      <th>count_special_chracter</th>\n",
              "      <th>count_question_marks</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>count_verbs</th>\n",
              "      <th>count_nouns</th>\n",
              "      <th>count_pronun</th>\n",
              "      <th>count_adjct</th>\n",
              "      <th>entities</th>\n",
              "      <th>count_profane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The world according to Jeff Goldblum is such a...</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322917</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>-0.031250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>-0.031250</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.251250</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Jeff Goldblum</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@kevinabstract ye</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.367771</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rubbing my tears into my face is part of my sk...</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.184295</td>\n",
              "      <td>-0.165064</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.184295</td>\n",
              "      <td>-0.165064</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.143572</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's the German word for when you start a po...</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.922618</td>\n",
              "      <td>0.699750</td>\n",
              "      <td>0.222868</td>\n",
              "      <td>0.134091</td>\n",
              "      <td>0.188636</td>\n",
              "      <td>0.216518</td>\n",
              "      <td>0.158482</td>\n",
              "      <td>0.058036</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.706100</td>\n",
              "      <td>0.541268</td>\n",
              "      <td>0.164833</td>\n",
              "      <td>0.218182</td>\n",
              "      <td>0.277273</td>\n",
              "      <td>0</td>\n",
              "      <td>0.093709</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.188636</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>German 2 years old present-day every week 3 mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prayers go up, blessings come down</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.077381</td>\n",
              "      <td>0.010119</td>\n",
              "      <td>0.067262</td>\n",
              "      <td>-0.155556</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.029762</td>\n",
              "      <td>-0.155556</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200284</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7658a62d-14e0-4d63-8011-4c7165b664e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7658a62d-14e0-4d63-8011-4c7165b664e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7658a62d-14e0-4d63-8011-4c7165b664e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ... count_profane\n",
              "0  The world according to Jeff Goldblum is such a...  ...             0\n",
              "1                                  @kevinabstract ye  ...             0\n",
              "2  Rubbing my tears into my face is part of my sk...  ...             0\n",
              "3  What's the German word for when you start a po...  ...             0\n",
              "4                 Prayers go up, blessings come down  ...             0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_test.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CU0CSKjnNNz",
        "outputId": "14f6d3e3-f265-4ead-c710-4c5d530aa4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label', 'POS_1', 'POS_2', 'POS_3', 'POS_4',\n",
              "       'Positive Sentiment', 'Negative Sentiment', 'sentiment',\n",
              "       'Blob Polarity', 'Blob Subjectivity', 'positive Sentiment first half',\n",
              "       'negative Sentiment first half', 'first half sentiment',\n",
              "       'first half Blob Polarity', 'first half Blob Subjectivity',\n",
              "       'positive Sentiment second half', 'negative Sentiment second half',\n",
              "       'second half sentiment', 'second half Blob Polarity',\n",
              "       'second half Blob Subjectivity', 'Capitalization', 'Topic :',\n",
              "       'contain_emoji', 'count_special_chracter', 'count_question_marks',\n",
              "       'subjectivity', 'count_verbs', 'count_nouns', 'count_pronun',\n",
              "       'count_adjct', 'entities', 'count_profane'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "H61gm8QGpHYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "8XyQIdKRpKyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train,x_train_text=result[['POS_1', 'POS_2', 'POS_3', 'POS_4',\n",
        "       'Positive Sentiment', 'Negative Sentiment', 'sentiment',\n",
        "       'Blob Polarity', 'Blob Subjectivity', 'positive Sentiment first half',\n",
        "       'negative Sentiment first half', 'first half sentiment',\n",
        "       'first half Blob Polarity', 'first half Blob Subjectivity',\n",
        "       'positive Sentiment second half', 'negative Sentiment second half',\n",
        "       'second half sentiment', 'second half Blob Polarity',\n",
        "       'second half Blob Subjectivity', 'Capitalization', 'Topic :',\n",
        "       'contain_emoji', 'count_special_chracter', 'count_question_marks',\n",
        "       'subjectivity', 'count_verbs', 'count_nouns', 'count_pronun',\n",
        "       'count_adjct', 'count_profane']],result[['label']],result[['text']]"
      ],
      "metadata": {
        "id": "v8id-O7qofmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test,y_test,x_test_text=result_test[['POS_1', 'POS_2', 'POS_3', 'POS_4',\n",
        "       'Positive Sentiment', 'Negative Sentiment', 'sentiment',\n",
        "       'Blob Polarity', 'Blob Subjectivity', 'positive Sentiment first half',\n",
        "       'negative Sentiment first half', 'first half sentiment',\n",
        "       'first half Blob Polarity', 'first half Blob Subjectivity',\n",
        "       'positive Sentiment second half', 'negative Sentiment second half',\n",
        "       'second half sentiment', 'second half Blob Polarity',\n",
        "       'second half Blob Subjectivity', 'Capitalization', 'Topic :',\n",
        "       'contain_emoji', 'count_special_chracter', 'count_question_marks',\n",
        "       'subjectivity', 'count_verbs', 'count_nouns', 'count_pronun',\n",
        "       'count_adjct', 'count_profane']],result_test[['label']],result_test[['text']]"
      ],
      "metadata": {
        "id": "60UsCFeoooCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6FY70KZ6TY"
      },
      "source": [
        "# RoBERTa Baseline for Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA9QzHTCl5F6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlT2IDHumPNi",
        "outputId": "50994a6b-2738-4a25-b3db-1e1f07a42b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 122 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 174 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 184 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 194 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 204 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 215 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 225 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 235 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 245 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 256 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 266 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 276 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 286 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 296 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 306 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.2.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 53.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.9)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2021.11.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-E_jNQbV_NL"
      },
      "outputs": [],
      "source": [
        "class PCLTrainDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length,displacemnt):\n",
        "        self.df = df\n",
        "        self.max_len = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = df['text'].values\n",
        "        self.fetures = df[['POS_1', 'POS_2', 'POS_3', 'POS_4',\n",
        "       'Positive Sentiment', 'Negative Sentiment', 'sentiment',\n",
        "       'Blob Polarity', 'Blob Subjectivity', 'positive Sentiment first half',\n",
        "       'negative Sentiment first half', 'first half sentiment',\n",
        "       'first half Blob Polarity', 'first half Blob Subjectivity',\n",
        "       'positive Sentiment second half', 'negative Sentiment second half',\n",
        "       'second half sentiment', 'second half Blob Polarity',\n",
        "       'second half Blob Subjectivity', 'Capitalization', 'Topic :',\n",
        "       'contain_emoji', 'count_special_chracter', 'count_question_marks',\n",
        "       'subjectivity', 'count_verbs', 'count_nouns', 'count_pronun',\n",
        "       'count_adjct', 'count_profane']].astype(float).values\n",
        "       \n",
        "        self.label=df['label'].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        # summary = self.summary[index]\n",
        "        inputs_text = self.tokenizer.encode_plus(\n",
        "                                text,\n",
        "                                truncation=True,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length=self.max_len,\n",
        "                                padding='max_length'\n",
        "                            )\n",
        "        \n",
        "                            \n",
        "        target = self.label[index]\n",
        "        \n",
        "        text_ids = inputs_text['input_ids']\n",
        "        text_mask = inputs_text['attention_mask']\n",
        "        \n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "        return {\n",
        "            \n",
        "            'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
        "            'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
        "            'features': torch.tensor(self.fetures[index], dtype=torch.float),\n",
        "            'target': torch.tensor(target, dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "    return 1/(1+math.exp(-x))"
      ],
      "metadata": {
        "id": "WLXkQK5Bawae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Recall_Loss(nn.Module):\n",
        "    '''Calculate F1 score. Can work with gpu tensors\n",
        "    \n",
        "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        `ndim` == 1. epsilon <= val <= 1\n",
        "    \n",
        "    Reference\n",
        "    ---------\n",
        "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
        "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
        "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n",
        "    '''\n",
        "    def __init__(self, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true,):\n",
        "        # assert y_pred.ndim == 2\n",
        "        # assert y_true.ndim == 1\n",
        "        # print(y_pred.shape)\n",
        "        # print(y_true.shape)\n",
        "        # y_pred[y_pred<0.5]=0\n",
        "        # y_pred[y_pred>=0.5]=0\n",
        "\n",
        "\n",
        "        \n",
        "        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2).to(torch.float32)\n",
        "        # y_pred_one_hot = F.one_hot(y_pred.to(torch.int64), 2).to(torch.float32)\n",
        "        \n",
        "        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        # f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
        "        # f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        # f1=f1.detach()\n",
        "        # print(f1.shape)\n",
        "        # y_pred=y_pred.reshape((y_pred.shape[0], 1))\n",
        "        # y_true=y_true.reshape((y_true.shape[0], 1))\n",
        "\n",
        "        # p1=y_true*(math.log(sigmoid(y_pred)))*(1-f1)[1]\n",
        "        # p0=(1-y_true)*math.log(1-sigmoid(y_pred))*(1-f1)[0]\n",
        "\n",
        "\n",
        "        # y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2)\n",
        "        # print(y_pred)\n",
        "        # print(y_true_one_hot)\n",
        "        recall=recall.detach()\n",
        "        CE =torch.nn.CrossEntropyLoss(weight=( 1 - recall))(y_pred, y_true_one_hot)\n",
        "        # loss = ( 1 - f1)  * CE\n",
        "        return  CE.mean()"
      ],
      "metadata": {
        "id": "skGp5I4wM_Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZa-chAxXf5r"
      },
      "outputs": [],
      "source": [
        "class PCL_Model_Arch(nn.Module):\n",
        "    def __init__(self,pre_trained='bert-base-uncased'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = AutoModel.from_pretrained(pre_trained, output_hidden_states=True)\n",
        "        self.hidden_size = self.bert.config.hidden_size\n",
        "        self.LSTM_1 = nn.LSTM(self.hidden_size,self.hidden_size,bidirectional=True)\n",
        "        self.LSTM_2 = nn.LSTM(self.hidden_size,self.hidden_size,bidirectional=True)\n",
        "        self.LSTM_3 = nn.LSTM(self.hidden_size,self.hidden_size,bidirectional=True)\n",
        "        self.LSTM_4 = nn.LSTM(self.hidden_size,self.hidden_size,bidirectional=True)\n",
        "        self.clf_1 = nn.Linear(self.hidden_size*8,30)\n",
        "        self.clf_2=nn.Linear(30,30)\n",
        "        self.clf_final=nn.Linear(60,2)\n",
        "        \n",
        "    def forward(self,text_id, text_mask,features):\n",
        "        \n",
        "        outputs = self.bert(input_ids=text_id,attention_mask=text_mask)\n",
        "        encoded_layers = outputs[2]\n",
        "        encoded_layer_1 = encoded_layers[-1].permute(1, 0, 2)\n",
        "        encoded_layer_2 = encoded_layers[-2].permute(1, 0, 2)\n",
        "        encoded_layer_3 = encoded_layers[-3].permute(1, 0, 2)\n",
        "        encoded_layer_4 = encoded_layers[-3].permute(1, 0, 2)\n",
        "        enc_hiddens, (last_hidden_1, last_cell) = self.LSTM_1(encoded_layer_1)\n",
        "        enc_hiddens, (last_hidden_2, last_cell) = self.LSTM_2(encoded_layer_2)\n",
        "        enc_hiddens, (last_hidden_3, last_cell) = self.LSTM_3(encoded_layer_3)\n",
        "        enc_hiddens, (last_hidden_4, last_cell) = self.LSTM_4(encoded_layer_4)\n",
        "        output_hidden = torch.cat((last_hidden_1[0], last_hidden_1[1],last_hidden_2[0], last_hidden_2[1],last_hidden_3[0], last_hidden_3[1],last_hidden_4[0], last_hidden_4[1]), dim=1)\n",
        "        output_hidden = F.dropout(output_hidden,0.2)\n",
        "        output_hidden = self.clf_1(output_hidden)\n",
        "        out_2=self.clf_2(features)\n",
        "        output = torch.cat((output_hidden,out_2), dim=1)\n",
        "        output=self.clf_final(output)\n",
        "        \n",
        "        return F.softmax(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class PCL_Model_Arch(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(PCL_Model_Arch, self).__init__()\n",
        "#         self.bert = AutoModel.from_pretrained('google/canine-c', output_hidden_states=False)\n",
        "#         self.drop = nn.Dropout(p=0.2)\n",
        "#         self.fc = nn.Linear(768, 2)\n",
        "\n",
        "        \n",
        "#         self.softmax = nn.Softmax()\n",
        "\n",
        "#     def forward(self, text_id, text_mask):\n",
        "#         # get the last 4 layers\n",
        "#         outputs= self.bert(text_id, attention_mask=text_mask)\n",
        "#         # all_layers  = [4, 16, 256, 768]\n",
        "#         hidden_layers = outputs[1]  # get hidden layers\n",
        "#         torch.cuda.empty_cache()\n",
        "\n",
        "        \n",
        "#         x = self.drop(hidden_layers)\n",
        "#         torch.cuda.empty_cache()\n",
        "#         # generate logits (batch, target_size)\n",
        "#         logit = self.fc(x)\n",
        "#         torch.cuda.empty_cache()\n",
        "#         return self.softmax(logit)"
      ],
      "metadata": {
        "id": "IfQwNPiRx_6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuODW43NYhTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "2b9bbca0bef341dbbf6ed7842a86bda8",
            "0080f49699b34f3e98b665772aadc600",
            "26a67b64340346b9a08d4107500e7731",
            "062aac1c5724452b93df4dcdb15a9766",
            "1b4c603f5c184adc968f8299b33df99a",
            "c615288d9775421c8913bf5eed9872ef",
            "1baa4d362fc746ad803345ee0f9e3807",
            "4f6303eccbd74d5ea6d0412ebd704749",
            "896c504cae164ab4ad25d1e2b8c07f33",
            "2ca44c7758b64b8dabe3971147b2c480",
            "1a982e69a2d14b81a0a2ee81d5d4bcbc",
            "d9b9bc61639445f2b9050ccd04febb3a",
            "8f7d5d62a968489d945b2eccb51d4d46",
            "eb38dc1c02944bbe8dc46f7aae0fec3d",
            "90f59a935a7b4e6f83c659fc46761ee6",
            "a09e419a2c344fd591f64f0938c3a438",
            "652beb3e38cd4d5297f39f284d56b5bb",
            "c4d58c810eb74179a315b7b094b744df",
            "51bfc7e758b44aae986ac052f4d74ac7",
            "0b70358c2de64d089a1b7b87a9f0dd0a",
            "f1626b5d4ba0465b8fdeea79fd2f4962",
            "d3d23150c7e645f984c21bf9a0a17b2a",
            "bce8ad6d1dd6407abab32aaadeb801da",
            "65d9025904024cd8af5cd3543fe38cdc",
            "759aa8961f294b06b43add63ddb5ea59",
            "7586b7e73a034d2885d1af0ef6cb829e",
            "446ce8e71aef48a89e8d8c60fada4cee",
            "f451996517d04d90aa993d61cfca39d8",
            "d6552a0ae0db4d6887bc679264d28403",
            "c684703538314a3f84edea53fb62908b",
            "f50a9cec1a064f0295fe4b015c60c142",
            "e98812885c0d4ef5a679ae6af004c747",
            "8d460c42382c4833b53df0050edd2c3d",
            "62eab194bfc9435e8b642c628aa0dcff",
            "8e96b92100a945b8ab2c697ad3d26d1f",
            "1b87b276a6034aaba384a82d2ecd7768",
            "f4deea6c2b1e4e839bde5c3da090a4a4",
            "08862aae5aed44889752fbae9b9f8cdc",
            "b3765a6da830499dab4c8da3ffa3c382",
            "009212da43b1421283e16f7956106fb0",
            "e905eaeaca8b4f05abe8f7b8c1ab996d",
            "a9ae5f9d005e4d2db43b45f202f44240",
            "8e916f269d714ef89b8f83b51ac84de0",
            "6674f5ff4c9c45d0b822c02b50de5e1b"
          ]
        },
        "outputId": "47a74f03-de02-4f97-b650-ef267f640ef5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b9bbca0bef341dbbf6ed7842a86bda8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9b9bc61639445f2b9050ccd04febb3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bce8ad6d1dd6407abab32aaadeb801da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62eab194bfc9435e8b642c628aa0dcff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer= AutoTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0XUHerFY2jd"
      },
      "outputs": [],
      "source": [
        "def criterion(outputs1,  targets):\n",
        "\n",
        "    criterion = Recall_Loss()\n",
        "    loss = criterion(outputs1, targets)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
        "    \"\"\"\n",
        "    Samples elements randomly from a given list of indices for imbalanced dataset\n",
        "    Arguments:\n",
        "        indices (list, optional): a list of indices\n",
        "        num_samples (int, optional): number of samples to draw\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, indices=None, num_samples=None):\n",
        "        # if indices is not provided,\n",
        "        # all elements in the dataset will be considered\n",
        "        self.indices = list(range(len(dataset.label))) \\\n",
        "            if indices is None else indices\n",
        "\n",
        "        # if num_samples is not provided,\n",
        "        # draw `len(indices)` samples in each iteration\n",
        "        self.num_samples = len(self.indices) \\\n",
        "            if num_samples is None else num_samples\n",
        "\n",
        "        # distribution of classes in the dataset\n",
        "        label_to_count = {}\n",
        "        for idx in self.indices:\n",
        "            label = self._get_label(dataset, idx)\n",
        "            if label in label_to_count:\n",
        "                label_to_count[label] += 1\n",
        "            else:\n",
        "                label_to_count[label] = 1\n",
        "\n",
        "        # weight for each sample\n",
        "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n",
        "        self.weights = torch.DoubleTensor(weights)\n",
        "\n",
        "    def _get_label(self, dataset, id_):\n",
        "        return dataset.label[id_]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "metadata": {
        "id": "Zeh7f_UdC6dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRX0b55VaxmS"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\"seed\": 2021,\n",
        "          \"epochs\": 3,\n",
        "          \"model_name\": \"xlnet-base-cased\",\n",
        "          \"train_batch_size\": 8,\n",
        "          \"valid_batch_size\": 64,\n",
        "          \"max_length\": 256,\n",
        "          \"learning_rate\": 1e-4,\n",
        "          \"scheduler\": 'CosineAnnealingLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"num_classes\": 1,\n",
        "          \"margin\": 0.5,\n",
        "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4afl1P8LaD07"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        \n",
        "        text_ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        text_mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        fetures=data['features'].to(device, dtype = torch.float)\n",
        "        targets = data['target'].to(device, dtype=torch.long)\n",
        "        \n",
        "        batch_size = text_ids.size(0)\n",
        "        # print(targets)\n",
        "\n",
        "        outputs = model(text_ids, text_mask,fetures)\n",
        "        # print(outputs.shape)\n",
        "        \n",
        "        # print(outputs.shape)\n",
        "\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        loss = loss / CONFIG['n_accumulate']\n",
        "        loss.backward()\n",
        "    \n",
        "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
        "            optimizer.step()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
        "                        LR=optimizer.param_groups[0]['lr'])\n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdWI_KWRafLZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:        \n",
        "        \n",
        "        text_ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        text_mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        targets = data['target'].to(device, dtype=torch.long)\n",
        "        fetures=data['features'].to(device, dtype = torch.float)\n",
        "        \n",
        "        batch_size = text_ids.size(0)\n",
        "\n",
        "        outputs = model(text_ids, text_mask,fetures)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "        \n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
        "                        LR=optimizer.param_groups[0]['lr'])   \n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1wtBAJJbEou"
      },
      "outputs": [],
      "source": [
        "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
        "    # To automatically log gradients\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "    \n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1): \n",
        "        gc.collect()\n",
        "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           device=CONFIG['device'], epoch=epoch)\n",
        "        \n",
        "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
        "                                         epoch=epoch)\n",
        "    \n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "        \n",
        "       \n",
        "        \n",
        "        # deep copy the model\n",
        "        if val_epoch_loss <= best_epoch_loss:\n",
        "            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
        "            best_epoch_loss = val_epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = f\"/content/drive/MyDrive/ISarcasm/Models/deberta_base/Loss-Fold-{fold}.bin\"\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            # Save a model file from the current directory\n",
        "            print(\"Model Saved\")\n",
        "            \n",
        "        print()\n",
        "    \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
        "    \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSXiJa2-bRiX"
      },
      "outputs": [],
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
        "                                                   eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
        "                                                             eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6nXhK_ObVNe"
      },
      "outputs": [],
      "source": [
        "def prepare_loaders(fold):\n",
        "    displacemnt_list=[0,512,1024,1536,2048,2560,3072,3584,4096,4608,4950]\n",
        "    df_train = result[result.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = result[result.kfold == fold].reset_index(drop=True)\n",
        "    sampler = ImbalancedDatasetSampler(df_train)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    train_dataset = PCLTrainDataset(df_train, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=displacemnt_list[fold])\n",
        "    valid_dataset = PCLTrainDataset(df_valid, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=displacemnt_list[fold])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True, drop_last=True,sampler=sampler)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)\n",
        "    \n",
        "    return train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.label.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL_n__e341e-",
        "outputId": "e01c4ddf-5bb3-41b5-cec1-c9f55c9689c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "zbYBYC5E5ODt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCN4vwBOeaLb"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
        "\n",
        "for fold, ( _, val_) in enumerate(skf.split(X=result, y=result.label.astype(int))):\n",
        "    result.loc[val_ , \"kfold\"] = int(fold)\n",
        "    \n",
        "result[\"kfold\"] = result[\"kfold\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOtw3nW-2X58"
      },
      "outputs": [],
      "source": [
        "del model,train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoQghNKN2Cy2",
        "outputId": "b4d55447-c20b-44c5-f2d0-dbeff5de179c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "588"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://seekinginference.com/applied_nlp/bert-cnn.html"
      ],
      "metadata": {
        "id": "QCwmBcvPlNaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXC4SsiDbbGR",
        "outputId": "41872c42-2cc0-47d8-c1e2-76d220d3222d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== Fold: 0 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:01<00:00,  1.52s/it, Epoch=1, LR=4.21e-5, Train_Loss=0.272]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=1, LR=4.21e-5, Valid_Loss=0.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.23017840114311192)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:02<00:00,  1.52s/it, Epoch=2, LR=3.82e-6, Train_Loss=0.106]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=2, LR=3.82e-6, Valid_Loss=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.23017840114311192 ---> 0.22799760888629872)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:02<00:00,  1.52s/it, Epoch=3, LR=7.46e-5, Train_Loss=0.0603]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.54s/it, Epoch=3, LR=7.46e-5, Valid_Loss=0.233]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete in 0h 22m 41s\n",
            "Best Loss: 0.2280\n",
            "\n",
            "====== Fold: 1 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:01<00:00,  1.52s/it, Epoch=1, LR=4.21e-5, Train_Loss=0.301]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=1, LR=4.21e-5, Valid_Loss=0.263]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.2632514023178321)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:02<00:00,  1.52s/it, Epoch=2, LR=3.82e-6, Train_Loss=0.12]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.54s/it, Epoch=2, LR=3.82e-6, Valid_Loss=0.241]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.2632514023178321 ---> 0.2413945581616047)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:06<00:00,  1.54s/it, Epoch=3, LR=7.46e-5, Train_Loss=0.0829]\n",
            "100%|██████████| 9/9 [00:23<00:00,  2.61s/it, Epoch=3, LR=7.46e-5, Valid_Loss=0.241]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete in 0h 22m 36s\n",
            "Best Loss: 0.2414\n",
            "\n",
            "====== Fold: 2 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:07<00:00,  1.54s/it, Epoch=1, LR=4.21e-5, Train_Loss=0.275]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.55s/it, Epoch=1, LR=4.21e-5, Valid_Loss=0.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.24030143087091)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.52s/it, Epoch=2, LR=3.82e-6, Train_Loss=0.108]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.52s/it, Epoch=2, LR=3.82e-6, Valid_Loss=0.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.24030143087091 ---> 0.22040169140061747)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.52s/it, Epoch=3, LR=7.46e-5, Train_Loss=0.0783]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=3, LR=7.46e-5, Valid_Loss=0.224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete in 0h 22m 34s\n",
            "Best Loss: 0.2204\n",
            "\n",
            "====== Fold: 3 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [07:00<00:00,  1.52s/it, Epoch=1, LR=4.21e-5, Train_Loss=0.258]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=1, LR=4.21e-5, Valid_Loss=0.247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.24694344347564753)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.52s/it, Epoch=2, LR=3.82e-6, Train_Loss=0.11]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.52s/it, Epoch=2, LR=3.82e-6, Valid_Loss=0.235]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.24694344347564753 ---> 0.23500306963490236)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.51s/it, Epoch=3, LR=7.46e-5, Train_Loss=0.0802]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=3, LR=7.46e-5, Valid_Loss=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.23500306963490236 ---> 0.22784528313776217)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 0h 22m 29s\n",
            "Best Loss: 0.2278\n",
            "\n",
            "====== Fold: 4 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla K80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.52s/it, Epoch=1, LR=4.21e-5, Train_Loss=0.26]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.52s/it, Epoch=1, LR=4.21e-5, Valid_Loss=0.231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (inf ---> 0.23056775557435377)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.51s/it, Epoch=2, LR=3.82e-6, Train_Loss=0.0932]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=2, LR=3.82e-6, Valid_Loss=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.23056775557435377 ---> 0.22793342237653286)\n",
            "Model Saved\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [06:59<00:00,  1.52s/it, Epoch=3, LR=7.46e-5, Train_Loss=0.0598]\n",
            "100%|██████████| 9/9 [00:22<00:00,  2.53s/it, Epoch=3, LR=7.46e-5, Valid_Loss=0.218]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Improved (0.22793342237653286 ---> 0.217538956324116)\n",
            "Model Saved\n",
            "\n",
            "Training complete in 0h 22m 30s\n",
            "Best Loss: 0.2175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for fold in range(0, CONFIG['n_fold']):\n",
        "    print(f\"====== Fold: {fold} ======\")\n",
        "\n",
        "    \n",
        "    # Create Dataloaders\n",
        "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
        "    \n",
        "    model = PCL_Model_Arch()\n",
        "    model.to(CONFIG['device'])\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Define Optimizer and Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
        "    scheduler = fetch_scheduler(optimizer)\n",
        "    \n",
        "    model, history = run_training(model, optimizer, scheduler,\n",
        "                                  device=CONFIG['device'],\n",
        "                                  num_epochs=CONFIG['epochs'],\n",
        "                                  fold=fold)\n",
        "    \n",
        "    \n",
        "    del model, history, train_loader, valid_loader\n",
        "    _ = gc.collect()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "XSvm2lLPAf0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = PCLTrainDataset(result_test, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "ujNNMM9HAGtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_fn(model, dataloader, device):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    PREDS = []\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        fetures=data['features'].to(device, dtype = torch.float)\n",
        "        \n",
        "        outputs = model(ids, mask,fetures)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "#         print(len(outputs))\n",
        "#         print(len(np.max(outputs.cpu().detach().numpy(),axis=1)))\n",
        "        PREDS.append(outputs.detach().cpu().numpy()) \n",
        "    \n",
        "    PREDS = np.concatenate(PREDS)\n",
        "    gc.collect()\n",
        "    \n",
        "    return PREDS"
      ],
      "metadata": {
        "id": "piuXPwW433gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model_paths, dataloader, device):\n",
        "    final_preds = []\n",
        "    for i, path in enumerate(model_paths):\n",
        "        model = PCL_Model_Arch()\n",
        "        model.to(CONFIG['device'])\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        \n",
        "        print(f\"Getting predictions for model {i+1}\")\n",
        "        preds = valid_fn(model, dataloader, device)\n",
        "        final_preds.append(preds)\n",
        "    \n",
        "    final_preds = np.array(final_preds)\n",
        "    final_preds = np.mean(final_preds, axis=0)\n",
        "    final_preds= np.argmax(final_preds,axis=1)\n",
        "    return final_preds"
      ],
      "metadata": {
        "id": "zaxyuvUP3Md0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models/bert_base_cased/Loss-Fold-0.bin','/content/drive/MyDrive/ISarcasm/Models/bert_base_cased/Loss-Fold-1.bin','/content/drive/MyDrive/ISarcasm/Models/bert_base_cased/Loss-Fold-2.bin','/content/drive/MyDrive/ISarcasm/Models/bert_base_cased/Loss-Fold-3.bin','/content/drive/MyDrive/ISarcasm/Models/bert_base_cased/Loss-Fold-4.bin']\n",
        "preds = inference(MODEL_PATH_2, valid_loader, CONFIG['device'])"
      ],
      "metadata": {
        "id": "-mbRltZW4Dvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5463ab81-2b3d-4487-bfc5-0df455f29ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:28<00:00,  2.58s/it]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:28<00:00,  2.59s/it]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:28<00:00,  2.59s/it]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:28<00:00,  2.59s/it]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:28<00:00,  2.59s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKQV51HyommQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import jaccard_score,f1_score,accuracy_score,recall_score,precision_score,classification_report\n",
        "def print_statistics(y, y_pred):\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision =precision_score(y, y_pred, average='weighted')\n",
        "    recall = recall_score(y, y_pred, average='weighted')\n",
        "    f_score = f1_score(y, y_pred, average='weighted')\n",
        "    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n",
        "          % (accuracy, precision, recall, f_score))\n",
        "    print(classification_report(y, y_pred))\n",
        "    return accuracy, precision, recall, f_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3965a5XAooJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ca1e34-4e00-4cda-fc0c-19b850d3ff9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.747\n",
            "Precision: 0.732\n",
            "Recall: 0.747\n",
            "F_score: 0.738\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       531\n",
            "           1       0.45      0.37      0.41       162\n",
            "\n",
            "    accuracy                           0.75       693\n",
            "   macro avg       0.63      0.62      0.62       693\n",
            "weighted avg       0.73      0.75      0.74       693\n",
            "\n",
            "(0.7474747474747475, 0.7321282101357289, 0.7474747474747475, 0.7384186910977759)\n"
          ]
        }
      ],
      "source": [
        "print(print_statistics(test['sarcastic'],preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8hjnxbbfJq"
      },
      "source": [
        "## Prepare submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7HICl8MJQf0"
      },
      "outputs": [],
      "source": [
        "!cat task1.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCjziGtxJRif"
      },
      "outputs": [],
      "source": [
        "!cat task2.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZDLUcYZbhYg"
      },
      "outputs": [],
      "source": [
        "!zip submission.zip task1.txt task2.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bert-base+LSTM+ FE+recall CE loss+ Imbalance datasampler.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b9bbca0bef341dbbf6ed7842a86bda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0080f49699b34f3e98b665772aadc600",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26a67b64340346b9a08d4107500e7731",
              "IPY_MODEL_062aac1c5724452b93df4dcdb15a9766",
              "IPY_MODEL_1b4c603f5c184adc968f8299b33df99a"
            ]
          }
        },
        "0080f49699b34f3e98b665772aadc600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26a67b64340346b9a08d4107500e7731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c615288d9775421c8913bf5eed9872ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1baa4d362fc746ad803345ee0f9e3807"
          }
        },
        "062aac1c5724452b93df4dcdb15a9766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f6303eccbd74d5ea6d0412ebd704749",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_896c504cae164ab4ad25d1e2b8c07f33"
          }
        },
        "1b4c603f5c184adc968f8299b33df99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ca44c7758b64b8dabe3971147b2c480",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 714B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a982e69a2d14b81a0a2ee81d5d4bcbc"
          }
        },
        "c615288d9775421c8913bf5eed9872ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1baa4d362fc746ad803345ee0f9e3807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f6303eccbd74d5ea6d0412ebd704749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "896c504cae164ab4ad25d1e2b8c07f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ca44c7758b64b8dabe3971147b2c480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a982e69a2d14b81a0a2ee81d5d4bcbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9b9bc61639445f2b9050ccd04febb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f7d5d62a968489d945b2eccb51d4d46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb38dc1c02944bbe8dc46f7aae0fec3d",
              "IPY_MODEL_90f59a935a7b4e6f83c659fc46761ee6",
              "IPY_MODEL_a09e419a2c344fd591f64f0938c3a438"
            ]
          }
        },
        "8f7d5d62a968489d945b2eccb51d4d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb38dc1c02944bbe8dc46f7aae0fec3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_652beb3e38cd4d5297f39f284d56b5bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4d58c810eb74179a315b7b094b744df"
          }
        },
        "90f59a935a7b4e6f83c659fc46761ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51bfc7e758b44aae986ac052f4d74ac7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b70358c2de64d089a1b7b87a9f0dd0a"
          }
        },
        "a09e419a2c344fd591f64f0938c3a438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f1626b5d4ba0465b8fdeea79fd2f4962",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 14.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3d23150c7e645f984c21bf9a0a17b2a"
          }
        },
        "652beb3e38cd4d5297f39f284d56b5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4d58c810eb74179a315b7b094b744df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51bfc7e758b44aae986ac052f4d74ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b70358c2de64d089a1b7b87a9f0dd0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1626b5d4ba0465b8fdeea79fd2f4962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3d23150c7e645f984c21bf9a0a17b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bce8ad6d1dd6407abab32aaadeb801da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65d9025904024cd8af5cd3543fe38cdc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_759aa8961f294b06b43add63ddb5ea59",
              "IPY_MODEL_7586b7e73a034d2885d1af0ef6cb829e",
              "IPY_MODEL_446ce8e71aef48a89e8d8c60fada4cee"
            ]
          }
        },
        "65d9025904024cd8af5cd3543fe38cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "759aa8961f294b06b43add63ddb5ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f451996517d04d90aa993d61cfca39d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6552a0ae0db4d6887bc679264d28403"
          }
        },
        "7586b7e73a034d2885d1af0ef6cb829e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c684703538314a3f84edea53fb62908b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f50a9cec1a064f0295fe4b015c60c142"
          }
        },
        "446ce8e71aef48a89e8d8c60fada4cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e98812885c0d4ef5a679ae6af004c747",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 666kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d460c42382c4833b53df0050edd2c3d"
          }
        },
        "f451996517d04d90aa993d61cfca39d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6552a0ae0db4d6887bc679264d28403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c684703538314a3f84edea53fb62908b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f50a9cec1a064f0295fe4b015c60c142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e98812885c0d4ef5a679ae6af004c747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d460c42382c4833b53df0050edd2c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62eab194bfc9435e8b642c628aa0dcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e96b92100a945b8ab2c697ad3d26d1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b87b276a6034aaba384a82d2ecd7768",
              "IPY_MODEL_f4deea6c2b1e4e839bde5c3da090a4a4",
              "IPY_MODEL_08862aae5aed44889752fbae9b9f8cdc"
            ]
          }
        },
        "8e96b92100a945b8ab2c697ad3d26d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b87b276a6034aaba384a82d2ecd7768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3765a6da830499dab4c8da3ffa3c382",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_009212da43b1421283e16f7956106fb0"
          }
        },
        "f4deea6c2b1e4e839bde5c3da090a4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e905eaeaca8b4f05abe8f7b8c1ab996d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9ae5f9d005e4d2db43b45f202f44240"
          }
        },
        "08862aae5aed44889752fbae9b9f8cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e916f269d714ef89b8f83b51ac84de0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 689kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6674f5ff4c9c45d0b822c02b50de5e1b"
          }
        },
        "b3765a6da830499dab4c8da3ffa3c382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "009212da43b1421283e16f7956106fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e905eaeaca8b4f05abe8f7b8c1ab996d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9ae5f9d005e4d2db43b45f202f44240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e916f269d714ef89b8f83b51ac84de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6674f5ff4c9c45d0b822c02b50de5e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}