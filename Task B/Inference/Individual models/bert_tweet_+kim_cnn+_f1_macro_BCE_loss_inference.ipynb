{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08esTFOYO99"
      },
      "source": [
        "# Main imports and code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnHQoayhBYlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfced5c3-0eb2-47aa-b2f4-cd660d369c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 27 13:08:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check which gpu we're using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYhFR7nSYOjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b40925-2c3b-4f5f-ea58-9efc55227db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.8\n"
          ]
        }
      ],
      "source": [
        "!pip  install transformers\n",
        "!pip install pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJC8wj73Zd_p"
      },
      "outputs": [],
      "source": [
        "# Any results you write to the current directory are saved as output.\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "from transformers import BertTokenizer,BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from argparse import ArgumentParser\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.engine.engine import Engine, State, Events\n",
        "from ignite.handlers import EarlyStopping\n",
        "from ignite.contrib.handlers import TensorboardLogger, ProgressBar\n",
        "from ignite.utils import convert_tensor\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvKeryw3eQPw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utils\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fezs8xASSS28"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3FDM6BjTLwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40da938-90da-4a32-adab-28e7cca2dd63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 10.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSzWEX54ScQi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2J-Qx3ekn_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558d102a-6ef1-4e7b-a500-17000675312b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.concat([train, validate], ignore_index=True)"
      ],
      "metadata": {
        "id": "PJrh2l2qdXf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv('/content/drive/MyDrive/ISarcasm/TestSet/task_B_En_test.csv')\n"
      ],
      "metadata": {
        "id": "wIDc7lJ7THeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6FY70KZ6TY"
      },
      "source": [
        "# RoBERTa Baseline for Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA9QzHTCl5F6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlT2IDHumPNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4555c3-a5b5-4073-f439-84f54dccf357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 296 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 311 kB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.3 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-E_jNQbV_NL"
      },
      "outputs": [],
      "source": [
        "class PCLTrainDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length,displacemnt):\n",
        "        self.df = df\n",
        "        self.max_len = max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = df['text'].values\n",
        "        self.label=df[['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        # summary = self.summary[index]\n",
        "        inputs_text = self.tokenizer.encode_plus(\n",
        "                                text,\n",
        "                                truncation=True,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length=self.max_len,\n",
        "                                padding='max_length'\n",
        "                            )\n",
        "        \n",
        "                            \n",
        "        target = self.label[index]\n",
        "        \n",
        "        text_ids = inputs_text['input_ids']\n",
        "        text_mask = inputs_text['attention_mask']\n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "        return {\n",
        "            \n",
        "            'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
        "            'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
        "            'target': torch.tensor(target, dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZa-chAxXf5r"
      },
      "outputs": [],
      "source": [
        "class PCL_Model_Arch(nn.Module):\n",
        "    def __init__(self,pre_trained='vinai/bertweet-base'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = AutoModel.from_pretrained(pre_trained, output_hidden_states=True)\n",
        "        output_channel = 16  # number of kernels\n",
        "        num_classes = 6  # number of targets to predict\n",
        "        dropout = 0.2  # dropout value\n",
        "        embedding_dim = 768   # length of embedding dim\n",
        "\n",
        "        ks = 3  # three conv nets here\n",
        "\n",
        "        # input_channel = word embeddings at a value of 1; 3 for RGB images\n",
        "        input_channel = 4  # for single embedding, input_channel = 1\n",
        "\n",
        "        # [3, 4, 5] = window height\n",
        "        # padding = padding to account for height of search window\n",
        "\n",
        "        # 3 convolutional nets\n",
        "        self.conv1 = nn.Conv2d(input_channel, output_channel, (3, embedding_dim), padding=(2, 0), groups=4)\n",
        "        self.conv2 = nn.Conv2d(input_channel, output_channel, (4, embedding_dim), padding=(3, 0), groups=4)\n",
        "        self.conv3 = nn.Conv2d(input_channel, output_channel, (5, embedding_dim), padding=(4, 0), groups=4)\n",
        "\n",
        "        # apply dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fully connected layer for classification\n",
        "        # 3x conv nets * output channel\n",
        "        self.fc1 = nn.Linear(ks * output_channel, num_classes)\n",
        "        self.softmax = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text_id, text_mask):\n",
        "        # get the last 4 layers\n",
        "        outputs= self.bert(text_id, attention_mask=text_mask)\n",
        "        # all_layers  = [4, 16, 256, 768]\n",
        "        hidden_layers = outputs[2]  # get hidden layers\n",
        "\n",
        "        hidden_layers = torch.stack(hidden_layers, dim=1)\n",
        "        x = hidden_layers[:, -4:] \n",
        "        # x = x.unsqueeze(1)\n",
        "        # x = torch.mean(x, 0)\n",
        "        # print(hidden_layers.size())\n",
        "      \n",
        "        torch.cuda.empty_cache()\n",
        "        x = [F.relu(self.conv1(x)).squeeze(3), F.relu(self.conv2(x)).squeeze(3), F.relu(self.conv3(x)).squeeze(3)]\n",
        "        # max-over-time pooling; # (batch, channel_output) * ks\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "        # concat results; (batch, channel_output * ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        # add dropout\n",
        "        x = self.dropout(x)\n",
        "        # generate logits (batch, target_size)\n",
        "        logit = self.fc1(x)\n",
        "        torch.cuda.empty_cache()\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT2dbUWN294h",
        "outputId": "c3072342-3a3c-4529-e103-14317eb9a9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 102 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 112 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 122 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 133 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 143 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 153 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 12.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=93111db2c93e452d1833197c2b89a5638e66dd6d3765c710de41c0934d0e20a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuODW43NYhTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "2a28031ebb924904864df63304242dfe",
            "c372cc76aba14e77b7336dccb3c38607",
            "bee975ad48f34f398e9da02cbec159e4",
            "138dffb00dea4af19bcbd8a74c17d559",
            "75f25244944341dca8d16646ef77f002",
            "3cfb1947e5a7485a86f5a4d1b5a1e4bc",
            "b5d60ae5977d412583f58145ea2acb92",
            "755992a0ab6c45408b7af7fcc91e6b11",
            "6098d219061446ff8f62ce25ecc4c364",
            "d59c67c20be546d1b91b6787bd231593",
            "00e48e8af65944938e4b08a468af443d",
            "ed8182203540426bb1de9a8b785d6b60",
            "3d491123b75340eeafc339e22813edf9",
            "9614a19c941a49bf8e3a24699b28e4e1",
            "94071102574f4ebeaa84a756e6acea1e",
            "580d35762f0d4f9e89fd2ce537ef6a84",
            "2c80bc3ca8d74d39870de108233d5304",
            "aee91bcaa61340ab8095d674d6ca834e",
            "de98af45a66b46028204ece464762bee",
            "f9adac90b9fe46738d7efaaf2337c0c3",
            "79450a8897b543bab7e15285cf7bb2ad",
            "c46b79d11a784c7ab28fa2306257971d",
            "1863d8ba24e84403bf1bb17a62177361",
            "4a139326f19340f5b1f6136ac91c041e",
            "28daef5234a940c8aaad02086007ddf4",
            "4a97f3f8d6e44cb1b75cc935be7807a3",
            "5441095181bd4753a0db5461021e4633",
            "50a1dffdb58347dc94e84752677bd70c",
            "492ed286dfd145c3a1266a24465ad15d",
            "68046b9594fc4feb8a30009f5e022cdc",
            "4a5cde8ea0164b64a6d664d8dd408908",
            "9e7bfbff2e484f659760d7a80269dc13",
            "d30bde1347c04dc8ae9682772cdf133f"
          ]
        },
        "outputId": "60babf28-9b22-46cd-f70c-7cb6304673fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a28031ebb924904864df63304242dfe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed8182203540426bb1de9a8b785d6b60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1863d8ba24e84403bf1bb17a62177361",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer= AutoTokenizer.from_pretrained('vinai/bertweet-base')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRX0b55VaxmS"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\"seed\": 2021,\n",
        "          \"epochs\": 5,\n",
        "          \"model_name\": \"xlnet-base-cased\",\n",
        "          \"train_batch_size\": 16,\n",
        "          \"valid_batch_size\": 64,\n",
        "          \"max_length\": 120,\n",
        "          \"learning_rate\": 1e-4,\n",
        "          \"scheduler\": 'CosineAnnealingLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"num_classes\": 1,\n",
        "          \"margin\": 0.5,\n",
        "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "XSvm2lLPAf0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = PCLTrainDataset(test, tokenizer=tokenizer, max_length=CONFIG['max_length'],displacemnt=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=2, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "ujNNMM9HAGtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_fn(model, dataloader, device):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    PREDS = []\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        ids = data['text_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['text_mask'].to(device, dtype = torch.long)\n",
        "        \n",
        "        outputs = model(ids, mask)\n",
        "        sig=nn.Sigmoid()\n",
        "        outputs=sig(outputs)\n",
        "        # outputs = outputs.argmax(dim=1)\n",
        "#         print(len(outputs))\n",
        "#         print(len(np.max(outputs.cpu().detach().numpy(),axis=1)))\n",
        "        PREDS.append(outputs.detach().cpu().numpy()) \n",
        "        # print(outputs.detach().cpu().numpy())\n",
        "    \n",
        "    PREDS = np.concatenate(PREDS)\n",
        "    gc.collect()\n",
        "    \n",
        "    return PREDS"
      ],
      "metadata": {
        "id": "piuXPwW433gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model_paths, dataloader, device):\n",
        "    final_preds = []\n",
        "    for i, path in enumerate(model_paths):\n",
        "        model = PCL_Model_Arch()\n",
        "        model.to(CONFIG['device'])\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        \n",
        "        print(f\"Getting predictions for model {i+1}\")\n",
        "        preds = valid_fn(model, dataloader, device)\n",
        "        final_preds.append(preds)\n",
        "    \n",
        "    final_preds = np.array(final_preds)\n",
        "    # print(final_preds)\n",
        "    final_preds = np.mean(final_preds, axis=0)\n",
        "    # print(final_preds)\n",
        "    final_preds[final_preds>=0.5] = 1\n",
        "    final_preds[final_preds<0.5] = 0\n",
        "    # final_preds= np.argmax(final_preds,axis=1)\n",
        "    return final_preds"
      ],
      "metadata": {
        "id": "zaxyuvUP3Md0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assymetric loss random sampler"
      ],
      "metadata": {
        "id": "ZKHCDN1ipDcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balanced Loss random sampler"
      ],
      "metadata": {
        "id": "-eVM3M85lKSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_balanced_loss_random_sampler/Loss-Fold-0.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_balanced_loss_random_sampler/Loss-Fold-1.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_balanced_loss_random_sampler/Loss-Fold-2.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_balanced_loss_random_sampler/Loss-Fold-3.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_balanced_loss_random_sampler/Loss-Fold-4.bin']\n",
        "# MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn/Loss-Fold-0.bin']\n",
        "preds = inference(MODEL_PATH_2, valid_loader, CONFIG['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502,
          "referenced_widgets": [
            "f768428ed16a4fb9b988415a32a48be6",
            "bc2e7cab43fd41609288514f62f925c6",
            "31cb8832c35940bd9df640ee6dd69b97",
            "3c5421ce43534d05b41c2ed63b8c6ff8",
            "8008b8387fa340ec9d18e9b30fc7fe10",
            "362630e6f5b644eba11452833884a1f0",
            "6cf94842dd7544c5889534ce1c808f3d",
            "6056a9a745e44464a3ad9f70a2463b8e",
            "4c1a2c8387a84a56b3aa0b9663ffec59",
            "0457e72bc6774165a2e644dc5f1a359a",
            "77032bb5f79a47f5816b701ff70cef3f"
          ]
        },
        "id": "vsnXTo2BTd5h",
        "outputId": "87f11f38-6be8-4753-e207-76aeae040ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f768428ed16a4fb9b988415a32a48be6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/517M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.08s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.08s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.10s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.10s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.10s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.metrics import f1_score,accuracy_score,precision_score,classification_report\n",
        "print(classification_report(test[['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']].values, preds,target_names=['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhCneZ1iTfG6",
        "outputId": "fa12a2b5-fed4-49a6-d457-15751a99e4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "            sarcasm       0.13      0.93      0.23       180\n",
            "              irony       0.06      0.90      0.11        20\n",
            "             satire       0.12      0.33      0.17        49\n",
            "     understatement       0.00      0.00      0.00         1\n",
            "      overstatement       0.05      0.10      0.06        10\n",
            "rhetorical_question       0.06      0.82      0.11        11\n",
            "\n",
            "          micro avg       0.11      0.78      0.20       271\n",
            "          macro avg       0.07      0.51      0.12       271\n",
            "       weighted avg       0.12      0.78      0.20       271\n",
            "        samples avg       0.12      0.12      0.12       271\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance losss under sampler"
      ],
      "metadata": {
        "id": "hSY0DEpHhO8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance loss no sampler"
      ],
      "metadata": {
        "id": "yDx7BMlNZ9ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balanced Loss + sampler cycle"
      ],
      "metadata": {
        "id": "xMC2FpO4SKD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assym Loss + sampler cycle"
      ],
      "metadata": {
        "id": "vE-pYYYvHlcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_assym_loss/Loss-Fold-0.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_assym_loss/Loss-Fold-1.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_assym_loss/Loss-Fold-2.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_assym_loss/Loss-Fold-3.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_assym_loss/Loss-Fold-4.bin']\n",
        "# MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn/Loss-Fold-0.bin']\n",
        "preds = inference(MODEL_PATH_2, valid_loader, CONFIG['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzTpRVh6Ut1E",
        "outputId": "a7f754d7-156a-47bb-a27b-8d47fd362596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.09s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.09s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.08s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.09s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.metrics import f1_score,accuracy_score,precision_score,classification_report\n",
        "print(classification_report(test[['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']].values, preds,target_names=['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ECPbiB8Uu7S",
        "outputId": "339c52d1-6e50-46ad-85bb-24669e7dccc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "            sarcasm       0.13      1.00      0.23       180\n",
            "              irony       0.03      0.95      0.05        20\n",
            "             satire       0.09      0.47      0.16        49\n",
            "     understatement       0.00      0.00      0.00         1\n",
            "      overstatement       0.02      0.30      0.03        10\n",
            "rhetorical_question       0.06      1.00      0.11        11\n",
            "\n",
            "          micro avg       0.08      0.87      0.15       271\n",
            "          macro avg       0.05      0.62      0.10       271\n",
            "       weighted avg       0.11      0.87      0.19       271\n",
            "        samples avg       0.09      0.13      0.10       271\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Recall* Loss + sampler defualt"
      ],
      "metadata": {
        "id": "xVvhX_-AHTMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn_recall_balancer/Loss-Fold-0.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn_recall_balancer/Loss-Fold-1.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn_recall_balancer/Loss-Fold-2.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn_recall_balancer/Loss-Fold-3.bin','/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn_recall_balancer/Loss-Fold-4.bin']\n",
        "# MODEL_PATH_2=['/content/drive/MyDrive/ISarcasm/Models_Task_B/bert_tweet_kim_cnn/Loss-Fold-0.bin']\n",
        "preds = inference(MODEL_PATH_2, valid_loader, CONFIG['device'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI7IREUkU-MR",
        "outputId": "7c5f289c-bfc8-447f-bce0-f52e907cb824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.09s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.09s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.09s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:23<00:00,  1.08s/it]\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions for model 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:24<00:00,  1.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.metrics import f1_score,accuracy_score,precision_score,classification_report\n",
        "print(classification_report(test[['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']].values, preds,target_names=['sarcasm', 'irony',\n",
        "       'satire', 'understatement', 'overstatement', 'rhetorical_question']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frBDCdkKU_po",
        "outputId": "5282430c-d202-414d-e9b2-df5577bff75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "            sarcasm       0.13      1.00      0.23       180\n",
            "              irony       0.01      1.00      0.03        20\n",
            "             satire       0.00      0.00      0.00        49\n",
            "     understatement       0.00      1.00      0.00         1\n",
            "      overstatement       0.01      0.20      0.02        10\n",
            "rhetorical_question       0.00      0.00      0.00        11\n",
            "\n",
            "          micro avg       0.05      0.75      0.09       271\n",
            "          macro avg       0.03      0.53      0.05       271\n",
            "       weighted avg       0.09      0.75      0.15       271\n",
            "        samples avg       0.05      0.12      0.07       271\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bert tweet +kim cnn+ f1 macro BCE loss_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a28031ebb924904864df63304242dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c372cc76aba14e77b7336dccb3c38607",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bee975ad48f34f398e9da02cbec159e4",
              "IPY_MODEL_138dffb00dea4af19bcbd8a74c17d559",
              "IPY_MODEL_75f25244944341dca8d16646ef77f002"
            ]
          }
        },
        "c372cc76aba14e77b7336dccb3c38607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bee975ad48f34f398e9da02cbec159e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cfb1947e5a7485a86f5a4d1b5a1e4bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5d60ae5977d412583f58145ea2acb92"
          }
        },
        "138dffb00dea4af19bcbd8a74c17d559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_755992a0ab6c45408b7af7fcc91e6b11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6098d219061446ff8f62ce25ecc4c364"
          }
        },
        "75f25244944341dca8d16646ef77f002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d59c67c20be546d1b91b6787bd231593",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558/558 [00:00&lt;00:00, 4.85kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00e48e8af65944938e4b08a468af443d"
          }
        },
        "3cfb1947e5a7485a86f5a4d1b5a1e4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5d60ae5977d412583f58145ea2acb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "755992a0ab6c45408b7af7fcc91e6b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6098d219061446ff8f62ce25ecc4c364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d59c67c20be546d1b91b6787bd231593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00e48e8af65944938e4b08a468af443d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed8182203540426bb1de9a8b785d6b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d491123b75340eeafc339e22813edf9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9614a19c941a49bf8e3a24699b28e4e1",
              "IPY_MODEL_94071102574f4ebeaa84a756e6acea1e",
              "IPY_MODEL_580d35762f0d4f9e89fd2ce537ef6a84"
            ]
          }
        },
        "3d491123b75340eeafc339e22813edf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9614a19c941a49bf8e3a24699b28e4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c80bc3ca8d74d39870de108233d5304",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aee91bcaa61340ab8095d674d6ca834e"
          }
        },
        "94071102574f4ebeaa84a756e6acea1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_de98af45a66b46028204ece464762bee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 843438,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 843438,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9adac90b9fe46738d7efaaf2337c0c3"
          }
        },
        "580d35762f0d4f9e89fd2ce537ef6a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79450a8897b543bab7e15285cf7bb2ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 824k/824k [00:00&lt;00:00, 678kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c46b79d11a784c7ab28fa2306257971d"
          }
        },
        "2c80bc3ca8d74d39870de108233d5304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aee91bcaa61340ab8095d674d6ca834e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de98af45a66b46028204ece464762bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9adac90b9fe46738d7efaaf2337c0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79450a8897b543bab7e15285cf7bb2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c46b79d11a784c7ab28fa2306257971d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1863d8ba24e84403bf1bb17a62177361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a139326f19340f5b1f6136ac91c041e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28daef5234a940c8aaad02086007ddf4",
              "IPY_MODEL_4a97f3f8d6e44cb1b75cc935be7807a3",
              "IPY_MODEL_5441095181bd4753a0db5461021e4633"
            ]
          }
        },
        "4a139326f19340f5b1f6136ac91c041e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28daef5234a940c8aaad02086007ddf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50a1dffdb58347dc94e84752677bd70c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_492ed286dfd145c3a1266a24465ad15d"
          }
        },
        "4a97f3f8d6e44cb1b75cc935be7807a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68046b9594fc4feb8a30009f5e022cdc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1078931,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1078931,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a5cde8ea0164b64a6d664d8dd408908"
          }
        },
        "5441095181bd4753a0db5461021e4633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e7bfbff2e484f659760d7a80269dc13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.03M/1.03M [00:00&lt;00:00, 2.89MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d30bde1347c04dc8ae9682772cdf133f"
          }
        },
        "50a1dffdb58347dc94e84752677bd70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "492ed286dfd145c3a1266a24465ad15d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68046b9594fc4feb8a30009f5e022cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a5cde8ea0164b64a6d664d8dd408908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e7bfbff2e484f659760d7a80269dc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d30bde1347c04dc8ae9682772cdf133f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f768428ed16a4fb9b988415a32a48be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc2e7cab43fd41609288514f62f925c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31cb8832c35940bd9df640ee6dd69b97",
              "IPY_MODEL_3c5421ce43534d05b41c2ed63b8c6ff8",
              "IPY_MODEL_8008b8387fa340ec9d18e9b30fc7fe10"
            ]
          }
        },
        "bc2e7cab43fd41609288514f62f925c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31cb8832c35940bd9df640ee6dd69b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_362630e6f5b644eba11452833884a1f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cf94842dd7544c5889534ce1c808f3d"
          }
        },
        "3c5421ce43534d05b41c2ed63b8c6ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6056a9a745e44464a3ad9f70a2463b8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 542529064,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 542529064,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c1a2c8387a84a56b3aa0b9663ffec59"
          }
        },
        "8008b8387fa340ec9d18e9b30fc7fe10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0457e72bc6774165a2e644dc5f1a359a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 517M/517M [00:32&lt;00:00, 17.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77032bb5f79a47f5816b701ff70cef3f"
          }
        },
        "362630e6f5b644eba11452833884a1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cf94842dd7544c5889534ce1c808f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6056a9a745e44464a3ad9f70a2463b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c1a2c8387a84a56b3aa0b9663ffec59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0457e72bc6774165a2e644dc5f1a359a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77032bb5f79a47f5816b701ff70cef3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}